{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from jax import random, lax, jit, vmap, pmap\n",
    "from functools import partial\n",
    "from jax_tqdm import loop_tqdm\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "from src import CliffWalking, Q_learning, EpsilonGreedy, animated_heatmap, tabular_rollout, tabular_parallel_rollout, plot_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryanp\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\jax-rl-KPtyfD6I-py3.10\\lib\\site-packages\\jax\\_src\\ops\\scatter.py:94: FutureWarning:\n",
      "\n",
      "scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SEED = 2\n",
    "INITIAL_STATE = jnp.array([3, 0])\n",
    "GOAL_STATE = jnp.array([3, 10])\n",
    "GRID_SIZE = jnp.array([4, 11])\n",
    "N_ACTIONS = 4\n",
    "DISCOUNT = 0.9\n",
    "LEARNING_RATE = 0.1\n",
    "TIME_STEPS = 100_000\n",
    "STOCHASTIC_RESET = False\n",
    "\n",
    "key = random.PRNGKey(SEED)\n",
    "\n",
    "env = CliffWalking(INITIAL_STATE, GOAL_STATE, GRID_SIZE, STOCHASTIC_RESET)\n",
    "policy = EpsilonGreedy(0.01)\n",
    "agent = Q_learning(\n",
    "    DISCOUNT,\n",
    "    LEARNING_RATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryanp\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\jax-rl-KPtyfD6I-py3.10\\lib\\site-packages\\jax\\_src\\ops\\scatter.py:94: FutureWarning:\n",
      "\n",
      "scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "\n",
      "Running for 100,000 iterations: 100%|██████████| 100000/100000 [00:09<00:00, 10706.24it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plotly.com"
       },
       "data": [
        {
         "type": "heatmap",
         "z": [
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ]
         ]
        }
       ],
       "frames": [
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ],
            [
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ],
            [
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ],
            [
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 0"
          }
         },
         "name": "frame_0",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -0.7325387001037598,
             -0.6787587404251099,
             -0.5841453075408936,
             -0.4861752986907959,
             -0.39337649941444397,
             -0.29701000452041626,
             -0.19900000095367432,
             -0.10000000149011612,
             -0.10000000149011612,
             0,
             0
            ],
            [
             -0.7725530862808228,
             -0.6897813677787781,
             -0.539103627204895,
             -0.431745320558548,
             -0.3224513828754425,
             -0.28080999851226807,
             -0.19900000095367432,
             -0.10000000149011612,
             -0.10000000149011612,
             0,
             0
            ],
            [
             -0.9139423966407776,
             -0.6934271454811096,
             -0.5588580369949341,
             -0.43810972571372986,
             -0.2984679937362671,
             -0.21601001918315887,
             -0.19900000095367432,
             -0.10000000149011612,
             0,
             0,
             0
            ],
            [
             -1.2136317491531372,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 500"
          }
         },
         "name": "frame_1",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -1.1361513137817383,
             -1.0452768802642822,
             -1.0332739353179932,
             -0.864827573299408,
             -0.7617065906524658,
             -0.6760638356208801,
             -0.580253541469574,
             -0.4872782826423645,
             -0.39403989911079407,
             -0.3925776779651642,
             -0.37788668274879456
            ],
            [
             -1.2103233337402344,
             -1.085199236869812,
             -1.0212504863739014,
             -0.8640275597572327,
             -0.7452806234359741,
             -0.6466836929321289,
             -0.5333512425422668,
             -0.4345199763774872,
             -0.36261188983917236,
             -0.305896520614624,
             -0.2977389991283417
            ],
            [
             -1.310795545578003,
             -1.1479113101959229,
             -1.0555557012557983,
             -0.8800101280212402,
             -0.7590551972389221,
             -0.6337078809738159,
             -0.4973624050617218,
             -0.40414974093437195,
             -0.3145716190338135,
             -0.305757999420166,
             -0.21846401691436768
            ],
            [
             -1.5705680847167969,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 1000"
          }
         },
         "name": "frame_2",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -1.4854222536087036,
             -1.4501217603683472,
             -1.3532342910766602,
             -1.26461923122406,
             -1.128104329109192,
             -1.0356181859970093,
             -0.9561793208122253,
             -0.8581764698028564,
             -0.7643880844116211,
             -0.6793465614318848,
             -0.6452014446258545
            ],
            [
             -1.5467782020568848,
             -1.4881948232650757,
             -1.343514323234558,
             -1.2546837329864502,
             -1.1201976537704468,
             -1.0179369449615479,
             -0.9265139698982239,
             -0.8465886116027832,
             -0.7416505813598633,
             -0.6441576480865479,
             -0.543302059173584
            ],
            [
             -1.6523807048797607,
             -1.5186848640441895,
             -1.3935242891311646,
             -1.2600398063659668,
             -1.1589909791946411,
             -1.0432018041610718,
             -0.8813995718955994,
             -0.8320788145065308,
             -0.7289403676986694,
             -0.6033371090888977,
             -0.4114919602870941
            ],
            [
             -1.9027214050292969,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 1500"
          }
         },
         "name": "frame_3",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -1.8082205057144165,
             -1.76447594165802,
             -1.6850780248641968,
             -1.611725091934204,
             -1.5089690685272217,
             -1.399416446685791,
             -1.2765944004058838,
             -1.1361513137817383,
             -1.1300798654556274,
             -1.023512363433838,
             -0.9998475313186646
            ],
            [
             -1.8565055131912231,
             -1.785536527633667,
             -1.7154110670089722,
             -1.6344975233078003,
             -1.5122637748718262,
             -1.3746603727340698,
             -1.2380033731460571,
             -1.145868182182312,
             -1.0747756958007812,
             -1.018567442893982,
             -0.9561793208122253
            ],
            [
             -1.9836941957473755,
             -1.8412256240844727,
             -1.7493451833724976,
             -1.646776556968689,
             -1.4969242811203003,
             -1.3517553806304932,
             -1.246635913848877,
             -1.1375540494918823,
             -1.0399404764175415,
             -0.9516622424125671,
             -0.8455259799957275
            ],
            [
             -2.2995686531066895,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 2000"
          }
         },
         "name": "frame_4",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -2.10923433303833,
             -2.063857316970825,
             -2.028996229171753,
             -1.9027214050292969,
             -1.8209307193756104,
             -1.7194771766662598,
             -1.6516046524047852,
             -1.5517551898956299,
             -1.45381760597229,
             -1.3125418424606323,
             -1.2824386358261108
            ],
            [
             -2.143218755722046,
             -2.1490821838378906,
             -2.0067451000213623,
             -1.9009268283843994,
             -1.821334719657898,
             -1.721374273300171,
             -1.6628656387329102,
             -1.5353702306747437,
             -1.4231984615325928,
             -1.3304319381713867,
             -1.2247897386550903
            ],
            [
             -2.2995686531066895,
             -2.224252939224243,
             -2.0604677200317383,
             -1.9835537672042847,
             -1.8653318881988525,
             -1.7415320873260498,
             -1.6349610090255737,
             -1.5244238376617432,
             -1.4256482124328613,
             -1.304823875427246,
             -1.0687053203582764
            ],
            [
             -2.5854945182800293,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 2500"
          }
         },
         "name": "frame_5",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -2.4528074264526367,
             -2.4104511737823486,
             -2.3106203079223633,
             -2.226203680038452,
             -2.147447347640991,
             -2.126612663269043,
             -1.9836941957473755,
             -1.8763470649719238,
             -1.7383137941360474,
             -1.654862403869629,
             -1.5705680847167969
            ],
            [
             -2.4528074264526367,
             -2.4085707664489746,
             -2.3408031463623047,
             -2.220069646835327,
             -2.1448442935943604,
             -2.0685060024261475,
             -1.9867032766342163,
             -1.8660295009613037,
             -1.7579660415649414,
             -1.6135709285736084,
             -1.5447773933410645
            ],
            [
             -2.602996587753296,
             -2.4959821701049805,
             -2.3758678436279297,
             -2.290320634841919,
             -2.1816165447235107,
             -2.0902228355407715,
             -1.948378562927246,
             -1.809970736503601,
             -1.7265434265136719,
             -1.6341203451156616,
             -1.399416446685791
            ],
            [
             -2.8804831504821777,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 3000"
          }
         },
         "name": "frame_6",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -2.750196933746338,
             -2.7279891967773438,
             -2.6476492881774902,
             -2.5282793045043945,
             -2.4528074264526367,
             -2.348672866821289,
             -2.28993821144104,
             -2.2008726596832275,
             -2.063857316970825,
             -2.0286221504211426,
             -1.9500261545181274
            ],
            [
             -2.8238794803619385,
             -2.7483036518096924,
             -2.6215858459472656,
             -2.5167789459228516,
             -2.429335117340088,
             -2.334543466567993,
             -2.2610349655151367,
             -2.165853977203369,
             -2.0624420642852783,
             -1.9887608289718628,
             -1.8765937089920044
            ],
            [
             -2.9515492916107178,
             -2.7947793006896973,
             -2.659313678741455,
             -2.526947498321533,
             -2.414766788482666,
             -2.3554046154022217,
             -2.266662836074829,
             -2.157867670059204,
             -2.0153636932373047,
             -1.9273622035980225,
             -1.7383137941360474
            ],
            [
             -3.1744544506073,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 3500"
          }
         },
         "name": "frame_7",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -3.0332818031311035,
             -2.9655234813690186,
             -2.902649402618408,
             -2.8840596675872803,
             -2.805743455886841,
             -2.6737313270568848,
             -2.576317310333252,
             -2.494412422180176,
             -2.337740182876587,
             -2.2474899291992188,
             -2.17465877532959
            ],
            [
             -3.1055095195770264,
             -3.0084424018859863,
             -2.923524856567383,
             -2.8662045001983643,
             -2.771986246109009,
             -2.6759088039398193,
             -2.5686025619506836,
             -2.4585225582122803,
             -2.3371171951293945,
             -2.262053966522217,
             -2.1402511596679688
            ],
            [
             -3.2251057624816895,
             -3.062563896179199,
             -2.973188638687134,
             -2.8803791999816895,
             -2.8029699325561523,
             -2.7020606994628906,
             -2.5531773567199707,
             -2.42455792427063,
             -2.3216261863708496,
             -2.162431240081787,
             -1.9786180257797241
            ],
            [
             -3.433858871459961,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 4000"
          }
         },
         "name": "frame_8",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -3.3691134452819824,
             -3.3102827072143555,
             -3.204993486404419,
             -3.067584991455078,
             -2.9655234813690186,
             -2.89420747756958,
             -2.8123257160186768,
             -2.7978389263153076,
             -2.6991727352142334,
             -2.6017746925354004,
             -2.5282793045043945
            ],
            [
             -3.3771798610687256,
             -3.349834442138672,
             -3.2487003803253174,
             -3.108516216278076,
             -2.9747307300567627,
             -2.9191925525665283,
             -2.8329687118530273,
             -2.763054370880127,
             -2.65250825881958,
             -2.56600022315979,
             -2.481799364089966
            ],
            [
             -3.488642930984497,
             -3.3419547080993652,
             -3.269362688064575,
             -3.121063470840454,
             -3.009396553039551,
             -2.9412641525268555,
             -2.86759877204895,
             -2.7497191429138184,
             -2.642756223678589,
             -2.4829163551330566,
             -2.359630823135376
            ],
            [
             -3.696831703186035,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 4500"
          }
         },
         "name": "frame_9",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -3.6271965503692627,
             -3.5294411182403564,
             -3.438251256942749,
             -3.4269447326660156,
             -3.2891793251037598,
             -3.1744544506073,
             -3.1055095195770264,
             -3.0079734325408936,
             -2.9152839183807373,
             -2.822695016860962,
             -2.750196933746338
            ],
            [
             -3.6381452083587646,
             -3.5724170207977295,
             -3.4774861335754395,
             -3.4026663303375244,
             -3.313816547393799,
             -3.234983205795288,
             -3.111569881439209,
             -3.004692316055298,
             -2.90817928314209,
             -2.806734085083008,
             -2.7230896949768066
            ],
            [
             -3.7647461891174316,
             -3.634603500366211,
             -3.5333399772644043,
             -3.4185328483581543,
             -3.3336310386657715,
             -3.194606304168701,
             -3.1113553047180176,
             -3.0121521949768066,
             -2.9317691326141357,
             -2.7981717586517334,
             -2.6364731788635254
            ],
            [
             -4.005749702453613,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 5000"
          }
         },
         "name": "frame_10",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -3.8845856189727783,
             -3.8531253337860107,
             -3.7598423957824707,
             -3.6537866592407227,
             -3.5831010341644287,
             -3.48791766166687,
             -3.35506010055542,
             -3.279310464859009,
             -3.1861400604248047,
             -3.1027653217315674,
             -3.0358681678771973
            ],
            [
             -3.9253509044647217,
             -3.8702287673950195,
             -3.7657742500305176,
             -3.6984736919403076,
             -3.5981318950653076,
             -3.471714973449707,
             -3.3669395446777344,
             -3.2408955097198486,
             -3.1501517295837402,
             -3.058835029602051,
             -2.952361583709717
            ],
            [
             -3.991072654724121,
             -3.882906198501587,
             -3.799297332763672,
             -3.697458028793335,
             -3.5778446197509766,
             -3.4746475219726562,
             -3.3592379093170166,
             -3.235703468322754,
             -3.1265618801116943,
             -2.9911065101623535,
             -2.814030885696411
            ],
            [
             -4.1837849617004395,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 5500"
          }
         },
         "name": "frame_11",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -4.166543483734131,
             -4.101540565490723,
             -4.005729675292969,
             -3.9206628799438477,
             -3.8088932037353516,
             -3.7304470539093018,
             -3.630722999572754,
             -3.5089738368988037,
             -3.420511245727539,
             -3.330793619155884,
             -3.3102827072143555
            ],
            [
             -4.18391227722168,
             -4.081057071685791,
             -3.9833474159240723,
             -3.9039199352264404,
             -3.8184027671813965,
             -3.7285633087158203,
             -3.6205456256866455,
             -3.510019302368164,
             -3.426609992980957,
             -3.299485445022583,
             -3.24015736579895
            ],
            [
             -4.276102542877197,
             -4.134520530700684,
             -3.9929776191711426,
             -3.9119443893432617,
             -3.794919490814209,
             -3.696279764175415,
             -3.6292152404785156,
             -3.499691963195801,
             -3.414390802383423,
             -3.297037124633789,
             -3.1552653312683105
            ],
            [
             -4.468837738037109,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 6000"
          }
         },
         "name": "frame_12",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -4.3000335693359375,
             -4.3022918701171875,
             -4.235111236572266,
             -4.136552333831787,
             -4.049753665924072,
             -3.9380087852478027,
             -3.862332344055176,
             -3.747692584991455,
             -3.6473422050476074,
             -3.6183133125305176,
             -3.567659854888916
            ],
            [
             -4.385976314544678,
             -4.329709053039551,
             -4.258976459503174,
             -4.152092933654785,
             -4.070883274078369,
             -3.969700336456299,
             -3.8588125705718994,
             -3.7554750442504883,
             -3.6662840843200684,
             -3.5775976181030273,
             -3.5065219402313232
            ],
            [
             -4.505280494689941,
             -4.388495922088623,
             -4.290595531463623,
             -4.182743549346924,
             -4.104355335235596,
             -3.975576400756836,
             -3.862565279006958,
             -3.7438294887542725,
             -3.6274759769439697,
             -3.527107000350952,
             -3.4015023708343506
            ],
            [
             -4.686788082122803,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 6500"
          }
         },
         "name": "frame_13",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -4.5793890953063965,
             -4.528433799743652,
             -4.447445869445801,
             -4.360948085784912,
             -4.289042949676514,
             -4.18833589553833,
             -4.070335388183594,
             -4.010439872741699,
             -3.9300050735473633,
             -3.886524200439453,
             -3.8237802982330322
            ],
            [
             -4.583149433135986,
             -4.557430744171143,
             -4.454117774963379,
             -4.378480434417725,
             -4.299557209014893,
             -4.180365562438965,
             -4.10101318359375,
             -4.011396884918213,
             -3.9168403148651123,
             -3.8253207206726074,
             -3.7623908519744873
            ],
            [
             -4.72291374206543,
             -4.5919342041015625,
             -4.481690406799316,
             -4.405294418334961,
             -4.284409999847412,
             -4.175776481628418,
             -4.073506832122803,
             -4.002020835876465,
             -3.8950576782226562,
             -3.7985424995422363,
             -3.6381452083587646
            ],
            [
             -4.938953876495361,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 7000"
          }
         },
         "name": "frame_14",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -4.759535312652588,
             -4.690945148468018,
             -4.633100509643555,
             -4.570493221282959,
             -4.473165512084961,
             -4.400330066680908,
             -4.330488204956055,
             -4.246452331542969,
             -4.198084354400635,
             -4.164407730102539,
             -4.120500087738037
            ],
            [
             -4.785437107086182,
             -4.725555896759033,
             -4.663249969482422,
             -4.570265293121338,
             -4.467055320739746,
             -4.411407947540283,
             -4.330121994018555,
             -4.2427496910095215,
             -4.196847438812256,
             -4.126537322998047,
             -4.056283473968506
            ],
            [
             -4.89911413192749,
             -4.780892848968506,
             -4.663943767547607,
             -4.5419230461120605,
             -4.448727607727051,
             -4.395278453826904,
             -4.298616886138916,
             -4.209252834320068,
             -4.186521053314209,
             -4.066555500030518,
             -3.924481153488159
            ],
            [
             -5.123256683349609,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 7500"
          }
         },
         "name": "frame_15",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -4.947636127471924,
             -4.937699317932129,
             -4.87734842300415,
             -4.796595573425293,
             -4.734560966491699,
             -4.637318134307861,
             -4.545188903808594,
             -4.47003698348999,
             -4.390313625335693,
             -4.339046955108643,
             -4.300926685333252
            ],
            [
             -5.009769916534424,
             -4.964205265045166,
             -4.889535427093506,
             -4.807764053344727,
             -4.7021307945251465,
             -4.6162919998168945,
             -4.531965255737305,
             -4.470328330993652,
             -4.380631446838379,
             -4.297677993774414,
             -4.244278907775879
            ],
            [
             -5.0948028564453125,
             -4.988000869750977,
             -4.888153076171875,
             -4.811390399932861,
             -4.719021320343018,
             -4.621185779571533,
             -4.529138565063477,
             -4.4530720710754395,
             -4.339669227600098,
             -4.247725963592529,
             -4.129631996154785
            ],
            [
             -5.290450096130371,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 8000"
          }
         },
         "name": "frame_16",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -5.146719455718994,
             -5.118343830108643,
             -5.047722339630127,
             -5.0016303062438965,
             -4.935947895050049,
             -4.8435163497924805,
             -4.775310039520264,
             -4.690945148468018,
             -4.581921577453613,
             -4.505542755126953,
             -4.4701948165893555
            ],
            [
             -5.193256378173828,
             -5.141566276550293,
             -5.062867164611816,
             -4.99173641204834,
             -4.944355010986328,
             -4.862723350524902,
             -4.787738800048828,
             -4.670034408569336,
             -4.587680816650391,
             -4.500636577606201,
             -4.415229320526123
            ],
            [
             -5.280587673187256,
             -5.170437335968018,
             -5.101891040802002,
             -5.0256829261779785,
             -4.938556671142578,
             -4.847065448760986,
             -4.7760419845581055,
             -4.6930718421936035,
             -4.573214530944824,
             -4.464950084686279,
             -4.303987979888916
            ],
            [
             -5.465917110443115,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 8500"
          }
         },
         "name": "frame_17",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -5.339326858520508,
             -5.308099746704102,
             -5.242861747741699,
             -5.198585510253906,
             -5.109782695770264,
             -5.051613807678223,
             -4.965762138366699,
             -4.893637657165527,
             -4.819042205810547,
             -4.744035720825195,
             -4.714414119720459
            ],
            [
             -5.404606819152832,
             -5.344746112823486,
             -5.273746967315674,
             -5.200099468231201,
             -5.100444316864014,
             -5.034401893615723,
             -4.956760883331299,
             -4.896700859069824,
             -4.803522109985352,
             -4.6880106925964355,
             -4.635291576385498
            ],
            [
             -5.479563236236572,
             -5.382227420806885,
             -5.29225492477417,
             -5.192918300628662,
             -5.113656044006348,
             -5.019932270050049,
             -4.945718288421631,
             -4.863109588623047,
             -4.768368721008301,
             -4.648913860321045,
             -4.523731708526611
            ],
            [
             -5.654288291931152,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 9000"
          }
         },
         "name": "frame_18",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -5.521661281585693,
             -5.498758316040039,
             -5.4692912101745605,
             -5.386939525604248,
             -5.309814929962158,
             -5.230238914489746,
             -5.150086402893066,
             -5.096240520477295,
             -4.99722957611084,
             -4.951141834259033,
             -4.886002540588379
            ],
            [
             -5.569519519805908,
             -5.501303195953369,
             -5.443072319030762,
             -5.379038333892822,
             -5.315474987030029,
             -5.240116596221924,
             -5.149196624755859,
             -5.075057506561279,
             -5.0023722648620605,
             -4.920801639556885,
             -4.826099872589111
            ],
            [
             -5.657686233520508,
             -5.552605628967285,
             -5.461153984069824,
             -5.390826225280762,
             -5.307046890258789,
             -5.223038196563721,
             -5.13460636138916,
             -5.073558807373047,
             -4.983725547790527,
             -4.864175319671631,
             -4.690945148468018
            ],
            [
             -5.825526714324951,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 9500"
          }
         },
         "name": "frame_19",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -5.723823547363281,
             -5.657686233520508,
             -5.620914459228516,
             -5.5247673988342285,
             -5.462368965148926,
             -5.38778018951416,
             -5.341192245483398,
             -5.261261940002441,
             -5.171077251434326,
             -5.145920276641846,
             -5.098464488983154
            ],
            [
             -5.739781856536865,
             -5.691098690032959,
             -5.626430034637451,
             -5.541801452636719,
             -5.473492622375488,
             -5.416406631469727,
             -5.330857753753662,
             -5.254218101501465,
             -5.166582107543945,
             -5.122165203094482,
             -5.054967880249023
            ],
            [
             -5.828790664672852,
             -5.736593723297119,
             -5.641753673553467,
             -5.552158355712891,
             -5.493661880493164,
             -5.416743278503418,
             -5.341977596282959,
             -5.279049396514893,
             -5.188868045806885,
             -5.0851521492004395,
             -4.929605007171631
            ],
            [
             -5.993153095245361,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 10000"
          }
         },
         "name": "frame_20",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -5.8676371574401855,
             -5.82552433013916,
             -5.769533157348633,
             -5.718674182891846,
             -5.649348258972168,
             -5.569519519805908,
             -5.505540370941162,
             -5.433902263641357,
             -5.3671040534973145,
             -5.289944171905518,
             -5.2465996742248535
            ],
            [
             -5.921553134918213,
             -5.849008083343506,
             -5.802443027496338,
             -5.717643737792969,
             -5.652818202972412,
             -5.582432746887207,
             -5.524399280548096,
             -5.447021961212158,
             -5.361942291259766,
             -5.291089057922363,
             -5.218660831451416
            ],
            [
             -6.015282154083252,
             -5.9098968505859375,
             -5.811644554138184,
             -5.724529266357422,
             -5.647611618041992,
             -5.571424961090088,
             -5.522428512573242,
             -5.462460517883301,
             -5.383318901062012,
             -5.251036643981934,
             -5.150086402893066
            ],
            [
             -6.186546802520752,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 10500"
          }
         },
         "name": "frame_21",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -6.039842128753662,
             -5.993153095245361,
             -5.947634696960449,
             -5.911798000335693,
             -5.828790664672852,
             -5.76451301574707,
             -5.707785606384277,
             -5.613824367523193,
             -5.5390214920043945,
             -5.479563236236572,
             -5.431448936462402
            ],
            [
             -6.067436695098877,
             -6.021620750427246,
             -5.950639724731445,
             -5.892587184906006,
             -5.823920726776123,
             -5.752390384674072,
             -5.690845012664795,
             -5.615623950958252,
             -5.513782978057861,
             -5.452812671661377,
             -5.386037349700928
            ],
            [
             -6.147945880889893,
             -6.042261123657227,
             -5.975493907928467,
             -5.89990234375,
             -5.81849479675293,
             -5.746302604675293,
             -5.678929328918457,
             -5.620074272155762,
             -5.522148609161377,
             -5.419140815734863,
             -5.2896599769592285
            ],
            [
             -6.330631732940674,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 11000"
          }
         },
         "name": "frame_22",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -6.18688440322876,
             -6.17543363571167,
             -6.107313632965088,
             -6.03322172164917,
             -5.993153095245361,
             -5.911798000335693,
             -5.854300498962402,
             -5.786375999450684,
             -5.711615085601807,
             -5.6361236572265625,
             -5.608229160308838
            ],
            [
             -6.240218639373779,
             -6.189896106719971,
             -6.128503322601318,
             -6.042215347290039,
             -5.995750904083252,
             -5.926232814788818,
             -5.8505940437316895,
             -5.781277656555176,
             -5.697127342224121,
             -5.6066765785217285,
             -5.542858600616455
            ],
            [
             -6.318349838256836,
             -6.2006731033325195,
             -6.128375053405762,
             -6.050968647003174,
             -5.99065637588501,
             -5.952565670013428,
             -5.873523712158203,
             -5.778437614440918,
             -5.701938152313232,
             -5.568509101867676,
             -5.41566276550293
            ],
            [
             -6.4757208824157715,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 11500"
          }
         },
         "name": "frame_23",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -6.337136745452881,
             -6.3386359214782715,
             -6.298094272613525,
             -6.227632999420166,
             -6.168208122253418,
             -6.091651439666748,
             -6.001845836639404,
             -5.906033039093018,
             -5.8404741287231445,
             -5.779919147491455,
             -5.741811752319336
            ],
            [
             -6.389890670776367,
             -6.353630542755127,
             -6.294236660003662,
             -6.229881286621094,
             -6.155970096588135,
             -6.086063385009766,
             -5.988490581512451,
             -5.904939651489258,
             -5.849613189697266,
             -5.769613742828369,
             -5.6994853019714355
            ],
            [
             -6.475037574768066,
             -6.3754353523254395,
             -6.307980537414551,
             -6.227851867675781,
             -6.15386438369751,
             -6.053185939788818,
             -5.973443031311035,
             -5.877959251403809,
             -5.808129787445068,
             -5.742852687835693,
             -5.591937065124512
            ],
            [
             -6.619813442230225,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 12000"
          }
         },
         "name": "frame_24",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -6.510885715484619,
             -6.467413425445557,
             -6.408044815063477,
             -6.346787929534912,
             -6.286109447479248,
             -6.222126483917236,
             -6.151038646697998,
             -6.07288932800293,
             -5.999116897583008,
             -5.9526801109313965,
             -5.9345502853393555
            ],
            [
             -6.541848659515381,
             -6.478744029998779,
             -6.415933132171631,
             -6.345719814300537,
             -6.288733959197998,
             -6.220188617706299,
             -6.15113639831543,
             -6.065469741821289,
             -5.988232612609863,
             -5.919916152954102,
             -5.874772548675537
            ],
            [
             -6.622455596923828,
             -6.517817497253418,
             -6.432573318481445,
             -6.35311222076416,
             -6.2980732917785645,
             -6.23337459564209,
             -6.1586713790893555,
             -6.074312210083008,
             -5.994108200073242,
             -5.878343105316162,
             -5.761438369750977
            ],
            [
             -6.784765243530273,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 12500"
          }
         },
         "name": "frame_25",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -6.673564434051514,
             -6.622455596923828,
             -6.5697221755981445,
             -6.496164321899414,
             -6.4125165939331055,
             -6.353733062744141,
             -6.298422336578369,
             -6.214845180511475,
             -6.1476521492004395,
             -6.07288932800293,
             -6.03109073638916
            ],
            [
             -6.689186096191406,
             -6.6358842849731445,
             -6.560387134552002,
             -6.496578216552734,
             -6.419373035430908,
             -6.352616310119629,
             -6.2770891189575195,
             -6.2191162109375,
             -6.15274715423584,
             -6.071932792663574,
             -6.016662120819092
            ],
            [
             -6.770597457885742,
             -6.664200782775879,
             -6.587344169616699,
             -6.50083589553833,
             -6.43013334274292,
             -6.3482513427734375,
             -6.276576042175293,
             -6.212959289550781,
             -6.146465301513672,
             -6.048559188842773,
             -5.911798000335693
            ],
            [
             -6.912140846252441,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 13000"
          }
         },
         "name": "frame_26",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -6.7810797691345215,
             -6.751488208770752,
             -6.708302974700928,
             -6.638528823852539,
             -6.570812702178955,
             -6.494136810302734,
             -6.446713447570801,
             -6.368640899658203,
             -6.297441005706787,
             -6.227632999420166,
             -6.1982102394104
            ],
            [
             -6.818163871765137,
             -6.762972831726074,
             -6.6989593505859375,
             -6.638577938079834,
             -6.577152252197266,
             -6.491405963897705,
             -6.426154613494873,
             -6.363400936126709,
             -6.278326034545898,
             -6.207098007202148,
             -6.149585247039795
            ],
            [
             -6.904704570770264,
             -6.807482719421387,
             -6.731597900390625,
             -6.64158821105957,
             -6.563724994659424,
             -6.492285251617432,
             -6.420907497406006,
             -6.3460259437561035,
             -6.242585182189941,
             -6.144652843475342,
             -6.03322172164917
            ],
            [
             -7.036133289337158,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 13500"
          }
         },
         "name": "frame_27",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -6.912414073944092,
             -6.878968715667725,
             -6.816145420074463,
             -6.769896507263184,
             -6.704280376434326,
             -6.630460739135742,
             -6.562049865722656,
             -6.486783027648926,
             -6.426493167877197,
             -6.360037803649902,
             -6.300717353820801
            ],
            [
             -6.955767631530762,
             -6.903604984283447,
             -6.850339412689209,
             -6.773657321929932,
             -6.70418119430542,
             -6.63054084777832,
             -6.557160377502441,
             -6.4854865074157715,
             -6.4166059494018555,
             -6.340604305267334,
             -6.284541606903076
            ],
            [
             -7.034360885620117,
             -6.92727518081665,
             -6.8424201011657715,
             -6.795900821685791,
             -6.709758758544922,
             -6.63406229019165,
             -6.563999176025391,
             -6.489367485046387,
             -6.396118640899658,
             -6.292505741119385,
             -6.184582233428955
            ],
            [
             -7.1788434982299805,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 14000"
          }
         },
         "name": "frame_28",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -7.063736438751221,
             -7.0129899978637695,
             -6.965704917907715,
             -6.914554595947266,
             -6.81900691986084,
             -6.754174709320068,
             -6.689668655395508,
             -6.607914924621582,
             -6.549858093261719,
             -6.483907699584961,
             -6.446484088897705
            ],
            [
             -7.093338489532471,
             -7.034851551055908,
             -6.95659065246582,
             -6.894675254821777,
             -6.815030574798584,
             -6.7532782554626465,
             -6.698611259460449,
             -6.6254353523254395,
             -6.549596309661865,
             -6.4563093185424805,
             -6.406028747558594
            ],
            [
             -7.1730451583862305,
             -7.059994220733643,
             -6.960369110107422,
             -6.899186611175537,
             -6.812638759613037,
             -6.739288806915283,
             -6.675287246704102,
             -6.6006011962890625,
             -6.5111002922058105,
             -6.428145885467529,
             -6.294110298156738
            ],
            [
             -7.290008544921875,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 14500"
          }
         },
         "name": "frame_29",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -7.155616760253906,
             -7.106125354766846,
             -7.06211519241333,
             -7.006195068359375,
             -6.944350719451904,
             -6.888149738311768,
             -6.828505516052246,
             -6.755544185638428,
             -6.6820831298828125,
             -6.619980335235596,
             -6.575002670288086
            ],
            [
             -7.203105926513672,
             -7.134833335876465,
             -7.085052013397217,
             -7.018278121948242,
             -6.945898056030273,
             -6.890796184539795,
             -6.802404880523682,
             -6.727177143096924,
             -6.652359962463379,
             -6.577818870544434,
             -6.5148138999938965
            ],
            [
             -7.264622688293457,
             -7.174647808074951,
             -7.098241806030273,
             -7.0140252113342285,
             -6.9434919357299805,
             -6.88955545425415,
             -6.808058738708496,
             -6.728745937347412,
             -6.636980056762695,
             -6.54973030090332,
             -6.4125165939331055
            ],
            [
             -7.422825336456299,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 15000"
          }
         },
         "name": "frame_30",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -7.277927875518799,
             -7.23748254776001,
             -7.177879810333252,
             -7.1241631507873535,
             -7.059408664703369,
             -6.9835309982299805,
             -6.914554595947266,
             -6.846209526062012,
             -6.785163879394531,
             -6.722772121429443,
             -6.676701545715332
            ],
            [
             -7.3192033767700195,
             -7.266880989074707,
             -7.1929216384887695,
             -7.134626388549805,
             -7.061973571777344,
             -6.998778343200684,
             -6.926314830780029,
             -6.855725288391113,
             -6.782791614532471,
             -6.715951919555664,
             -6.638176918029785
            ],
            [
             -7.395970344543457,
             -7.297281742095947,
             -7.203510284423828,
             -7.130853176116943,
             -7.064527988433838,
             -7.001753807067871,
             -6.9503068923950195,
             -6.864673137664795,
             -6.78788423538208,
             -6.6937336921691895,
             -6.550107002258301
            ],
            [
             -7.524376392364502,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 15500"
          }
         },
         "name": "frame_31",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -7.3981032371521,
             -7.372873306274414,
             -7.3098063468933105,
             -7.234430313110352,
             -7.165844440460205,
             -7.093888282775879,
             -7.014928817749023,
             -6.958399295806885,
             -6.900222301483154,
             -6.845100402832031,
             -6.818401336669922
            ],
            [
             -7.440900802612305,
             -7.374412536621094,
             -7.3165507316589355,
             -7.245298385620117,
             -7.175581455230713,
             -7.088625907897949,
             -7.02077579498291,
             -6.959951877593994,
             -6.897686004638672,
             -6.821902751922607,
             -6.776740074157715
            ],
            [
             -7.501185417175293,
             -7.401151180267334,
             -7.325769901275635,
             -7.240551948547363,
             -7.174622058868408,
             -7.106852054595947,
             -7.02496862411499,
             -6.949511528015137,
             -6.866795539855957,
             -6.780058860778809,
             -6.656230926513672
            ],
            [
             -7.6219258308410645,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 16000"
          }
         },
         "name": "frame_32",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -7.4855637550354,
             -7.438209056854248,
             -7.3951416015625,
             -7.3580803871154785,
             -7.2915191650390625,
             -7.230445861816406,
             -7.152921676635742,
             -7.073191165924072,
             -7.003562927246094,
             -6.949301719665527,
             -6.912898063659668
            ],
            [
             -7.5251007080078125,
             -7.463106632232666,
             -7.413447856903076,
             -7.3596367835998535,
             -7.290415287017822,
             -7.22652530670166,
             -7.155906677246094,
             -7.077195644378662,
             -7.0074872970581055,
             -6.924172401428223,
             -6.861996173858643
            ],
            [
             -7.595078945159912,
             -7.499297142028809,
             -7.426535606384277,
             -7.366437911987305,
             -7.296408653259277,
             -7.221555233001709,
             -7.138849258422852,
             -7.064671039581299,
             -6.987135410308838,
             -6.900527000427246,
             -6.755544185638428
            ],
            [
             -7.715631484985352,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 16500"
          }
         },
         "name": "frame_33",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -7.571291923522949,
             -7.544557094573975,
             -7.504131317138672,
             -7.450863361358643,
             -7.382052898406982,
             -7.334596633911133,
             -7.255788803100586,
             -7.181392669677734,
             -7.113132953643799,
             -7.057657241821289,
             -7.034542083740234
            ],
            [
             -7.61166524887085,
             -7.568436622619629,
             -7.5117692947387695,
             -7.452969551086426,
             -7.387528896331787,
             -7.328207015991211,
             -7.253244400024414,
             -7.187106609344482,
             -7.113055229187012,
             -7.046027660369873,
             -6.972259998321533
            ],
            [
             -7.691070556640625,
             -7.59731912612915,
             -7.523354530334473,
             -7.464216232299805,
             -7.396570205688477,
             -7.332762718200684,
             -7.249717712402344,
             -7.175315856933594,
             -7.104343414306641,
             -7.011783599853516,
             -6.870274543762207
            ],
            [
             -7.807626724243164,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 17000"
          }
         },
         "name": "frame_34",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -7.703204154968262,
             -7.6713547706604,
             -7.60526180267334,
             -7.551346302032471,
             -7.494311332702637,
             -7.430996417999268,
             -7.346336841583252,
             -7.272732257843018,
             -7.20712423324585,
             -7.1514482498168945,
             -7.102268218994141
            ],
            [
             -7.716299533843994,
             -7.683292865753174,
             -7.608749866485596,
             -7.553734302520752,
             -7.493040084838867,
             -7.425879001617432,
             -7.346161365509033,
             -7.278688430786133,
             -7.200250625610352,
             -7.131478786468506,
             -7.066195487976074
            ],
            [
             -7.785088539123535,
             -7.696317195892334,
             -7.618086814880371,
             -7.559731483459473,
             -7.476326942443848,
             -7.412067413330078,
             -7.341792106628418,
             -7.27028226852417,
             -7.178619384765625,
             -7.098151683807373,
             -6.962024211883545
            ],
            [
             -7.9131903648376465,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 17500"
          }
         },
         "name": "frame_35",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -7.761562347412109,
             -7.730447292327881,
             -7.689696788787842,
             -7.640620708465576,
             -7.584360122680664,
             -7.524975776672363,
             -7.457557201385498,
             -7.375803470611572,
             -7.317174434661865,
             -7.247908592224121,
             -7.198395252227783
            ],
            [
             -7.806286811828613,
             -7.753080368041992,
             -7.702810287475586,
             -7.657342910766602,
             -7.5766801834106445,
             -7.519552230834961,
             -7.461832523345947,
             -7.379547119140625,
             -7.313051700592041,
             -7.232023239135742,
             -7.162217140197754
            ],
            [
             -7.875262260437012,
             -7.787935256958008,
             -7.709812164306641,
             -7.657709121704102,
             -7.596665859222412,
             -7.533401012420654,
             -7.46381950378418,
             -7.381516456604004,
             -7.2920355796813965,
             -7.194995880126953,
             -7.055067539215088
            ],
            [
             -7.995419502258301,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 18000"
          }
         },
         "name": "frame_36",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -7.866243839263916,
             -7.832968711853027,
             -7.782530307769775,
             -7.740517616271973,
             -7.680485248565674,
             -7.604219913482666,
             -7.53165864944458,
             -7.453481197357178,
             -7.391055107116699,
             -7.318145275115967,
             -7.291003227233887
            ],
            [
             -7.902399063110352,
             -7.858180999755859,
             -7.807031631469727,
             -7.7515082359313965,
             -7.689296245574951,
             -7.616105556488037,
             -7.532918453216553,
             -7.4569926261901855,
             -7.390985012054443,
             -7.310248374938965,
             -7.23410701751709
            ],
            [
             -7.976640701293945,
             -7.897577285766602,
             -7.81503438949585,
             -7.74778413772583,
             -7.6907477378845215,
             -7.6226654052734375,
             -7.5403947830200195,
             -7.473265647888184,
             -7.378084659576416,
             -7.2844767570495605,
             -7.134045124053955
            ],
            [
             -8.090352058410645,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 18500"
          }
         },
         "name": "frame_37",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -7.95501184463501,
             -7.930543422698975,
             -7.881899356842041,
             -7.829550266265869,
             -7.773324012756348,
             -7.7052154541015625,
             -7.628283977508545,
             -7.564856052398682,
             -7.474173069000244,
             -7.423820972442627,
             -7.388004779815674
            ],
            [
             -7.989925861358643,
             -7.949587821960449,
             -7.88478946685791,
             -7.827043056488037,
             -7.7594428062438965,
             -7.699574947357178,
             -7.6213765144348145,
             -7.553775787353516,
             -7.477416515350342,
             -7.3944196701049805,
             -7.343094348907471
            ],
            [
             -8.056368827819824,
             -7.97265100479126,
             -7.9050164222717285,
             -7.832770824432373,
             -7.759227275848389,
             -7.692139148712158,
             -7.614012241363525,
             -7.5457763671875,
             -7.460610389709473,
             -7.356835842132568,
             -7.2322468757629395
            ],
            [
             -8.165888786315918,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 19000"
          }
         },
         "name": "frame_38",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.05523681640625,
             -8.01496696472168,
             -7.953841209411621,
             -7.894015312194824,
             -7.839881896972656,
             -7.784547328948975,
             -7.7176947593688965,
             -7.654488563537598,
             -7.573700428009033,
             -7.509363174438477,
             -7.449532985687256
            ],
            [
             -8.076397895812988,
             -8.028572082519531,
             -7.963964462280273,
             -7.904971122741699,
             -7.847254276275635,
             -7.785601615905762,
             -7.712051868438721,
             -7.644627094268799,
             -7.579464912414551,
             -7.49313497543335,
             -7.417982578277588
            ],
            [
             -8.132955551147461,
             -8.046611785888672,
             -7.967164993286133,
             -7.912144184112549,
             -7.846919059753418,
             -7.781267166137695,
             -7.708992004394531,
             -7.641787528991699,
             -7.5515875816345215,
             -7.448093891143799,
             -7.310801029205322
            ],
            [
             -8.239469528198242,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 19500"
          }
         },
         "name": "frame_39",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.112998008728027,
             -8.07614803314209,
             -8.034467697143555,
             -7.989532470703125,
             -7.925081253051758,
             -7.87184476852417,
             -7.803489685058594,
             -7.735763072967529,
             -7.660237789154053,
             -7.596034526824951,
             -7.550031661987305
            ],
            [
             -8.149659156799316,
             -8.09899616241455,
             -8.052573204040527,
             -8.001226425170898,
             -7.930321216583252,
             -7.864145278930664,
             -7.798641204833984,
             -7.723602771759033,
             -7.647948741912842,
             -7.563264846801758,
             -7.5088348388671875
            ],
            [
             -8.202654838562012,
             -8.126179695129395,
             -8.06257152557373,
             -7.995974540710449,
             -7.929720878601074,
             -7.864780426025391,
             -7.797417640686035,
             -7.718315124511719,
             -7.620875835418701,
             -7.51298713684082,
             -7.385866165161133
            ],
            [
             -8.31103229522705,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 20000"
          }
         },
         "name": "frame_40",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.204461097717285,
             -8.170435905456543,
             -8.130526542663574,
             -8.07614803314209,
             -8.008763313293457,
             -7.935052871704102,
             -7.864372730255127,
             -7.8012189865112305,
             -7.734424591064453,
             -7.65979528427124,
             -7.619616508483887
            ],
            [
             -8.222569465637207,
             -8.184807777404785,
             -8.132144927978516,
             -8.076635360717773,
             -8.010234832763672,
             -7.9454169273376465,
             -7.867753982543945,
             -7.792150497436523,
             -7.711671829223633,
             -7.632755279541016,
             -7.568046569824219
            ],
            [
             -8.282899856567383,
             -8.204463958740234,
             -8.149391174316406,
             -8.087969779968262,
             -8.015254974365234,
             -7.946166038513184,
             -7.864321231842041,
             -7.791340351104736,
             -7.696492671966553,
             -7.5979509353637695,
             -7.450901508331299
            ],
            [
             -8.39111614227295,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 20500"
          }
         },
         "name": "frame_41",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.276191711425781,
             -8.242528915405273,
             -8.204133987426758,
             -8.146292686462402,
             -8.086312294006348,
             -8.015182495117188,
             -7.9490065574646,
             -7.871850490570068,
             -7.792901992797852,
             -7.731578826904297,
             -7.693403720855713
            ],
            [
             -8.305357933044434,
             -8.250664710998535,
             -8.201546669006348,
             -8.148829460144043,
             -8.087223052978516,
             -8.018782615661621,
             -7.943826675415039,
             -7.8661417961120605,
             -7.779999732971191,
             -7.704543590545654,
             -7.643182277679443
            ],
            [
             -8.361628532409668,
             -8.282098770141602,
             -8.21583366394043,
             -8.147501945495605,
             -8.089877128601074,
             -8.015626907348633,
             -7.940725803375244,
             -7.857358932495117,
             -7.7707905769348145,
             -7.6738505363464355,
             -7.526612281799316
            ],
            [
             -8.457098960876465,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 21000"
          }
         },
         "name": "frame_42",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.344117164611816,
             -8.30943489074707,
             -8.268386840820312,
             -8.206844329833984,
             -8.14680290222168,
             -8.089815139770508,
             -8.014473915100098,
             -7.945192337036133,
             -7.8706374168396,
             -7.8060479164123535,
             -7.761911869049072
            ],
            [
             -8.374985694885254,
             -8.329561233520508,
             -8.279803276062012,
             -8.222637176513672,
             -8.161334037780762,
             -8.084681510925293,
             -8.009526252746582,
             -7.934674263000488,
             -7.855556011199951,
             -7.780336380004883,
             -7.707604885101318
            ],
            [
             -8.431072235107422,
             -8.354294776916504,
             -8.285887718200684,
             -8.221261024475098,
             -8.16470718383789,
             -8.092419624328613,
             -8.00607967376709,
             -7.925119400024414,
             -7.835873603820801,
             -7.7313337326049805,
             -7.591787338256836
            ],
            [
             -8.527098655700684,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 21500"
          }
         },
         "name": "frame_43",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.40766429901123,
             -8.377260208129883,
             -8.337296485900879,
             -8.277502059936523,
             -8.219682693481445,
             -8.151172637939453,
             -8.07614803314209,
             -8.012222290039062,
             -7.932223796844482,
             -7.87121057510376,
             -7.828385353088379
            ],
            [
             -8.430817604064941,
             -8.38909912109375,
             -8.345614433288574,
             -8.28816032409668,
             -8.223864555358887,
             -8.15737533569336,
             -8.086495399475098,
             -8.006640434265137,
             -7.931911945343018,
             -7.848006248474121,
             -7.781533718109131
            ],
            [
             -8.497156143188477,
             -8.42331600189209,
             -8.352606773376465,
             -8.288517951965332,
             -8.218472480773926,
             -8.152639389038086,
             -8.08217716217041,
             -7.9986796379089355,
             -7.9051127433776855,
             -7.795189380645752,
             -7.661739349365234
            ],
            [
             -8.590535163879395,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 22000"
          }
         },
         "name": "frame_44",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.456609725952148,
             -8.433080673217773,
             -8.392377853393555,
             -8.340523719787598,
             -8.276904106140137,
             -8.206085205078125,
             -8.14811897277832,
             -8.078825950622559,
             -8.00429916381836,
             -7.952908992767334,
             -7.9139556884765625
            ],
            [
             -8.490612983703613,
             -8.456937789916992,
             -8.40833568572998,
             -8.34654712677002,
             -8.287226676940918,
             -8.210606575012207,
             -8.146990776062012,
             -8.068328857421875,
             -7.989044189453125,
             -7.917140483856201,
             -7.848630905151367
            ],
            [
             -8.554276466369629,
             -8.488353729248047,
             -8.424249649047852,
             -8.351747512817383,
             -8.288087844848633,
             -8.221681594848633,
             -8.15097713470459,
             -8.07044506072998,
             -7.977532863616943,
             -7.86751127243042,
             -7.727022171020508
            ],
            [
             -8.655019760131836,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 22500"
          }
         },
         "name": "frame_45",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.546929359436035,
             -8.515246391296387,
             -8.459692001342773,
             -8.40536880493164,
             -8.344799995422363,
             -8.276772499084473,
             -8.220362663269043,
             -8.134956359863281,
             -8.061976432800293,
             -7.991833209991455,
             -7.935924530029297
            ],
            [
             -8.5679349899292,
             -8.523566246032715,
             -8.470948219299316,
             -8.408984184265137,
             -8.347146987915039,
             -8.281731605529785,
             -8.2152681350708,
             -8.137903213500977,
             -8.04943561553955,
             -7.969801902770996,
             -7.891442775726318
            ],
            [
             -8.61894702911377,
             -8.540584564208984,
             -8.47166633605957,
             -8.406020164489746,
             -8.342987060546875,
             -8.280960083007812,
             -8.206750869750977,
             -8.127915382385254,
             -8.03929615020752,
             -7.9315996170043945,
             -7.782000541687012
            ],
            [
             -8.710758209228516,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 23000"
          }
         },
         "name": "frame_46",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.585152626037598,
             -8.55686092376709,
             -8.51540470123291,
             -8.467984199523926,
             -8.407844543457031,
             -8.340417861938477,
             -8.275565147399902,
             -8.187969207763672,
             -8.120268821716309,
             -8.055315017700195,
             -8.016192436218262
            ],
            [
             -8.622194290161133,
             -8.581589698791504,
             -8.52466106414795,
             -8.468881607055664,
             -8.407132148742676,
             -8.335652351379395,
             -8.26909065246582,
             -8.19326400756836,
             -8.117475509643555,
             -8.028122901916504,
             -7.9540696144104
            ],
            [
             -8.673365592956543,
             -8.59932804107666,
             -8.537839889526367,
             -8.474632263183594,
             -8.410341262817383,
             -8.34912395477295,
             -8.276534080505371,
             -8.188399314880371,
             -8.101000785827637,
             -7.982987880706787,
             -7.832404136657715
            ],
            [
             -8.76141357421875,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 23500"
          }
         },
         "name": "frame_47",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.651525497436523,
             -8.61913776397705,
             -8.572298049926758,
             -8.518552780151367,
             -8.457244873046875,
             -8.393839836120605,
             -8.326166152954102,
             -8.257152557373047,
             -8.183748245239258,
             -8.11038875579834,
             -8.055670738220215
            ],
            [
             -8.678077697753906,
             -8.631954193115234,
             -8.57760238647461,
             -8.525233268737793,
             -8.466972351074219,
             -8.400301933288574,
             -8.32834529876709,
             -8.24708366394043,
             -8.163189888000488,
             -8.08078384399414,
             -8.006869316101074
            ],
            [
             -8.734853744506836,
             -8.660688400268555,
             -8.5934419631958,
             -8.533706665039062,
             -8.473776817321777,
             -8.399968147277832,
             -8.328896522521973,
             -8.247167587280273,
             -8.14712142944336,
             -8.037320137023926,
             -7.888939380645752
            ],
            [
             -8.819559097290039,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 24000"
          }
         },
         "name": "frame_48",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.702383041381836,
             -8.671539306640625,
             -8.630125045776367,
             -8.57692813873291,
             -8.518035888671875,
             -8.454530715942383,
             -8.388094902038574,
             -8.320659637451172,
             -8.235041618347168,
             -8.160918235778809,
             -8.113419532775879
            ],
            [
             -8.724283218383789,
             -8.690377235412598,
             -8.637665748596191,
             -8.57749080657959,
             -8.518452644348145,
             -8.45693302154541,
             -8.382116317749023,
             -8.303788185119629,
             -8.215402603149414,
             -8.13037395477295,
             -8.054340362548828
            ],
            [
             -8.78580093383789,
             -8.719961166381836,
             -8.653189659118652,
             -8.585695266723633,
             -8.518118858337402,
             -8.450030326843262,
             -8.379032135009766,
             -8.296674728393555,
             -8.200185775756836,
             -8.082418441772461,
             -7.935924530029297
            ],
            [
             -8.868664741516113,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 24500"
          }
         },
         "name": "frame_49",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.74537181854248,
             -8.71743106842041,
             -8.679153442382812,
             -8.633003234863281,
             -8.573025703430176,
             -8.50295352935791,
             -8.438748359680176,
             -8.36123275756836,
             -8.29322624206543,
             -8.22349739074707,
             -8.169452667236328
            ],
            [
             -8.774552345275879,
             -8.737594604492188,
             -8.688830375671387,
             -8.636778831481934,
             -8.570255279541016,
             -8.501791954040527,
             -8.430469512939453,
             -8.357988357543945,
             -8.27381706237793,
             -8.188006401062012,
             -8.106884956359863
            ],
            [
             -8.833097457885742,
             -8.76675033569336,
             -8.698578834533691,
             -8.63441276550293,
             -8.575570106506348,
             -8.499910354614258,
             -8.427176475524902,
             -8.345913887023926,
             -8.248852729797363,
             -8.135002136230469,
             -7.983142375946045
            ],
            [
             -8.913244247436523,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 25000"
          }
         },
         "name": "frame_50",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.806001663208008,
             -8.77602481842041,
             -8.731992721557617,
             -8.675843238830566,
             -8.622925758361816,
             -8.558387756347656,
             -8.483755111694336,
             -8.406342506408691,
             -8.327191352844238,
             -8.257731437683105,
             -8.201628684997559
            ],
            [
             -8.834155082702637,
             -8.790491104125977,
             -8.741809844970703,
             -8.683757781982422,
             -8.623623847961426,
             -8.551114082336426,
             -8.477828979492188,
             -8.392265319824219,
             -8.312562942504883,
             -8.228750228881836,
             -8.144244194030762
            ],
            [
             -8.889973640441895,
             -8.815574645996094,
             -8.75107192993164,
             -8.685953140258789,
             -8.622223854064941,
             -8.551996231079102,
             -8.47784423828125,
             -8.385805130004883,
             -8.289215087890625,
             -8.173993110656738,
             -8.030474662780762
            ],
            [
             -8.96772289276123,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 25500"
          }
         },
         "name": "frame_51",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.846820831298828,
             -8.82401180267334,
             -8.780293464660645,
             -8.725870132446289,
             -8.659730911254883,
             -8.590093612670898,
             -8.526235580444336,
             -8.457134246826172,
             -8.376875877380371,
             -8.306377410888672,
             -8.252900123596191
            ],
            [
             -8.878137588500977,
             -8.835943222045898,
             -8.790396690368652,
             -8.726600646972656,
             -8.662079811096191,
             -8.597512245178223,
             -8.525752067565918,
             -8.448140144348145,
             -8.364473342895508,
             -8.282276153564453,
             -8.199374198913574
            ],
            [
             -8.935423851013184,
             -8.865200996398926,
             -8.799226760864258,
             -8.735251426696777,
             -8.66572093963623,
             -8.597427368164062,
             -8.523096084594727,
             -8.434221267700195,
             -8.33558464050293,
             -8.218985557556152,
             -8.075928688049316
            ],
            [
             -9.013042449951172,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 26000"
          }
         },
         "name": "frame_52",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.89148235321045,
             -8.865468978881836,
             -8.82182788848877,
             -8.771367073059082,
             -8.70872688293457,
             -8.646097183227539,
             -8.57687759399414,
             -8.502042770385742,
             -8.433662414550781,
             -8.357613563537598,
             -8.299148559570312
            ],
            [
             -8.920470237731934,
             -8.880102157592773,
             -8.831587791442871,
             -8.774147033691406,
             -8.711291313171387,
             -8.641767501831055,
             -8.571622848510742,
             -8.489500999450684,
             -8.409777641296387,
             -8.321206092834473,
             -8.238130569458008
            ],
            [
             -8.977038383483887,
             -8.907116889953613,
             -8.840296745300293,
             -8.774598121643066,
             -8.706292152404785,
             -8.634527206420898,
             -8.561277389526367,
             -8.476242065429688,
             -8.381572723388672,
             -8.260871887207031,
             -8.114432334899902
            ],
            [
             -9.05263614654541,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 26500"
          }
         },
         "name": "frame_53",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.935161590576172,
             -8.908799171447754,
             -8.866691589355469,
             -8.808374404907227,
             -8.749547004699707,
             -8.686309814453125,
             -8.619146347045898,
             -8.543473243713379,
             -8.46915054321289,
             -8.393363952636719,
             -8.341371536254883
            ],
            [
             -8.966166496276855,
             -8.924840927124023,
             -8.876091003417969,
             -8.818902969360352,
             -8.757704734802246,
             -8.687023162841797,
             -8.614357948303223,
             -8.532062530517578,
             -8.444989204406738,
             -8.366753578186035,
             -8.275398254394531
            ],
            [
             -9.01547622680664,
             -8.950867652893066,
             -8.885635375976562,
             -8.824328422546387,
             -8.757761001586914,
             -8.685811996459961,
             -8.603373527526855,
             -8.521288871765137,
             -8.419291496276855,
             -8.300752639770508,
             -8.151955604553223
            ],
            [
             -9.089507102966309,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 27000"
          }
         },
         "name": "frame_54",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.977120399475098,
             -8.947308540344238,
             -8.901866912841797,
             -8.85433578491211,
             -8.799089431762695,
             -8.731379508972168,
             -8.667837142944336,
             -8.584427833557129,
             -8.510465621948242,
             -8.435733795166016,
             -8.37701416015625
            ],
            [
             -9.00069522857666,
             -8.965790748596191,
             -8.912175178527832,
             -8.855896949768066,
             -8.794459342956543,
             -8.725302696228027,
             -8.657368659973145,
             -8.579480171203613,
             -8.493941307067871,
             -8.39819049835205,
             -8.305509567260742
            ],
            [
             -9.049747467041016,
             -8.98798656463623,
             -8.928586959838867,
             -8.863876342773438,
             -8.798248291015625,
             -8.727585792541504,
             -8.646035194396973,
             -8.565951347351074,
             -8.459602355957031,
             -8.335691452026367,
             -8.187463760375977
            ],
            [
             -9.124038696289062,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 27500"
          }
         },
         "name": "frame_55",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.017425537109375,
             -8.988738059997559,
             -8.945138931274414,
             -8.89255428314209,
             -8.835323333740234,
             -8.768745422363281,
             -8.69995403289795,
             -8.622397422790527,
             -8.545434951782227,
             -8.47160530090332,
             -8.409721374511719
            ],
            [
             -9.042689323425293,
             -9.000385284423828,
             -8.953447341918945,
             -8.897271156311035,
             -8.834332466125488,
             -8.768224716186523,
             -8.693317413330078,
             -8.610099792480469,
             -8.52232837677002,
             -8.438911437988281,
             -8.35142993927002
            ],
            [
             -9.092571258544922,
             -9.02624225616455,
             -8.965007781982422,
             -8.902429580688477,
             -8.836882591247559,
             -8.766589164733887,
             -8.687202453613281,
             -8.595388412475586,
             -8.49216079711914,
             -8.368264198303223,
             -8.222929000854492
            ],
            [
             -9.161925315856934,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 28000"
          }
         },
         "name": "frame_56",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.055964469909668,
             -9.026747703552246,
             -8.981325149536133,
             -8.92540454864502,
             -8.870429039001465,
             -8.805498123168945,
             -8.729823112487793,
             -8.656312942504883,
             -8.579215049743652,
             -8.502510070800781,
             -8.448409080505371
            ],
            [
             -9.077108383178711,
             -9.042288780212402,
             -8.99169921875,
             -8.937113761901855,
             -8.8720064163208,
             -8.800549507141113,
             -8.727080345153809,
             -8.647258758544922,
             -8.565372467041016,
             -8.467374801635742,
             -8.383201599121094
            ],
            [
             -9.127982139587402,
             -9.065717697143555,
             -9.002652168273926,
             -8.941433906555176,
             -8.87342643737793,
             -8.802210807800293,
             -8.72203540802002,
             -8.630131721496582,
             -8.522146224975586,
             -8.39822006225586,
             -8.25413990020752
            ],
            [
             -9.195305824279785,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 28500"
          }
         },
         "name": "frame_57",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.084176063537598,
             -9.057085037231445,
             -9.012612342834473,
             -8.964253425598145,
             -8.906655311584473,
             -8.838760375976562,
             -8.767230033874512,
             -8.696582794189453,
             -8.61672306060791,
             -8.54153823852539,
             -8.484029769897461
            ],
            [
             -9.111576080322266,
             -9.073331832885742,
             -9.021602630615234,
             -8.969168663024902,
             -8.910378456115723,
             -8.840860366821289,
             -8.766529083251953,
             -8.683433532714844,
             -8.595480918884277,
             -8.500838279724121,
             -8.4086332321167
            ],
            [
             -9.164041519165039,
             -9.098783493041992,
             -9.03543472290039,
             -8.973812103271484,
             -8.906227111816406,
             -8.834691047668457,
             -8.752436637878418,
             -8.659639358520508,
             -8.556717872619629,
             -8.43012809753418,
             -8.286643028259277
            ],
            [
             -9.227803230285645,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 29000"
          }
         },
         "name": "frame_58",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.120881080627441,
             -9.089593887329102,
             -9.046003341674805,
             -8.995924949645996,
             -8.940134048461914,
             -8.873538970947266,
             -8.800390243530273,
             -8.725052833557129,
             -8.644250869750977,
             -8.571625709533691,
             -8.50278377532959
            ],
            [
             -9.146583557128906,
             -9.102800369262695,
             -9.055612564086914,
             -8.999818801879883,
             -8.942819595336914,
             -8.873387336730957,
             -8.797082901000977,
             -8.717206001281738,
             -8.628071784973145,
             -8.533334732055664,
             -8.440301895141602
            ],
            [
             -9.194746017456055,
             -9.131144523620605,
             -9.068951606750488,
             -9.006351470947266,
             -8.943702697753906,
             -8.86770248413086,
             -8.787781715393066,
             -8.693779945373535,
             -8.586705207824707,
             -8.461739540100098,
             -8.317120552062988
            ],
            [
             -9.258721351623535,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 29500"
          }
         },
         "name": "frame_59",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.146391868591309,
             -9.121333122253418,
             -9.076913833618164,
             -9.025444984436035,
             -8.96749210357666,
             -8.903707504272461,
             -8.8355131149292,
             -8.757620811462402,
             -8.674510955810547,
             -8.597858428955078,
             -8.54427433013916
            ],
            [
             -9.174324035644531,
             -9.137022972106934,
             -9.09048080444336,
             -9.032929420471191,
             -8.966649055480957,
             -8.8988676071167,
             -8.83026123046875,
             -8.742815017700195,
             -8.654062271118164,
             -8.559454917907715,
             -8.465843200683594
            ],
            [
             -9.224725723266602,
             -9.16235065460205,
             -9.103753089904785,
             -9.042935371398926,
             -8.973862648010254,
             -8.899675369262695,
             -8.81725025177002,
             -8.721139907836914,
             -8.616278648376465,
             -8.489948272705078,
             -8.343344688415527
            ],
            [
             -9.287459373474121,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 30000"
          }
         },
         "name": "frame_60",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.179327011108398,
             -9.152000427246094,
             -9.107024192810059,
             -9.0545072555542,
             -8.997843742370605,
             -8.928937911987305,
             -8.858823776245117,
             -8.787803649902344,
             -8.705883979797363,
             -8.629850387573242,
             -8.561779022216797
            ],
            [
             -9.204560279846191,
             -9.168957710266113,
             -9.119274139404297,
             -9.060518264770508,
             -8.99869155883789,
             -8.93166732788086,
             -8.85736083984375,
             -8.773247718811035,
             -8.680882453918457,
             -8.588753700256348,
             -8.49400806427002
            ],
            [
             -9.255110740661621,
             -9.194558143615723,
             -9.131905555725098,
             -9.06982135772705,
             -9.001431465148926,
             -8.925626754760742,
             -8.84325885772705,
             -8.74819278717041,
             -8.64001750946045,
             -8.515804290771484,
             -8.370495796203613
            ],
            [
             -9.315537452697754,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 30500"
          }
         },
         "name": "frame_61",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.20370101928711,
             -9.179068565368652,
             -9.131893157958984,
             -9.081133842468262,
             -9.021208763122559,
             -8.956128120422363,
             -8.887269973754883,
             -8.81192684173584,
             -8.733932495117188,
             -8.656854629516602,
             -8.592289924621582
            ],
            [
             -9.233794212341309,
             -9.19516658782959,
             -9.144453048706055,
             -9.087947845458984,
             -9.026887893676758,
             -8.957731246948242,
             -8.879218101501465,
             -8.800257682800293,
             -8.709991455078125,
             -8.614947319030762,
             -8.52344799041748
            ],
            [
             -9.28138542175293,
             -9.220932960510254,
             -9.16074275970459,
             -9.098657608032227,
             -9.032454490661621,
             -8.956035614013672,
             -8.871134757995605,
             -8.77614974975586,
             -8.666830062866211,
             -8.539283752441406,
             -8.394519805908203
            ],
            [
             -9.34149169921875,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 31000"
          }
         },
         "name": "frame_62",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.227352142333984,
             -9.200949668884277,
             -9.160359382629395,
             -9.1101713180542,
             -9.047669410705566,
             -8.986832618713379,
             -8.915094375610352,
             -8.844120025634766,
             -8.761499404907227,
             -8.684703826904297,
             -8.618451118469238
            ],
            [
             -9.258598327636719,
             -9.221048355102539,
             -9.171381950378418,
             -9.115729331970215,
             -9.050165176391602,
             -8.984915733337402,
             -8.906804084777832,
             -8.820493698120117,
             -8.733242988586426,
             -8.637142181396484,
             -8.5439453125
            ],
            [
             -9.305359840393066,
             -9.246004104614258,
             -9.188000679016113,
             -9.123871803283691,
             -9.055012702941895,
             -8.980204582214355,
             -8.893864631652832,
             -8.79641342163086,
             -8.685851097106934,
             -8.559679985046387,
             -8.417211532592773
            ],
            [
             -9.364581108093262,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 31500"
          }
         },
         "name": "frame_63",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.257798194885254,
             -9.228188514709473,
             -9.183667182922363,
             -9.132972717285156,
             -9.071817398071289,
             -9.00538444519043,
             -8.938614845275879,
             -8.865361213684082,
             -8.78614616394043,
             -8.705056190490723,
             -8.633003234863281
            ],
            [
             -9.283952713012695,
             -9.243844985961914,
             -9.19594669342041,
             -9.13961410522461,
             -9.076939582824707,
             -9.005188941955566,
             -8.92958927154541,
             -8.844977378845215,
             -8.756926536560059,
             -8.66204833984375,
             -8.560797691345215
            ],
            [
             -9.329216003417969,
             -9.270999908447266,
             -9.213899612426758,
             -9.15073013305664,
             -9.08029556274414,
             -9.004081726074219,
             -8.917987823486328,
             -8.819865226745605,
             -8.707799911499023,
             -8.581526756286621,
             -8.438257217407227
            ],
            [
             -9.386883735656738,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 32000"
          }
         },
         "name": "frame_64",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.2798433303833,
             -9.251852989196777,
             -9.209909439086914,
             -9.156731605529785,
             -9.097846984863281,
             -9.032303810119629,
             -8.962510108947754,
             -8.885566711425781,
             -8.807029724121094,
             -8.728485107421875,
             -8.655166625976562
            ],
            [
             -9.307987213134766,
             -9.266796112060547,
             -9.219308853149414,
             -9.162160873413086,
             -9.100112915039062,
             -9.030627250671387,
             -8.953967094421387,
             -8.870063781738281,
             -8.78037166595459,
             -8.680282592773438,
             -8.581925392150879
            ],
            [
             -9.350096702575684,
             -9.294185638427734,
             -9.232583999633789,
             -9.170126914978027,
             -9.099815368652344,
             -9.022472381591797,
             -8.93695068359375,
             -8.838133811950684,
             -8.72626781463623,
             -8.599825859069824,
             -8.457341194152832
            ],
            [
             -9.407005310058594,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 32500"
          }
         },
         "name": "frame_65",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.301177978515625,
             -9.273144721984863,
             -9.227014541625977,
             -9.176993370056152,
             -9.11667251586914,
             -9.051648139953613,
             -8.978583335876465,
             -8.903712272644043,
             -8.825769424438477,
             -8.745453834533691,
             -8.68143081665039
            ],
            [
             -9.327560424804688,
             -9.287680625915527,
             -9.238550186157227,
             -9.1848783493042,
             -9.12145709991455,
             -9.05186653137207,
             -8.97411060333252,
             -8.891721725463867,
             -8.800466537475586,
             -8.6978178024292,
             -8.603271484375
            ],
            [
             -9.372697830200195,
             -9.316779136657715,
             -9.256682395935059,
             -9.1910982131958,
             -9.122304916381836,
             -9.04443073272705,
             -8.956512451171875,
             -8.857202529907227,
             -8.745525360107422,
             -8.619174003601074,
             -8.476808547973633
            ],
            [
             -9.42746353149414,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 33000"
          }
         },
         "name": "frame_66",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.32119369506836,
             -9.288519859313965,
             -9.248785018920898,
             -9.19641399383545,
             -9.136496543884277,
             -9.075336456298828,
             -9.002272605895996,
             -8.92453384399414,
             -8.8513765335083,
             -8.77042007446289,
             -8.699999809265137
            ],
            [
             -9.34626579284668,
             -9.30666446685791,
             -9.257254600524902,
             -9.200782775878906,
             -9.138473510742188,
             -9.06811809539795,
             -8.991575241088867,
             -8.907906532287598,
             -8.818547248840332,
             -8.719864845275879,
             -8.621793746948242
            ],
            [
             -9.391613960266113,
             -9.336094856262207,
             -9.276979446411133,
             -9.2114839553833,
             -9.141692161560059,
             -9.06275463104248,
             -8.974625587463379,
             -8.874317169189453,
             -8.76089859008789,
             -8.633772850036621,
             -8.493852615356445
            ],
            [
             -9.445771217346191,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 33500"
          }
         },
         "name": "frame_67",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.33651065826416,
             -9.3079252243042,
             -9.264898300170898,
             -9.215431213378906,
             -9.15502643585205,
             -9.091851234436035,
             -9.022802352905273,
             -8.94568920135498,
             -8.868608474731445,
             -8.787440299987793,
             -8.72246265411377
            ],
            [
             -9.365850448608398,
             -9.323915481567383,
             -9.275050163269043,
             -9.220227241516113,
             -9.156750679016113,
             -9.087387084960938,
             -9.008633613586426,
             -8.924217224121094,
             -8.834002494812012,
             -8.73567008972168,
             -8.636565208435059
            ],
            [
             -9.409523010253906,
             -9.353006362915039,
             -9.293142318725586,
             -9.227509498596191,
             -9.157166481018066,
             -9.078099250793457,
             -8.9877347946167,
             -8.88846492767334,
             -8.776613235473633,
             -8.650949478149414,
             -8.509926795959473
            ],
            [
             -9.46223258972168,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 34000"
          }
         },
         "name": "frame_68",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.349714279174805,
             -9.322074890136719,
             -9.279526710510254,
             -9.229394912719727,
             -9.170602798461914,
             -9.107498168945312,
             -9.034934043884277,
             -8.959986686706543,
             -8.879922866821289,
             -8.79814624786377,
             -8.725183486938477
            ],
            [
             -9.382373809814453,
             -9.343581199645996,
             -9.292582511901855,
             -9.237141609191895,
             -9.172966003417969,
             -9.101943016052246,
             -9.024749755859375,
             -8.93939208984375,
             -8.84646987915039,
             -8.749333381652832,
             -8.650369644165039
            ],
            [
             -9.4260892868042,
             -9.371729850769043,
             -9.311647415161133,
             -9.247169494628906,
             -9.17437744140625,
             -9.095479011535645,
             -9.005478858947754,
             -8.904803276062012,
             -8.792579650878906,
             -8.666211128234863,
             -8.525004386901855
            ],
            [
             -9.478205680847168,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 34500"
          }
         },
         "name": "frame_69",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.368045806884766,
             -9.340605735778809,
             -9.296991348266602,
             -9.243439674377441,
             -9.184706687927246,
             -9.120125770568848,
             -9.047971725463867,
             -8.973548889160156,
             -8.895264625549316,
             -8.811570167541504,
             -8.744561195373535
            ],
            [
             -9.397018432617188,
             -9.355568885803223,
             -9.305752754211426,
             -9.249820709228516,
             -9.187662124633789,
             -9.117706298828125,
             -9.039268493652344,
             -8.955690383911133,
             -8.863537788391113,
             -8.764265060424805,
             -8.663325309753418
            ],
            [
             -9.440890312194824,
             -9.386046409606934,
             -9.327003479003906,
             -9.262273788452148,
             -9.190266609191895,
             -9.109355926513672,
             -9.01877498626709,
             -8.918338775634766,
             -8.805163383483887,
             -8.679067611694336,
             -8.53783893585205
            ],
            [
             -9.491768836975098,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 35000"
          }
         },
         "name": "frame_70",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.384622573852539,
             -9.351044654846191,
             -9.306418418884277,
             -9.254018783569336,
             -9.19723892211914,
             -9.129966735839844,
             -9.063211441040039,
             -8.98888111114502,
             -8.911890029907227,
             -8.830608367919922,
             -8.760360717773438
            ],
            [
             -9.410719871520996,
             -9.369216918945312,
             -9.319880485534668,
             -9.263400077819824,
             -9.20014476776123,
             -9.129660606384277,
             -9.05271053314209,
             -8.96790599822998,
             -8.87619400024414,
             -8.781797409057617,
             -8.677460670471191
            ],
            [
             -9.454137802124023,
             -9.399721145629883,
             -9.340742111206055,
             -9.274541854858398,
             -9.201462745666504,
             -9.120244979858398,
             -9.030274391174316,
             -8.92889404296875,
             -8.816255569458008,
             -8.690313339233398,
             -8.550206184387207
            ],
            [
             -9.504951477050781,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 35500"
          }
         },
         "name": "frame_71",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.393892288208008,
             -9.362984657287598,
             -9.317591667175293,
             -9.266329765319824,
             -9.209102630615234,
             -9.14413070678711,
             -9.076248168945312,
             -8.99852180480957,
             -8.919743537902832,
             -8.839540481567383,
             -8.768046379089355
            ],
            [
             -9.423322677612305,
             -9.381665229797363,
             -9.3328857421875,
             -9.275683403015137,
             -9.212239265441895,
             -9.14120864868164,
             -9.06528377532959,
             -8.982196807861328,
             -8.88764476776123,
             -8.79043197631836,
             -8.685264587402344
            ],
            [
             -9.466596603393555,
             -9.412057876586914,
             -9.352203369140625,
             -9.286032676696777,
             -9.212850570678711,
             -9.13068675994873,
             -9.040300369262695,
             -8.939265251159668,
             -8.826301574707031,
             -8.700990676879883,
             -8.560986518859863
            ],
            [
             -9.516336441040039,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 36000"
          }
         },
         "name": "frame_72",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.405028343200684,
             -9.374369621276855,
             -9.328471183776855,
             -9.278478622436523,
             -9.221081733703613,
             -9.157383918762207,
             -9.08988094329834,
             -9.012906074523926,
             -8.934016227722168,
             -8.85110855102539,
             -8.784280776977539
            ],
            [
             -9.431909561157227,
             -9.391014099121094,
             -9.341672897338867,
             -9.285384178161621,
             -9.222095489501953,
             -9.15196704864502,
             -9.074174880981445,
             -8.989273071289062,
             -8.898149490356445,
             -8.799016952514648,
             -8.695707321166992
            ],
            [
             -9.47632884979248,
             -9.42183780670166,
             -9.362288475036621,
             -9.296111106872559,
             -9.222512245178223,
             -9.14054012298584,
             -9.049531936645508,
             -8.94818115234375,
             -8.835378646850586,
             -8.709744453430176,
             -8.570276260375977
            ],
            [
             -9.525742530822754,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 36500"
          }
         },
         "name": "frame_73",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.415077209472656,
             -9.381905555725098,
             -9.337275505065918,
             -9.286216735839844,
             -9.22887134552002,
             -9.167664527893066,
             -9.097865104675293,
             -9.022293090820312,
             -8.943962097167969,
             -8.860493659973145,
             -8.787239074707031
            ],
            [
             -9.443283081054688,
             -9.400700569152832,
             -9.349821090698242,
             -9.293911933898926,
             -9.230865478515625,
             -9.15998363494873,
             -9.083983421325684,
             -9.002260208129883,
             -8.909330368041992,
             -8.810304641723633,
             -8.706121444702148
            ],
            [
             -9.484816551208496,
             -9.430648803710938,
             -9.370725631713867,
             -9.304400444030762,
             -9.230581283569336,
             -9.148486137390137,
             -9.057173728942871,
             -8.955955505371094,
             -8.843260765075684,
             -8.717873573303223,
             -8.578399658203125
            ],
            [
             -9.534120559692383,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 37000"
          }
         },
         "name": "frame_74",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.422699928283691,
             -9.3902006149292,
             -9.347525596618652,
             -9.29483699798584,
             -9.239290237426758,
             -9.17544937133789,
             -9.10720157623291,
             -9.032368659973145,
             -8.950401306152344,
             -8.86965560913086,
             -8.793543815612793
            ],
            [
             -9.450289726257324,
             -9.407852172851562,
             -9.356061935424805,
             -9.300156593322754,
             -9.237900733947754,
             -9.168743133544922,
             -9.090730667114258,
             -9.0070219039917,
             -8.915932655334473,
             -8.816758155822754,
             -8.71124267578125
            ],
            [
             -9.49190616607666,
             -9.437952041625977,
             -9.378144264221191,
             -9.311591148376465,
             -9.23759937286377,
             -9.155444145202637,
             -9.064183235168457,
             -8.96273422241211,
             -8.849966049194336,
             -8.724495887756348,
             -8.5851411819458
            ],
            [
             -9.540911674499512,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 37500"
          }
         },
         "name": "frame_75",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.427850723266602,
             -9.396783828735352,
             -9.35153579711914,
             -9.299515724182129,
             -9.241151809692383,
             -9.176252365112305,
             -9.109395027160645,
             -9.034958839416504,
             -8.956014633178711,
             -8.877750396728516,
             -8.806340217590332
            ],
            [
             -9.45530891418457,
             -9.412182807922363,
             -9.362617492675781,
             -9.305874824523926,
             -9.242410659790039,
             -9.172700881958008,
             -9.097475051879883,
             -9.012112617492676,
             -8.919343948364258,
             -8.819110870361328,
             -8.715850830078125
            ],
            [
             -9.497987747192383,
             -9.443967819213867,
             -9.38413143157959,
             -9.317815780639648,
             -9.243823051452637,
             -9.161616325378418,
             -9.070155143737793,
             -8.968600273132324,
             -8.8557767868042,
             -8.730242729187012,
             -8.590808868408203
            ],
            [
             -9.54683780670166,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 38000"
          }
         },
         "name": "frame_76",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.429362297058105,
             -9.398151397705078,
             -9.355981826782227,
             -9.306682586669922,
             -9.248193740844727,
             -9.185256004333496,
             -9.11568832397461,
             -9.043889045715332,
             -8.964864730834961,
             -8.884451866149902,
             -8.810789108276367
            ],
            [
             -9.4602689743042,
             -9.418839454650879,
             -9.36772632598877,
             -9.312174797058105,
             -9.2488431930542,
             -9.181166648864746,
             -9.104138374328613,
             -9.019671440124512,
             -8.926606178283691,
             -8.828340530395508,
             -8.721917152404785
            ],
            [
             -9.502335548400879,
             -9.448384284973145,
             -9.388425827026367,
             -9.321711540222168,
             -9.247519493103027,
             -9.165287971496582,
             -9.073967933654785,
             -8.972492218017578,
             -8.85964298248291,
             -8.734176635742188,
             -8.594772338867188
            ],
            [
             -9.55100154876709,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 38500"
          }
         },
         "name": "frame_77",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.434187889099121,
             -9.400262832641602,
             -9.358491897583008,
             -9.306755065917969,
             -9.24870491027832,
             -9.185256004333496,
             -9.11568832397461,
             -9.043889045715332,
             -8.964864730834961,
             -8.884451866149902,
             -8.810789108276367
            ],
            [
             -9.462499618530273,
             -9.420536994934082,
             -9.371389389038086,
             -9.313353538513184,
             -9.249873161315918,
             -9.182422637939453,
             -9.104310035705566,
             -9.019671440124512,
             -8.928512573242188,
             -8.83047866821289,
             -8.724313735961914
            ],
            [
             -9.505931854248047,
             -9.451972007751465,
             -9.392029762268066,
             -9.325467109680176,
             -9.251449584960938,
             -9.169194221496582,
             -9.077789306640625,
             -8.97616958618164,
             -8.863268852233887,
             -8.73783016204834,
             -8.598443031311035
            ],
            [
             -9.554658889770508,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 39000"
          }
         },
         "name": "frame_78",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.43506908416748,
             -9.405146598815918,
             -9.359221458435059,
             -9.308351516723633,
             -9.251774787902832,
             -9.189054489135742,
             -9.120320320129395,
             -9.045252799987793,
             -8.96645450592041,
             -8.887521743774414,
             -8.810789108276367
            ],
            [
             -9.466070175170898,
             -9.423676490783691,
             -9.374662399291992,
             -9.318062782287598,
             -9.255640983581543,
             -9.18483829498291,
             -9.10859203338623,
             -9.024231910705566,
             -8.932299613952637,
             -8.833907127380371,
             -8.727577209472656
            ],
            [
             -9.508495330810547,
             -9.45450496673584,
             -9.394514083862305,
             -9.32785701751709,
             -9.253801345825195,
             -9.17153549194336,
             -9.0801420211792,
             -8.978584289550781,
             -8.86571979522705,
             -8.740294456481934,
             -8.600859642028809
            ],
            [
             -9.557100296020508,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 39500"
          }
         },
         "name": "frame_79",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.437302589416504,
             -9.405611991882324,
             -9.361382484436035,
             -9.312026023864746,
             -9.255692481994629,
             -9.189072608947754,
             -9.12439250946045,
             -9.047603607177734,
             -8.972028732299805,
             -8.891740798950195,
             -8.811644554138184
            ],
            [
             -9.468619346618652,
             -9.426836013793945,
             -9.376348495483398,
             -9.32040786743164,
             -9.256711959838867,
             -9.1859130859375,
             -9.11042308807373,
             -9.027207374572754,
             -8.935833930969238,
             -8.836847305297852,
             -8.730183601379395
            ],
            [
             -9.51019287109375,
             -9.456191062927246,
             -9.396223068237305,
             -9.329607963562012,
             -9.255582809448242,
             -9.173301696777344,
             -9.081869125366211,
             -8.980279922485352,
             -8.867409706115723,
             -8.74199104309082,
             -8.602614402770996
            ],
            [
             -9.55885124206543,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 40000"
          }
         },
         "name": "frame_80",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.440718650817871,
             -9.40626049041748,
             -9.361382484436035,
             -9.312026023864746,
             -9.255692481994629,
             -9.189072608947754,
             -9.12526798248291,
             -9.051270484924316,
             -8.972066879272461,
             -8.892306327819824,
             -8.819389343261719
            ],
            [
             -9.469289779663086,
             -9.427772521972656,
             -9.377874374389648,
             -9.320828437805176,
             -9.257268905639648,
             -9.188494682312012,
             -9.111236572265625,
             -9.027207374572754,
             -8.937566757202148,
             -8.838408470153809,
             -8.732531547546387
            ],
            [
             -9.511519432067871,
             -9.45753288269043,
             -9.397539138793945,
             -9.330854415893555,
             -9.256799697875977,
             -9.174511909484863,
             -9.08306884765625,
             -8.981475830078125,
             -8.868595123291016,
             -8.743172645568848,
             -8.603819847106934
            ],
            [
             -9.560101509094238,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 40500"
          }
         },
         "name": "frame_81",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.440718650817871,
             -9.40626049041748,
             -9.361382484436035,
             -9.312026023864746,
             -9.255692481994629,
             -9.189072608947754,
             -9.12526798248291,
             -9.051270484924316,
             -8.972066879272461,
             -8.892306327819824,
             -8.819389343261719
            ],
            [
             -9.469491004943848,
             -9.427772521972656,
             -9.377874374389648,
             -9.320828437805176,
             -9.257268905639648,
             -9.189566612243652,
             -9.113871574401855,
             -9.0299711227417,
             -8.9392671585083,
             -8.8389892578125,
             -8.732531547546387
            ],
            [
             -9.512368202209473,
             -9.45837688446045,
             -9.398386001586914,
             -9.33172607421875,
             -9.257654190063477,
             -9.175355911254883,
             -9.0839262008667,
             -8.982344627380371,
             -8.86949348449707,
             -8.74406623840332,
             -8.60470962524414
            ],
            [
             -9.56096076965332,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 41000"
          }
         },
         "name": "frame_82",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.440718650817871,
             -9.40878963470459,
             -9.364657402038574,
             -9.313797950744629,
             -9.257140159606934,
             -9.192817687988281,
             -9.12526798248291,
             -9.052170753479004,
             -8.975082397460938,
             -8.892306327819824,
             -8.819389343261719
            ],
            [
             -9.4710693359375,
             -9.429281234741211,
             -9.378113746643066,
             -9.321471214294434,
             -9.259076118469238,
             -9.191405296325684,
             -9.116539001464844,
             -9.033426284790039,
             -8.94299602508545,
             -8.841506958007812,
             -8.733824729919434
            ],
            [
             -9.512908935546875,
             -9.458908081054688,
             -9.398927688598633,
             -9.33227252960205,
             -9.258213996887207,
             -9.17592716217041,
             -9.084486961364746,
             -8.982901573181152,
             -8.870028495788574,
             -8.744612693786621,
             -8.605256080627441
            ],
            [
             -9.561519622802734,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 41500"
          }
         },
         "name": "frame_83",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.440718650817871,
             -9.40878963470459,
             -9.364657402038574,
             -9.313797950744629,
             -9.257140159606934,
             -9.196690559387207,
             -9.12830924987793,
             -9.05471134185791,
             -8.976790428161621,
             -8.896141052246094,
             -8.823528289794922
            ],
            [
             -9.4710693359375,
             -9.429281234741211,
             -9.37923526763916,
             -9.321722984313965,
             -9.259610176086426,
             -9.191866874694824,
             -9.116539001464844,
             -9.034052848815918,
             -8.943899154663086,
             -8.841506958007812,
             -8.735776901245117
            ],
            [
             -9.513301849365234,
             -9.459304809570312,
             -9.399316787719727,
             -9.33266544342041,
             -9.258607864379883,
             -9.176319122314453,
             -9.08488655090332,
             -8.983294486999512,
             -8.870412826538086,
             -8.744985580444336,
             -8.605623245239258
            ],
            [
             -9.56189250946045,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 42000"
          }
         },
         "name": "frame_84",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.440718650817871,
             -9.40878963470459,
             -9.366436958312988,
             -9.314596176147461,
             -9.257196426391602,
             -9.197181701660156,
             -9.128487586975098,
             -9.057127952575684,
             -8.97947883605957,
             -8.896960258483887,
             -8.823528289794922
            ],
            [
             -9.471115112304688,
             -9.43020248413086,
             -9.380267143249512,
             -9.322641372680664,
             -9.259610176086426,
             -9.191866874694824,
             -9.116539001464844,
             -9.034052848815918,
             -8.944337844848633,
             -8.842949867248535,
             -8.735776901245117
            ],
            [
             -9.513567924499512,
             -9.459572792053223,
             -9.399584770202637,
             -9.332930564880371,
             -9.258868217468262,
             -9.176576614379883,
             -9.085142135620117,
             -8.983548164367676,
             -8.870660781860352,
             -8.745240211486816,
             -8.605886459350586
            ],
            [
             -9.56216049194336,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 42500"
          }
         },
         "name": "frame_85",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.440718650817871,
             -9.40878963470459,
             -9.366436958312988,
             -9.314596176147461,
             -9.257196426391602,
             -9.197181701660156,
             -9.128487586975098,
             -9.057127952575684,
             -8.97947883605957,
             -8.896960258483887,
             -8.823528289794922
            ],
            [
             -9.471115112304688,
             -9.43020248413086,
             -9.380267143249512,
             -9.32435417175293,
             -9.26162338256836,
             -9.19230842590332,
             -9.116539001464844,
             -9.034052848815918,
             -8.944337844848633,
             -8.842949867248535,
             -8.735776901245117
            ],
            [
             -9.513741493225098,
             -9.459748268127441,
             -9.399757385253906,
             -9.333100318908691,
             -9.259038925170898,
             -9.176749229431152,
             -9.08531665802002,
             -8.983721733093262,
             -8.870842933654785,
             -8.745421409606934,
             -8.606064796447754
            ],
            [
             -9.562335968017578,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 43000"
          }
         },
         "name": "frame_86",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.440718650817871,
             -9.40878963470459,
             -9.366436958312988,
             -9.314596176147461,
             -9.257196426391602,
             -9.197181701660156,
             -9.128487586975098,
             -9.057127952575684,
             -8.97947883605957,
             -8.896960258483887,
             -8.823528289794922
            ],
            [
             -9.471115112304688,
             -9.43020248413086,
             -9.380267143249512,
             -9.32435417175293,
             -9.26162338256836,
             -9.19230842590332,
             -9.116539001464844,
             -9.034052848815918,
             -8.944337844848633,
             -8.842949867248535,
             -8.735776901245117
            ],
            [
             -9.5138578414917,
             -9.459868431091309,
             -9.399879455566406,
             -9.333224296569824,
             -9.259160995483398,
             -9.176871299743652,
             -9.08543586730957,
             -8.983843803405762,
             -8.870963096618652,
             -8.745539665222168,
             -8.606180191040039
            ],
            [
             -9.56244945526123,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 43500"
          }
         },
         "name": "frame_87",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.444581985473633,
             -9.410889625549316,
             -9.367768287658691,
             -9.315180778503418,
             -9.257196426391602,
             -9.197181701660156,
             -9.128487586975098,
             -9.057127952575684,
             -8.97947883605957,
             -8.896960258483887,
             -8.823528289794922
            ],
            [
             -9.4725980758667,
             -9.43020248413086,
             -9.38099193572998,
             -9.326931953430176,
             -9.263656616210938,
             -9.194742202758789,
             -9.117949485778809,
             -9.034953117370605,
             -8.944337844848633,
             -8.842949867248535,
             -8.735776901245117
            ],
            [
             -9.513935089111328,
             -9.459943771362305,
             -9.399951934814453,
             -9.333295822143555,
             -9.259233474731445,
             -9.176944732666016,
             -9.085514068603516,
             -8.983922004699707,
             -8.871040344238281,
             -8.74561595916748,
             -8.606257438659668
            ],
            [
             -9.562528610229492,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 44000"
          }
         },
         "name": "frame_88",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.444581985473633,
             -9.410889625549316,
             -9.368924140930176,
             -9.318785667419434,
             -9.259257316589355,
             -9.199580192565918,
             -9.1303071975708,
             -9.057127952575684,
             -8.97947883605957,
             -8.896960258483887,
             -8.823528289794922
            ],
            [
             -9.473196029663086,
             -9.431558609008789,
             -9.38147258758545,
             -9.327792167663574,
             -9.26391315460205,
             -9.194742202758789,
             -9.118631362915039,
             -9.03787612915039,
             -8.947017669677734,
             -8.844874382019043,
             -8.736763954162598
            ],
            [
             -9.513978004455566,
             -9.459986686706543,
             -9.39999771118164,
             -9.333341598510742,
             -9.25928020477295,
             -9.176990509033203,
             -9.085556983947754,
             -8.983963012695312,
             -8.871081352233887,
             -8.745658874511719,
             -8.606300354003906
            ],
            [
             -9.562569618225098,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 44500"
          }
         },
         "name": "frame_89",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.444581985473633,
             -9.413935661315918,
             -9.370662689208984,
             -9.320240020751953,
             -9.262828826904297,
             -9.19984245300293,
             -9.1303071975708,
             -9.057127952575684,
             -8.97947883605957,
             -8.896960258483887,
             -8.823528289794922
            ],
            [
             -9.473196029663086,
             -9.43172550201416,
             -9.38147258758545,
             -9.327792167663574,
             -9.26391315460205,
             -9.197087287902832,
             -9.120575904846191,
             -9.039194107055664,
             -8.947924613952637,
             -8.844874382019043,
             -8.736763954162598
            ],
            [
             -9.514017105102539,
             -9.4600248336792,
             -9.400035858154297,
             -9.333379745483398,
             -9.259317398071289,
             -9.177027702331543,
             -9.08559513092041,
             -8.984001159667969,
             -8.871119499206543,
             -8.745697021484375,
             -8.606338500976562
            ],
            [
             -9.56260871887207,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 45000"
          }
         },
         "name": "frame_90",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.445144653320312,
             -9.413935661315918,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.202174186706543,
             -9.134615898132324,
             -9.061598777770996,
             -8.9833984375,
             -8.899798393249512,
             -8.823528289794922
            ],
            [
             -9.475528717041016,
             -9.43288516998291,
             -9.382842063903809,
             -9.328608512878418,
             -9.265259742736816,
             -9.198230743408203,
             -9.120779037475586,
             -9.03931999206543,
             -8.94917106628418,
             -8.847084045410156,
             -8.738465309143066
            ],
            [
             -9.514041900634766,
             -9.460051536560059,
             -9.400062561035156,
             -9.333407402038574,
             -9.259346008300781,
             -9.177055358886719,
             -9.085622787475586,
             -8.984029769897461,
             -8.871149063110352,
             -8.745725631713867,
             -8.606366157531738
            ],
            [
             -9.562633514404297,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 45500"
          }
         },
         "name": "frame_91",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.445144653320312,
             -9.413935661315918,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.202174186706543,
             -9.134615898132324,
             -9.061598777770996,
             -8.9833984375,
             -8.899798393249512,
             -8.823528289794922
            ],
            [
             -9.476313591003418,
             -9.434052467346191,
             -9.384132385253906,
             -9.328981399536133,
             -9.265259742736816,
             -9.198230743408203,
             -9.120779037475586,
             -9.03931999206543,
             -8.94917106628418,
             -8.847084045410156,
             -8.738465309143066
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 46000"
          }
         },
         "name": "frame_92",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.445144653320312,
             -9.413935661315918,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.202174186706543,
             -9.134615898132324,
             -9.061598777770996,
             -8.9833984375,
             -8.899798393249512,
             -8.823528289794922
            ],
            [
             -9.476313591003418,
             -9.434052467346191,
             -9.384132385253906,
             -9.329957008361816,
             -9.26657485961914,
             -9.19858455657959,
             -9.12224006652832,
             -9.040813446044922,
             -8.950491905212402,
             -8.848362922668457,
             -8.739192008972168
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 46500"
          }
         },
         "name": "frame_93",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.445144653320312,
             -9.413935661315918,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.202174186706543,
             -9.134615898132324,
             -9.061598777770996,
             -8.9833984375,
             -8.899798393249512,
             -8.823528289794922
            ],
            [
             -9.476313591003418,
             -9.434052467346191,
             -9.384132385253906,
             -9.329957008361816,
             -9.26657485961914,
             -9.19858455657959,
             -9.12224006652832,
             -9.040813446044922,
             -8.950491905212402,
             -8.848362922668457,
             -8.739192008972168
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 47000"
          }
         },
         "name": "frame_94",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.202174186706543,
             -9.134615898132324,
             -9.061598777770996,
             -8.9833984375,
             -8.899798393249512,
             -8.823528289794922
            ],
            [
             -9.476935386657715,
             -9.435218811035156,
             -9.385415077209473,
             -9.330952644348145,
             -9.267789840698242,
             -9.199277877807617,
             -9.12224006652832,
             -9.040813446044922,
             -8.950491905212402,
             -8.849491119384766,
             -8.739846229553223
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 47500"
          }
         },
         "name": "frame_95",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.202174186706543,
             -9.134615898132324,
             -9.061598777770996,
             -8.9833984375,
             -8.899798393249512,
             -8.823528289794922
            ],
            [
             -9.476935386657715,
             -9.435218811035156,
             -9.385415077209473,
             -9.331958770751953,
             -9.268945693969727,
             -9.199618339538574,
             -9.123019218444824,
             -9.04158878326416,
             -8.950716018676758,
             -8.850053787231445,
             -8.739846229553223
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 48000"
          }
         },
         "name": "frame_96",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.202174186706543,
             -9.134615898132324,
             -9.061598777770996,
             -8.9833984375,
             -8.899798393249512,
             -8.823528289794922
            ],
            [
             -9.476935386657715,
             -9.435218811035156,
             -9.385415077209473,
             -9.331958770751953,
             -9.268945693969727,
             -9.199618339538574,
             -9.123019218444824,
             -9.04158878326416,
             -8.950716018676758,
             -8.850053787231445,
             -8.739846229553223
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 48500"
          }
         },
         "name": "frame_97",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.202174186706543,
             -9.134615898132324,
             -9.061598777770996,
             -8.9833984375,
             -8.899798393249512,
             -8.823528289794922
            ],
            [
             -9.476935386657715,
             -9.435218811035156,
             -9.385415077209473,
             -9.331958770751953,
             -9.268945693969727,
             -9.199618339538574,
             -9.123019218444824,
             -9.04158878326416,
             -8.950716018676758,
             -8.850053787231445,
             -8.739846229553223
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 49000"
          }
         },
         "name": "frame_98",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.204071998596191,
             -9.136697769165039,
             -9.061897277832031,
             -8.9833984375,
             -8.899798393249512,
             -8.823528289794922
            ],
            [
             -9.476935386657715,
             -9.435218811035156,
             -9.385415077209473,
             -9.332967758178711,
             -9.27001667022705,
             -9.20035171508789,
             -9.123689651489258,
             -9.04158878326416,
             -8.951896667480469,
             -8.850053787231445,
             -8.739846229553223
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 49500"
          }
         },
         "name": "frame_99",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.204071998596191,
             -9.136697769165039,
             -9.061897277832031,
             -8.9833984375,
             -8.899798393249512,
             -8.823528289794922
            ],
            [
             -9.476935386657715,
             -9.435218811035156,
             -9.385415077209473,
             -9.332967758178711,
             -9.27001667022705,
             -9.20035171508789,
             -9.123689651489258,
             -9.04158878326416,
             -8.951896667480469,
             -8.850053787231445,
             -8.739846229553223
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 50000"
          }
         },
         "name": "frame_100",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.204071998596191,
             -9.136697769165039,
             -9.061897277832031,
             -8.9833984375,
             -8.899798393249512,
             -8.823528289794922
            ],
            [
             -9.476935386657715,
             -9.435218811035156,
             -9.385415077209473,
             -9.332967758178711,
             -9.27001667022705,
             -9.20035171508789,
             -9.123689651489258,
             -9.04158878326416,
             -8.951896667480469,
             -8.850053787231445,
             -8.740434646606445
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 50500"
          }
         },
         "name": "frame_101",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.204071998596191,
             -9.136697769165039,
             -9.064213752746582,
             -8.986040115356445,
             -8.907997131347656,
             -8.831192970275879
            ],
            [
             -9.476935386657715,
             -9.435218811035156,
             -9.385415077209473,
             -9.332967758178711,
             -9.27001667022705,
             -9.20035171508789,
             -9.123689651489258,
             -9.042145729064941,
             -8.951896667480469,
             -8.85168743133545,
             -8.740964889526367
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 51000"
          }
         },
         "name": "frame_102",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.204071998596191,
             -9.136697769165039,
             -9.064213752746582,
             -8.986040115356445,
             -8.907997131347656,
             -8.831192970275879
            ],
            [
             -9.476935386657715,
             -9.435218811035156,
             -9.385415077209473,
             -9.332967758178711,
             -9.27001667022705,
             -9.20035171508789,
             -9.123689651489258,
             -9.042145729064941,
             -8.951896667480469,
             -8.85168743133545,
             -8.740964889526367
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 51500"
          }
         },
         "name": "frame_103",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.204071998596191,
             -9.136697769165039,
             -9.064213752746582,
             -8.986040115356445,
             -8.907997131347656,
             -8.831192970275879
            ],
            [
             -9.476935386657715,
             -9.435218811035156,
             -9.385415077209473,
             -9.332967758178711,
             -9.27001667022705,
             -9.201578140258789,
             -9.126547813415527,
             -9.043834686279297,
             -8.954048156738281,
             -8.855362892150879,
             -8.742257118225098
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 52000"
          }
         },
         "name": "frame_104",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.204071998596191,
             -9.136697769165039,
             -9.064213752746582,
             -8.986040115356445,
             -8.907997131347656,
             -8.831192970275879
            ],
            [
             -9.476935386657715,
             -9.435382843017578,
             -9.38598918914795,
             -9.333834648132324,
             -9.271157264709473,
             -9.20280933380127,
             -9.127838134765625,
             -9.045162200927734,
             -8.954048156738281,
             -8.855362892150879,
             -8.742257118225098
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 52500"
          }
         },
         "name": "frame_105",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.204071998596191,
             -9.136697769165039,
             -9.064213752746582,
             -8.986040115356445,
             -8.907997131347656,
             -8.831192970275879
            ],
            [
             -9.476935386657715,
             -9.435382843017578,
             -9.385992050170898,
             -9.333834648132324,
             -9.271157264709473,
             -9.20280933380127,
             -9.127838134765625,
             -9.046510696411133,
             -8.955061912536621,
             -8.855362892150879,
             -8.742257118225098
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 53000"
          }
         },
         "name": "frame_106",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.204071998596191,
             -9.136697769165039,
             -9.064213752746582,
             -8.986040115356445,
             -8.907997131347656,
             -8.831192970275879
            ],
            [
             -9.476935386657715,
             -9.435382843017578,
             -9.385992050170898,
             -9.333834648132324,
             -9.271157264709473,
             -9.20280933380127,
             -9.127838134765625,
             -9.046510696411133,
             -8.955061912536621,
             -8.855362892150879,
             -8.742257118225098
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 53500"
          }
         },
         "name": "frame_107",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.204071998596191,
             -9.136697769165039,
             -9.064213752746582,
             -8.986040115356445,
             -8.907997131347656,
             -8.831192970275879
            ],
            [
             -9.476935386657715,
             -9.435382843017578,
             -9.385992050170898,
             -9.333834648132324,
             -9.271157264709473,
             -9.20280933380127,
             -9.127838134765625,
             -9.046510696411133,
             -8.955061912536621,
             -8.855362892150879,
             -8.742257118225098
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 54000"
          }
         },
         "name": "frame_108",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.204071998596191,
             -9.136697769165039,
             -9.064213752746582,
             -8.986040115356445,
             -8.907997131347656,
             -8.831192970275879
            ],
            [
             -9.476935386657715,
             -9.435382843017578,
             -9.385992050170898,
             -9.333834648132324,
             -9.271916389465332,
             -9.203763961791992,
             -9.128423690795898,
             -9.047815322875977,
             -8.956538200378418,
             -8.855921745300293,
             -8.742257118225098
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 54500"
          }
         },
         "name": "frame_109",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.204071998596191,
             -9.136697769165039,
             -9.064213752746582,
             -8.986040115356445,
             -8.907997131347656,
             -8.831192970275879
            ],
            [
             -9.476935386657715,
             -9.435382843017578,
             -9.385992050170898,
             -9.333834648132324,
             -9.271916389465332,
             -9.203763961791992,
             -9.128423690795898,
             -9.047815322875977,
             -8.956538200378418,
             -8.855921745300293,
             -8.742257118225098
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 55000"
          }
         },
         "name": "frame_110",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.44544792175293,
             -9.414636611938477,
             -9.370662689208984,
             -9.321870803833008,
             -9.266103744506836,
             -9.204071998596191,
             -9.136697769165039,
             -9.064213752746582,
             -8.986040115356445,
             -8.907997131347656,
             -8.831192970275879
            ],
            [
             -9.476935386657715,
             -9.435382843017578,
             -9.385992050170898,
             -9.333834648132324,
             -9.271916389465332,
             -9.203763961791992,
             -9.128423690795898,
             -9.048014640808105,
             -8.95690631866455,
             -8.856942176818848,
             -8.74260425567627
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 55500"
          }
         },
         "name": "frame_111",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.373230934143066,
             -9.323633193969727,
             -9.269542694091797,
             -9.207148551940918,
             -9.13900375366211,
             -9.066535949707031,
             -8.986405372619629,
             -8.909655570983887,
             -8.834908485412598
            ],
            [
             -9.476935386657715,
             -9.436384201049805,
             -9.387128829956055,
             -9.335047721862793,
             -9.272294044494629,
             -9.203763961791992,
             -9.128423690795898,
             -9.049121856689453,
             -8.95690631866455,
             -8.856942176818848,
             -8.74291706085205
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 56000"
          }
         },
         "name": "frame_112",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.373230934143066,
             -9.323633193969727,
             -9.269542694091797,
             -9.207148551940918,
             -9.13900375366211,
             -9.066535949707031,
             -8.986405372619629,
             -8.909655570983887,
             -8.834908485412598
            ],
            [
             -9.476935386657715,
             -9.436384201049805,
             -9.387128829956055,
             -9.335047721862793,
             -9.272294044494629,
             -9.203763961791992,
             -9.128423690795898,
             -9.049121856689453,
             -8.95690631866455,
             -8.856942176818848,
             -8.74319839477539
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 56500"
          }
         },
         "name": "frame_113",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.373230934143066,
             -9.323633193969727,
             -9.269542694091797,
             -9.207148551940918,
             -9.13900375366211,
             -9.066535949707031,
             -8.987022399902344,
             -8.909655570983887,
             -8.834908485412598
            ],
            [
             -9.478464126586914,
             -9.438767433166504,
             -9.389535903930664,
             -9.33604907989502,
             -9.27340316772461,
             -9.204033851623535,
             -9.128423690795898,
             -9.050331115722656,
             -8.957917213439941,
             -8.856942176818848,
             -8.74319839477539
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 57000"
          }
         },
         "name": "frame_114",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.373230934143066,
             -9.323633193969727,
             -9.269542694091797,
             -9.207148551940918,
             -9.13900375366211,
             -9.066535949707031,
             -8.987022399902344,
             -8.909655570983887,
             -8.834908485412598
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.390752792358398,
             -9.336142539978027,
             -9.274425506591797,
             -9.20466136932373,
             -9.129240036010742,
             -9.050331115722656,
             -8.959250450134277,
             -8.857132911682129,
             -8.74319839477539
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 57500"
          }
         },
         "name": "frame_115",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.373230934143066,
             -9.323633193969727,
             -9.269542694091797,
             -9.207148551940918,
             -9.13900375366211,
             -9.066535949707031,
             -8.987022399902344,
             -8.909655570983887,
             -8.834908485412598
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.390752792358398,
             -9.336142539978027,
             -9.274425506591797,
             -9.20466136932373,
             -9.129240036010742,
             -9.050331115722656,
             -8.959250450134277,
             -8.857132911682129,
             -8.743452072143555
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 58000"
          }
         },
         "name": "frame_116",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.373230934143066,
             -9.323633193969727,
             -9.269542694091797,
             -9.207148551940918,
             -9.13900375366211,
             -9.066535949707031,
             -8.987022399902344,
             -8.909655570983887,
             -8.834908485412598
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.390752792358398,
             -9.336142539978027,
             -9.274425506591797,
             -9.20466136932373,
             -9.129240036010742,
             -9.050331115722656,
             -8.959250450134277,
             -8.857132911682129,
             -8.743452072143555
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 58500"
          }
         },
         "name": "frame_117",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.373230934143066,
             -9.323633193969727,
             -9.269542694091797,
             -9.207148551940918,
             -9.13900375366211,
             -9.066535949707031,
             -8.987022399902344,
             -8.909655570983887,
             -8.834908485412598
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.390752792358398,
             -9.336142539978027,
             -9.274425506591797,
             -9.20466136932373,
             -9.129240036010742,
             -9.050331115722656,
             -8.959250450134277,
             -8.857132911682129,
             -8.743452072143555
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 59000"
          }
         },
         "name": "frame_118",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.373230934143066,
             -9.323633193969727,
             -9.269542694091797,
             -9.207148551940918,
             -9.13900375366211,
             -9.066535949707031,
             -8.987022399902344,
             -8.909655570983887,
             -8.834908485412598
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.390752792358398,
             -9.336142539978027,
             -9.274425506591797,
             -9.20466136932373,
             -9.129240036010742,
             -9.050331115722656,
             -8.959250450134277,
             -8.857132911682129,
             -8.743452072143555
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 59500"
          }
         },
         "name": "frame_119",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.373230934143066,
             -9.323633193969727,
             -9.269542694091797,
             -9.207148551940918,
             -9.13900375366211,
             -9.066535949707031,
             -8.987022399902344,
             -8.909655570983887,
             -8.834908485412598
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.390752792358398,
             -9.336142539978027,
             -9.275402069091797,
             -9.205188751220703,
             -9.129240036010742,
             -9.050331115722656,
             -8.959746360778809,
             -8.858330726623535,
             -8.743680000305176
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 60000"
          }
         },
         "name": "frame_120",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.373230934143066,
             -9.323633193969727,
             -9.269542694091797,
             -9.207148551940918,
             -9.13900375366211,
             -9.066535949707031,
             -8.987022399902344,
             -8.909655570983887,
             -8.834908485412598
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.390752792358398,
             -9.336142539978027,
             -9.275402069091797,
             -9.20630168914795,
             -9.13024616241455,
             -9.051674842834473,
             -8.960467338562012,
             -8.858330726623535,
             -8.743680000305176
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 60500"
          }
         },
         "name": "frame_121",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.373230934143066,
             -9.323633193969727,
             -9.269542694091797,
             -9.207863807678223,
             -9.140913963317871,
             -9.066535949707031,
             -8.987022399902344,
             -8.909655570983887,
             -8.834908485412598
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.390752792358398,
             -9.336142539978027,
             -9.275402069091797,
             -9.20744800567627,
             -9.13241195678711,
             -9.051775932312012,
             -8.961669921875,
             -8.858363151550293,
             -8.743885040283203
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 61000"
          }
         },
         "name": "frame_122",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.373230934143066,
             -9.323633193969727,
             -9.269542694091797,
             -9.207863807678223,
             -9.140913963317871,
             -9.066535949707031,
             -8.987022399902344,
             -8.909655570983887,
             -8.834908485412598
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.390752792358398,
             -9.336142539978027,
             -9.275402069091797,
             -9.20744800567627,
             -9.13241195678711,
             -9.051775932312012,
             -8.961669921875,
             -8.858363151550293,
             -8.744070053100586
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 61500"
          }
         },
         "name": "frame_123",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.374090194702148,
             -9.325237274169922,
             -9.270023345947266,
             -9.209759712219238,
             -9.142810821533203,
             -9.066556930541992,
             -8.992109298706055,
             -8.912004470825195,
             -8.834908485412598
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.390827178955078,
             -9.336142539978027,
             -9.275402069091797,
             -9.20744800567627,
             -9.13241195678711,
             -9.051775932312012,
             -8.961669921875,
             -8.859642028808594,
             -8.74423599243164
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 62000"
          }
         },
         "name": "frame_124",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.374090194702148,
             -9.325237274169922,
             -9.270023345947266,
             -9.209759712219238,
             -9.142810821533203,
             -9.066556930541992,
             -8.992109298706055,
             -8.912004470825195,
             -8.834908485412598
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.390827178955078,
             -9.336142539978027,
             -9.275402069091797,
             -9.20744800567627,
             -9.13241195678711,
             -9.051775932312012,
             -8.961669921875,
             -8.860451698303223,
             -8.74423599243164
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 62500"
          }
         },
         "name": "frame_125",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.374090194702148,
             -9.325237274169922,
             -9.270023345947266,
             -9.209759712219238,
             -9.142810821533203,
             -9.066556930541992,
             -8.992109298706055,
             -8.912004470825195,
             -8.834908485412598
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.39207935333252,
             -9.33813190460205,
             -9.276532173156738,
             -9.207852363586426,
             -9.13328742980957,
             -9.052949905395508,
             -8.961669921875,
             -8.860793113708496,
             -8.744385719299316
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 63000"
          }
         },
         "name": "frame_126",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.374090194702148,
             -9.325237274169922,
             -9.270023345947266,
             -9.211636543273926,
             -9.14370059967041,
             -9.07113265991211,
             -8.99389934539795,
             -8.914349555969238,
             -8.83529281616211
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.39207935333252,
             -9.33920669555664,
             -9.276904106140137,
             -9.208620071411133,
             -9.13328742980957,
             -9.052949905395508,
             -8.961669921875,
             -8.860793113708496,
             -8.74452018737793
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 63500"
          }
         },
         "name": "frame_127",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.374090194702148,
             -9.325237274169922,
             -9.270023345947266,
             -9.211636543273926,
             -9.14370059967041,
             -9.07113265991211,
             -8.99389934539795,
             -8.914349555969238,
             -8.83529281616211
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.39207935333252,
             -9.3394193649292,
             -9.277585983276367,
             -9.20975399017334,
             -9.133831024169922,
             -9.052949905395508,
             -8.961669921875,
             -8.860793113708496,
             -8.74452018737793
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 64000"
          }
         },
         "name": "frame_128",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.374090194702148,
             -9.325237274169922,
             -9.270023345947266,
             -9.211636543273926,
             -9.14370059967041,
             -9.07113265991211,
             -8.99389934539795,
             -8.914349555969238,
             -8.83529281616211
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.39207935333252,
             -9.3394193649292,
             -9.277585983276367,
             -9.20975399017334,
             -9.133831024169922,
             -9.052949905395508,
             -8.961669921875,
             -8.860793113708496,
             -8.744641304016113
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 64500"
          }
         },
         "name": "frame_129",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.376829147338867,
             -9.328808784484863,
             -9.271296501159668,
             -9.211636543273926,
             -9.14370059967041,
             -9.07113265991211,
             -8.99389934539795,
             -8.914349555969238,
             -8.83529281616211
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.393396377563477,
             -9.34020709991455,
             -9.278705596923828,
             -9.21013069152832,
             -9.134403228759766,
             -9.053000450134277,
             -8.962175369262695,
             -8.861388206481934,
             -8.744641304016113
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 65000"
          }
         },
         "name": "frame_130",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.416900634765625,
             -9.376829147338867,
             -9.328808784484863,
             -9.271296501159668,
             -9.211636543273926,
             -9.14370059967041,
             -9.07113265991211,
             -8.99389934539795,
             -8.914349555969238,
             -8.83529281616211
            ],
            [
             -9.478745460510254,
             -9.439162254333496,
             -9.393396377563477,
             -9.34020709991455,
             -9.278705596923828,
             -9.21013069152832,
             -9.134403228759766,
             -9.053000450134277,
             -8.962175369262695,
             -8.861388206481934,
             -8.744641304016113
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 65500"
          }
         },
         "name": "frame_131",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.418076515197754,
             -9.378412246704102,
             -9.330276489257812,
             -9.273214340209961,
             -9.213157653808594,
             -9.144519805908203,
             -9.07113265991211,
             -8.99389934539795,
             -8.914349555969238,
             -8.83529281616211
            ],
            [
             -9.478745460510254,
             -9.439716339111328,
             -9.393396377563477,
             -9.34020709991455,
             -9.278705596923828,
             -9.210823059082031,
             -9.135213851928711,
             -9.053000450134277,
             -8.962974548339844,
             -8.861388206481934,
             -8.744641304016113
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 66000"
          }
         },
         "name": "frame_132",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450443267822266,
             -9.418076515197754,
             -9.378412246704102,
             -9.330276489257812,
             -9.273214340209961,
             -9.213157653808594,
             -9.144519805908203,
             -9.07113265991211,
             -8.99389934539795,
             -8.914349555969238,
             -8.83529281616211
            ],
            [
             -9.478745460510254,
             -9.439716339111328,
             -9.393396377563477,
             -9.34020709991455,
             -9.278705596923828,
             -9.210823059082031,
             -9.135213851928711,
             -9.053000450134277,
             -8.962974548339844,
             -8.861388206481934,
             -8.744641304016113
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 66500"
          }
         },
         "name": "frame_133",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.273214340209961,
             -9.213157653808594,
             -9.144519805908203,
             -9.07113265991211,
             -8.99389934539795,
             -8.914349555969238,
             -8.83529281616211
            ],
            [
             -9.480154037475586,
             -9.439949035644531,
             -9.39341926574707,
             -9.34020709991455,
             -9.278705596923828,
             -9.210823059082031,
             -9.135213851928711,
             -9.053000450134277,
             -8.962974548339844,
             -8.861388206481934,
             -8.744641304016113
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 67000"
          }
         },
         "name": "frame_134",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.273214340209961,
             -9.213157653808594,
             -9.144519805908203,
             -9.073470115661621,
             -8.994978904724121,
             -8.914349555969238,
             -8.83529281616211
            ],
            [
             -9.480154037475586,
             -9.441361427307129,
             -9.394696235656738,
             -9.341269493103027,
             -9.278724670410156,
             -9.211910247802734,
             -9.136462211608887,
             -9.054204940795898,
             -8.963184356689453,
             -8.861696243286133,
             -8.744750022888184
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 67500"
          }
         },
         "name": "frame_135",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.273214340209961,
             -9.213157653808594,
             -9.144519805908203,
             -9.073470115661621,
             -8.994978904724121,
             -8.914349555969238,
             -8.83529281616211
            ],
            [
             -9.480154037475586,
             -9.441361427307129,
             -9.394696235656738,
             -9.341269493103027,
             -9.278724670410156,
             -9.211910247802734,
             -9.136462211608887,
             -9.054204940795898,
             -8.963184356689453,
             -8.861696243286133,
             -8.744750022888184
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 68000"
          }
         },
         "name": "frame_136",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.273214340209961,
             -9.213157653808594,
             -9.144519805908203,
             -9.073470115661621,
             -8.994978904724121,
             -8.914349555969238,
             -8.83529281616211
            ],
            [
             -9.480154037475586,
             -9.441361427307129,
             -9.394696235656738,
             -9.341269493103027,
             -9.278724670410156,
             -9.211910247802734,
             -9.136462211608887,
             -9.055161476135254,
             -8.96533489227295,
             -8.86182975769043,
             -8.744750022888184
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 68500"
          }
         },
         "name": "frame_137",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.273998260498047,
             -9.213566780090332,
             -9.146679878234863,
             -9.075671195983887,
             -8.997152328491211,
             -8.915943145751953,
             -8.83529281616211
            ],
            [
             -9.480154037475586,
             -9.441361427307129,
             -9.394696235656738,
             -9.342185974121094,
             -9.27980899810791,
             -9.211910247802734,
             -9.136462211608887,
             -9.055562973022461,
             -8.96533489227295,
             -8.86182975769043,
             -8.744750022888184
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 69000"
          }
         },
         "name": "frame_138",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.273998260498047,
             -9.213566780090332,
             -9.146679878234863,
             -9.075671195983887,
             -8.997152328491211,
             -8.915943145751953,
             -8.83529281616211
            ],
            [
             -9.480154037475586,
             -9.441361427307129,
             -9.394696235656738,
             -9.342185974121094,
             -9.280900001525879,
             -9.213001251220703,
             -9.137816429138184,
             -9.056886672973633,
             -8.966328620910645,
             -8.86226749420166,
             -8.744848251342773
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 69500"
          }
         },
         "name": "frame_139",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.273998260498047,
             -9.213566780090332,
             -9.146679878234863,
             -9.075671195983887,
             -8.997152328491211,
             -8.915943145751953,
             -8.83529281616211
            ],
            [
             -9.480154037475586,
             -9.441361427307129,
             -9.394696235656738,
             -9.342185974121094,
             -9.280900001525879,
             -9.214104652404785,
             -9.139154434204102,
             -9.058167457580566,
             -8.966365814208984,
             -8.86226749420166,
             -8.744848251342773
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 70000"
          }
         },
         "name": "frame_140",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.273998260498047,
             -9.213566780090332,
             -9.146679878234863,
             -9.075671195983887,
             -8.997152328491211,
             -8.915943145751953,
             -8.83529281616211
            ],
            [
             -9.480154037475586,
             -9.441361427307129,
             -9.394696235656738,
             -9.342185974121094,
             -9.280900001525879,
             -9.214104652404785,
             -9.139154434204102,
             -9.058167457580566,
             -8.966365814208984,
             -8.86226749420166,
             -8.744848251342773
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 70500"
          }
         },
         "name": "frame_141",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.273998260498047,
             -9.213566780090332,
             -9.146679878234863,
             -9.075671195983887,
             -8.997152328491211,
             -8.915943145751953,
             -8.83529281616211
            ],
            [
             -9.480154037475586,
             -9.441361427307129,
             -9.394696235656738,
             -9.342185974121094,
             -9.282079696655273,
             -9.215052604675293,
             -9.139732360839844,
             -9.058208465576172,
             -8.967333793640137,
             -8.862762451171875,
             -8.7449369430542
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 71000"
          }
         },
         "name": "frame_142",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.273998260498047,
             -9.213566780090332,
             -9.146679878234863,
             -9.075671195983887,
             -8.997152328491211,
             -8.915943145751953,
             -8.83529281616211
            ],
            [
             -9.480154037475586,
             -9.441361427307129,
             -9.394696235656738,
             -9.342185974121094,
             -9.282079696655273,
             -9.215052604675293,
             -9.139732360839844,
             -9.058208465576172,
             -8.967333793640137,
             -8.862762451171875,
             -8.7449369430542
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 71500"
          }
         },
         "name": "frame_143",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.273998260498047,
             -9.213566780090332,
             -9.146679878234863,
             -9.075671195983887,
             -8.997152328491211,
             -8.915943145751953,
             -8.83529281616211
            ],
            [
             -9.480154037475586,
             -9.441361427307129,
             -9.394696235656738,
             -9.342185974121094,
             -9.282079696655273,
             -9.215052604675293,
             -9.139732360839844,
             -9.058208465576172,
             -8.967333793640137,
             -8.862762451171875,
             -8.7449369430542
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 72000"
          }
         },
         "name": "frame_144",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.273998260498047,
             -9.213566780090332,
             -9.146679878234863,
             -9.075671195983887,
             -8.997152328491211,
             -8.915943145751953,
             -8.83529281616211
            ],
            [
             -9.480154037475586,
             -9.441361427307129,
             -9.394696235656738,
             -9.342185974121094,
             -9.282079696655273,
             -9.215052604675293,
             -9.139732360839844,
             -9.058208465576172,
             -8.967333793640137,
             -8.862762451171875,
             -8.7449369430542
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 72500"
          }
         },
         "name": "frame_145",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.273998260498047,
             -9.213566780090332,
             -9.146679878234863,
             -9.075671195983887,
             -8.997152328491211,
             -8.915943145751953,
             -8.83529281616211
            ],
            [
             -9.480154037475586,
             -9.441361427307129,
             -9.394696235656738,
             -9.342185974121094,
             -9.282079696655273,
             -9.215218544006348,
             -9.139732360839844,
             -9.058208465576172,
             -8.967333793640137,
             -8.862762451171875,
             -8.7449369430542
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 73000"
          }
         },
         "name": "frame_146",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.273998260498047,
             -9.213566780090332,
             -9.146679878234863,
             -9.075671195983887,
             -8.997152328491211,
             -8.915943145751953,
             -8.83529281616211
            ],
            [
             -9.480154037475586,
             -9.441361427307129,
             -9.394696235656738,
             -9.342185974121094,
             -9.282079696655273,
             -9.215218544006348,
             -9.139732360839844,
             -9.058208465576172,
             -8.967333793640137,
             -8.862762451171875,
             -8.7449369430542
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 73500"
          }
         },
         "name": "frame_147",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.273998260498047,
             -9.213566780090332,
             -9.146679878234863,
             -9.075671195983887,
             -8.997152328491211,
             -8.915943145751953,
             -8.83529281616211
            ],
            [
             -9.480154037475586,
             -9.441361427307129,
             -9.394696235656738,
             -9.342185974121094,
             -9.282079696655273,
             -9.215218544006348,
             -9.139732360839844,
             -9.058208465576172,
             -8.967333793640137,
             -8.863077163696289,
             -8.7449369430542
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 74000"
          }
         },
         "name": "frame_148",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.2769193649292,
             -9.215071678161621,
             -9.147613525390625,
             -9.075671195983887,
             -8.997152328491211,
             -8.915943145751953,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442748069763184,
             -9.395268440246582,
             -9.342227935791016,
             -9.28255558013916,
             -9.21728801727295,
             -9.141742706298828,
             -9.05932331085205,
             -8.967333793640137,
             -8.863077163696289,
             -8.7449369430542
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 74500"
          }
         },
         "name": "frame_149",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.2769193649292,
             -9.215071678161621,
             -9.147613525390625,
             -9.075671195983887,
             -8.997152328491211,
             -8.915943145751953,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442748069763184,
             -9.395268440246582,
             -9.342227935791016,
             -9.28255558013916,
             -9.21728801727295,
             -9.141742706298828,
             -9.05932331085205,
             -8.968099594116211,
             -8.863601684570312,
             -8.745016098022461
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 75000"
          }
         },
         "name": "frame_150",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.2769193649292,
             -9.215071678161621,
             -9.147613525390625,
             -9.075671195983887,
             -8.997152328491211,
             -8.915943145751953,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442748069763184,
             -9.395268440246582,
             -9.342227935791016,
             -9.28255558013916,
             -9.21728801727295,
             -9.141742706298828,
             -9.05932331085205,
             -8.968099594116211,
             -8.863601684570312,
             -8.745016098022461
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 75500"
          }
         },
         "name": "frame_151",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.378739356994629,
             -9.330276489257812,
             -9.2769193649292,
             -9.215071678161621,
             -9.147613525390625,
             -9.075671195983887,
             -8.997152328491211,
             -8.915943145751953,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442748069763184,
             -9.395268440246582,
             -9.343435287475586,
             -9.283307075500488,
             -9.21728801727295,
             -9.141742706298828,
             -9.05932331085205,
             -8.968099594116211,
             -8.863601684570312,
             -8.745016098022461
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 76000"
          }
         },
         "name": "frame_152",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.379129409790039,
             -9.330450057983398,
             -9.278583526611328,
             -9.216849327087402,
             -9.150751113891602,
             -9.075891494750977,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442748069763184,
             -9.396023750305176,
             -9.34469985961914,
             -9.285694122314453,
             -9.218316078186035,
             -9.14290714263916,
             -9.06052017211914,
             -8.968276977539062,
             -8.863813400268555,
             -8.745016098022461
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 76500"
          }
         },
         "name": "frame_153",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.379129409790039,
             -9.330450057983398,
             -9.278583526611328,
             -9.216849327087402,
             -9.150751113891602,
             -9.075891494750977,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442748069763184,
             -9.396023750305176,
             -9.344748497009277,
             -9.285725593566895,
             -9.219346046447754,
             -9.144062995910645,
             -9.06095027923584,
             -8.969192504882812,
             -8.864356994628906,
             -8.745087623596191
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 77000"
          }
         },
         "name": "frame_154",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.379129409790039,
             -9.330450057983398,
             -9.278583526611328,
             -9.216849327087402,
             -9.150751113891602,
             -9.075891494750977,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442748069763184,
             -9.396023750305176,
             -9.344748497009277,
             -9.285725593566895,
             -9.219346046447754,
             -9.144062995910645,
             -9.06095027923584,
             -8.969192504882812,
             -8.864356994628906,
             -8.745087623596191
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 77500"
          }
         },
         "name": "frame_155",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.379129409790039,
             -9.330450057983398,
             -9.278583526611328,
             -9.216849327087402,
             -9.150751113891602,
             -9.075891494750977,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442748069763184,
             -9.396023750305176,
             -9.344748497009277,
             -9.285725593566895,
             -9.219346046447754,
             -9.144062995910645,
             -9.06095027923584,
             -8.969192504882812,
             -8.864356994628906,
             -8.745087623596191
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 78000"
          }
         },
         "name": "frame_156",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.379129409790039,
             -9.332477569580078,
             -9.278736114501953,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442748069763184,
             -9.396023750305176,
             -9.345942497253418,
             -9.285725593566895,
             -9.219346046447754,
             -9.145142555236816,
             -9.061613082885742,
             -8.969192504882812,
             -8.864356994628906,
             -8.745087623596191
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 78500"
          }
         },
         "name": "frame_157",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.421270370483398,
             -9.379129409790039,
             -9.332477569580078,
             -9.278736114501953,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442748069763184,
             -9.39755630493164,
             -9.347702980041504,
             -9.287641525268555,
             -9.219482421875,
             -9.145150184631348,
             -9.062679290771484,
             -8.969693183898926,
             -8.864483833312988,
             -8.745087623596191
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 79000"
          }
         },
         "name": "frame_158",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.42160701751709,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442767143249512,
             -9.399093627929688,
             -9.34797477722168,
             -9.287837028503418,
             -9.219482421875,
             -9.145150184631348,
             -9.062679290771484,
             -8.969693183898926,
             -8.864483833312988,
             -8.745087623596191
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 79500"
          }
         },
         "name": "frame_159",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.42160701751709,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442767143249512,
             -9.399093627929688,
             -9.34797477722168,
             -9.287837028503418,
             -9.219482421875,
             -9.145150184631348,
             -9.062679290771484,
             -8.969693183898926,
             -8.864483833312988,
             -8.745087623596191
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 80000"
          }
         },
         "name": "frame_160",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.42160701751709,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442767143249512,
             -9.399093627929688,
             -9.34797477722168,
             -9.287837028503418,
             -9.219482421875,
             -9.145150184631348,
             -9.062679290771484,
             -8.969693183898926,
             -8.864483833312988,
             -8.745087623596191
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 80500"
          }
         },
         "name": "frame_161",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.42160701751709,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442767143249512,
             -9.399093627929688,
             -9.34797477722168,
             -9.290726661682129,
             -9.22249698638916,
             -9.147197723388672,
             -9.0634183883667,
             -8.969992637634277,
             -8.864483833312988,
             -8.745087623596191
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 81000"
          }
         },
         "name": "frame_162",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.42160701751709,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442767143249512,
             -9.399093627929688,
             -9.34797477722168,
             -9.290726661682129,
             -9.22249698638916,
             -9.147197723388672,
             -9.0634183883667,
             -8.969992637634277,
             -8.864483833312988,
             -8.745087623596191
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 81500"
          }
         },
         "name": "frame_163",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.42160701751709,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442767143249512,
             -9.399093627929688,
             -9.34797477722168,
             -9.290726661682129,
             -9.22249698638916,
             -9.147197723388672,
             -9.0634183883667,
             -8.969992637634277,
             -8.864483833312988,
             -8.745087623596191
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 82000"
          }
         },
         "name": "frame_164",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.42160701751709,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442767143249512,
             -9.400062561035156,
             -9.348167419433594,
             -9.290726661682129,
             -9.223469734191895,
             -9.148185729980469,
             -9.06368350982666,
             -8.969992637634277,
             -8.864483833312988,
             -8.745087623596191
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 82500"
          }
         },
         "name": "frame_165",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.42160701751709,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442767143249512,
             -9.400062561035156,
             -9.348167419433594,
             -9.290726661682129,
             -9.223469734191895,
             -9.148185729980469,
             -9.06368350982666,
             -8.969992637634277,
             -8.864483833312988,
             -8.745087623596191
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 83000"
          }
         },
         "name": "frame_166",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.42160701751709,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442767143249512,
             -9.400062561035156,
             -9.348167419433594,
             -9.290726661682129,
             -9.223469734191895,
             -9.148185729980469,
             -9.06368350982666,
             -8.969992637634277,
             -8.865036964416504,
             -8.745152473449707
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 83500"
          }
         },
         "name": "frame_167",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.42160701751709,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442767143249512,
             -9.40050220489502,
             -9.348167419433594,
             -9.290726661682129,
             -9.223469734191895,
             -9.148185729980469,
             -9.06368350982666,
             -8.969992637634277,
             -8.865036964416504,
             -8.745152473449707
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 84000"
          }
         },
         "name": "frame_168",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.42160701751709,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442767143249512,
             -9.40050220489502,
             -9.348167419433594,
             -9.290726661682129,
             -9.223469734191895,
             -9.148185729980469,
             -9.06368350982666,
             -8.969992637634277,
             -8.865036964416504,
             -8.745152473449707
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 84500"
          }
         },
         "name": "frame_169",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.450993537902832,
             -9.42160701751709,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.48141098022461,
             -9.442767143249512,
             -9.40050220489502,
             -9.348167419433594,
             -9.291766166687012,
             -9.223495483398438,
             -9.148185729980469,
             -9.06368350982666,
             -8.969992637634277,
             -8.865036964416504,
             -8.745152473449707
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 85000"
          }
         },
         "name": "frame_170",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.0004301071167,
             -8.915946006774902,
             -8.83529281616211
            ],
            [
             -9.483524322509766,
             -9.444391250610352,
             -9.40050220489502,
             -9.348167419433594,
             -9.291766166687012,
             -9.223495483398438,
             -9.148185729980469,
             -9.06368350982666,
             -8.969992637634277,
             -8.865036964416504,
             -8.745152473449707
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 85500"
          }
         },
         "name": "frame_171",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.001176834106445,
             -8.919528007507324,
             -8.841634750366211
            ],
            [
             -9.483524322509766,
             -9.444391250610352,
             -9.40050220489502,
             -9.348167419433594,
             -9.291766166687012,
             -9.223495483398438,
             -9.148341178894043,
             -9.064102172851562,
             -8.970916748046875,
             -8.865649223327637,
             -8.74526309967041
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 86000"
          }
         },
         "name": "frame_172",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.001176834106445,
             -8.919528007507324,
             -8.841634750366211
            ],
            [
             -9.483524322509766,
             -9.444391250610352,
             -9.40050220489502,
             -9.348167419433594,
             -9.291766166687012,
             -9.223495483398438,
             -9.148341178894043,
             -9.064102172851562,
             -8.971733093261719,
             -8.865653038024902,
             -8.74526309967041
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 86500"
          }
         },
         "name": "frame_173",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.001176834106445,
             -8.919528007507324,
             -8.841634750366211
            ],
            [
             -9.483524322509766,
             -9.444391250610352,
             -9.40050220489502,
             -9.348167419433594,
             -9.291766166687012,
             -9.223495483398438,
             -9.148341178894043,
             -9.064102172851562,
             -8.971733093261719,
             -8.865653038024902,
             -8.745309829711914
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 87000"
          }
         },
         "name": "frame_174",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33431625366211,
             -9.280241966247559,
             -9.218731880187988,
             -9.152505874633789,
             -9.077847480773926,
             -9.001176834106445,
             -8.919528007507324,
             -8.841634750366211
            ],
            [
             -9.48367977142334,
             -9.44599723815918,
             -9.401786804199219,
             -9.349609375,
             -9.29181957244873,
             -9.22357177734375,
             -9.14896011352539,
             -9.064102172851562,
             -8.972418785095215,
             -8.866199493408203,
             -8.745389938354492
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 87500"
          }
         },
         "name": "frame_175",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33552074432373,
             -9.282476425170898,
             -9.221026420593262,
             -9.154890060424805,
             -9.082406044006348,
             -9.005297660827637,
             -8.922073364257812,
             -8.843810081481934
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.403109550476074,
             -9.350912094116211,
             -9.292219161987305,
             -9.22357177734375,
             -9.14896011352539,
             -9.064102172851562,
             -8.972468376159668,
             -8.866199493408203,
             -8.745424270629883
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 88000"
          }
         },
         "name": "frame_176",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33552074432373,
             -9.282476425170898,
             -9.221026420593262,
             -9.154890060424805,
             -9.082406044006348,
             -9.005297660827637,
             -8.922073364257812,
             -8.843810081481934
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.403109550476074,
             -9.350912094116211,
             -9.292219161987305,
             -9.22357177734375,
             -9.14896011352539,
             -9.064102172851562,
             -8.972468376159668,
             -8.866199493408203,
             -8.745424270629883
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 88500"
          }
         },
         "name": "frame_177",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33552074432373,
             -9.282476425170898,
             -9.222965240478516,
             -9.156137466430664,
             -9.08464241027832,
             -9.007181167602539,
             -8.927836418151855,
             -8.846940040588379
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.403109550476074,
             -9.350912094116211,
             -9.292219161987305,
             -9.22357177734375,
             -9.14909839630127,
             -9.064102172851562,
             -8.972468376159668,
             -8.866631507873535,
             -8.745454788208008
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 89000"
          }
         },
         "name": "frame_178",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33552074432373,
             -9.282476425170898,
             -9.222965240478516,
             -9.156137466430664,
             -9.08464241027832,
             -9.007181167602539,
             -8.927836418151855,
             -8.846940040588379
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.403109550476074,
             -9.350912094116211,
             -9.292219161987305,
             -9.22357177734375,
             -9.14909839630127,
             -9.064102172851562,
             -8.972468376159668,
             -8.866631507873535,
             -8.745454788208008
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 89500"
          }
         },
         "name": "frame_179",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33552074432373,
             -9.282476425170898,
             -9.222965240478516,
             -9.156137466430664,
             -9.08464241027832,
             -9.007181167602539,
             -8.927836418151855,
             -8.846940040588379
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.403109550476074,
             -9.350912094116211,
             -9.292219161987305,
             -9.22357177734375,
             -9.14909839630127,
             -9.064102172851562,
             -8.973217964172363,
             -8.866695404052734,
             -8.745482444763184
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 90000"
          }
         },
         "name": "frame_180",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33552074432373,
             -9.282476425170898,
             -9.222965240478516,
             -9.156137466430664,
             -9.08464241027832,
             -9.007181167602539,
             -8.927836418151855,
             -8.846940040588379
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.403109550476074,
             -9.350912094116211,
             -9.292219161987305,
             -9.22357177734375,
             -9.14909839630127,
             -9.064102172851562,
             -8.973217964172363,
             -8.866695404052734,
             -8.74550724029541
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 90500"
          }
         },
         "name": "frame_181",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33552074432373,
             -9.282476425170898,
             -9.222965240478516,
             -9.156137466430664,
             -9.08464241027832,
             -9.007181167602539,
             -8.927836418151855,
             -8.846940040588379
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.403109550476074,
             -9.352120399475098,
             -9.292704582214355,
             -9.22357177734375,
             -9.14909839630127,
             -9.064102172851562,
             -8.973580360412598,
             -8.867059707641602,
             -8.74550724029541
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 91000"
          }
         },
         "name": "frame_182",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33552074432373,
             -9.282476425170898,
             -9.224212646484375,
             -9.156137466430664,
             -9.085132598876953,
             -9.008576393127441,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.403109550476074,
             -9.352120399475098,
             -9.292704582214355,
             -9.225465774536133,
             -9.149874687194824,
             -9.06563949584961,
             -8.974625587463379,
             -8.867449760437012,
             -8.745530128479004
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 91500"
          }
         },
         "name": "frame_183",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33552074432373,
             -9.282476425170898,
             -9.224212646484375,
             -9.156137466430664,
             -9.085132598876953,
             -9.008576393127441,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.403109550476074,
             -9.352120399475098,
             -9.292704582214355,
             -9.225465774536133,
             -9.149874687194824,
             -9.06563949584961,
             -8.975132942199707,
             -8.867449760437012,
             -8.745550155639648
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 92000"
          }
         },
         "name": "frame_184",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33552074432373,
             -9.282476425170898,
             -9.224212646484375,
             -9.156137466430664,
             -9.085132598876953,
             -9.008576393127441,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.403109550476074,
             -9.352120399475098,
             -9.292704582214355,
             -9.225465774536133,
             -9.149874687194824,
             -9.06563949584961,
             -8.975132942199707,
             -8.867449760437012,
             -8.745550155639648
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 92500"
          }
         },
         "name": "frame_185",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33552074432373,
             -9.282476425170898,
             -9.224212646484375,
             -9.156137466430664,
             -9.085132598876953,
             -9.008576393127441,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.403109550476074,
             -9.352120399475098,
             -9.292704582214355,
             -9.225465774536133,
             -9.149874687194824,
             -9.06563949584961,
             -8.975132942199707,
             -8.867449760437012,
             -8.745550155639648
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 93000"
          }
         },
         "name": "frame_186",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33552074432373,
             -9.282476425170898,
             -9.224212646484375,
             -9.156137466430664,
             -9.085132598876953,
             -9.008576393127441,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.403966903686523,
             -9.353184700012207,
             -9.293725967407227,
             -9.227058410644531,
             -9.150869369506836,
             -9.065861701965332,
             -8.975566864013672,
             -8.86754322052002,
             -8.74556827545166
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 93500"
          }
         },
         "name": "frame_187",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33552074432373,
             -9.282476425170898,
             -9.224212646484375,
             -9.156137466430664,
             -9.085132598876953,
             -9.008576393127441,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.403966903686523,
             -9.353184700012207,
             -9.293725967407227,
             -9.227058410644531,
             -9.150869369506836,
             -9.065861701965332,
             -8.975566864013672,
             -8.86754322052002,
             -8.74556827545166
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 94000"
          }
         },
         "name": "frame_188",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33552074432373,
             -9.282476425170898,
             -9.224212646484375,
             -9.156137466430664,
             -9.085132598876953,
             -9.008576393127441,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.403966903686523,
             -9.353184700012207,
             -9.293725967407227,
             -9.227058410644531,
             -9.150869369506836,
             -9.065861701965332,
             -8.975566864013672,
             -8.86754322052002,
             -8.74556827545166
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 94500"
          }
         },
         "name": "frame_189",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.382454872131348,
             -9.33552074432373,
             -9.282476425170898,
             -9.224212646484375,
             -9.156137466430664,
             -9.085132598876953,
             -9.008576393127441,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.403966903686523,
             -9.353184700012207,
             -9.293725967407227,
             -9.227058410644531,
             -9.150869369506836,
             -9.065861701965332,
             -8.975566864013672,
             -8.86754322052002,
             -8.74556827545166
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 95000"
          }
         },
         "name": "frame_190",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.385976791381836,
             -9.338157653808594,
             -9.285387992858887,
             -9.22584342956543,
             -9.159250259399414,
             -9.0888032913208,
             -9.010483741760254,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.404489517211914,
             -9.353184700012207,
             -9.293725967407227,
             -9.227058410644531,
             -9.150869369506836,
             -9.067076683044434,
             -8.976200103759766,
             -8.867804527282715,
             -8.74556827545166
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 95500"
          }
         },
         "name": "frame_191",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453025817871094,
             -9.423263549804688,
             -9.385976791381836,
             -9.338157653808594,
             -9.285387992858887,
             -9.22584342956543,
             -9.159250259399414,
             -9.0888032913208,
             -9.010483741760254,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.48367977142334,
             -9.44643497467041,
             -9.404489517211914,
             -9.353184700012207,
             -9.293725967407227,
             -9.227058410644531,
             -9.150869369506836,
             -9.067076683044434,
             -8.976200103759766,
             -8.867804527282715,
             -8.745584487915039
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 96000"
          }
         },
         "name": "frame_192",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.456483840942383,
             -9.423895835876465,
             -9.386385917663574,
             -9.338157653808594,
             -9.285387992858887,
             -9.22584342956543,
             -9.159250259399414,
             -9.0888032913208,
             -9.010483741760254,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.485167503356934,
             -9.44643497467041,
             -9.405827522277832,
             -9.353251457214355,
             -9.294788360595703,
             -9.227263450622559,
             -9.150869369506836,
             -9.067076683044434,
             -8.976200103759766,
             -8.867804527282715,
             -8.745599746704102
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 96500"
          }
         },
         "name": "frame_193",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.456483840942383,
             -9.423895835876465,
             -9.386385917663574,
             -9.338157653808594,
             -9.285387992858887,
             -9.22584342956543,
             -9.159250259399414,
             -9.0888032913208,
             -9.010483741760254,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.485167503356934,
             -9.44643497467041,
             -9.405827522277832,
             -9.353251457214355,
             -9.294788360595703,
             -9.227263450622559,
             -9.150869369506836,
             -9.067076683044434,
             -8.976200103759766,
             -8.867804527282715,
             -8.745599746704102
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 97000"
          }
         },
         "name": "frame_194",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.456483840942383,
             -9.423895835876465,
             -9.386385917663574,
             -9.338157653808594,
             -9.285387992858887,
             -9.22584342956543,
             -9.159250259399414,
             -9.0888032913208,
             -9.010483741760254,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.485167503356934,
             -9.44643497467041,
             -9.405827522277832,
             -9.354456901550293,
             -9.29576301574707,
             -9.22811508178711,
             -9.151213645935059,
             -9.067638397216797,
             -8.97641372680664,
             -8.867904663085938,
             -8.745613098144531
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 97500"
          }
         },
         "name": "frame_195",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.456483840942383,
             -9.423895835876465,
             -9.386385917663574,
             -9.338157653808594,
             -9.285387992858887,
             -9.22584342956543,
             -9.159250259399414,
             -9.0888032913208,
             -9.010483741760254,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.485167503356934,
             -9.44643497467041,
             -9.405827522277832,
             -9.354456901550293,
             -9.29576301574707,
             -9.22811508178711,
             -9.151213645935059,
             -9.067638397216797,
             -8.97641372680664,
             -8.867904663085938,
             -8.745613098144531
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 98000"
          }
         },
         "name": "frame_196",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.456483840942383,
             -9.423895835876465,
             -9.386385917663574,
             -9.338157653808594,
             -9.285387992858887,
             -9.22584342956543,
             -9.159250259399414,
             -9.0888032913208,
             -9.010483741760254,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.485167503356934,
             -9.44643497467041,
             -9.405827522277832,
             -9.354456901550293,
             -9.29576301574707,
             -9.228912353515625,
             -9.151819229125977,
             -9.067638397216797,
             -8.97641372680664,
             -8.867904663085938,
             -8.745613098144531
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 98500"
          }
         },
         "name": "frame_197",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.456483840942383,
             -9.423895835876465,
             -9.386385917663574,
             -9.338157653808594,
             -9.285387992858887,
             -9.22584342956543,
             -9.159250259399414,
             -9.0888032913208,
             -9.010483741760254,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.485167503356934,
             -9.44643497467041,
             -9.405827522277832,
             -9.354456901550293,
             -9.29576301574707,
             -9.228912353515625,
             -9.151819229125977,
             -9.067638397216797,
             -8.97641372680664,
             -8.867904663085938,
             -8.745613098144531
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 99000"
          }
         },
         "name": "frame_198",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.456483840942383,
             -9.427972793579102,
             -9.38654613494873,
             -9.3397216796875,
             -9.285387992858887,
             -9.22584342956543,
             -9.159250259399414,
             -9.0888032913208,
             -9.010483741760254,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.486245155334473,
             -9.447558403015137,
             -9.405827522277832,
             -9.355100631713867,
             -9.29633903503418,
             -9.229766845703125,
             -9.153593063354492,
             -9.069281578063965,
             -8.976682662963867,
             -8.868127822875977,
             -8.745613098144531
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 99500"
          }
         },
         "name": "frame_199",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.456483840942383,
             -9.427972793579102,
             -9.38654613494873,
             -9.3397216796875,
             -9.285387992858887,
             -9.22584342956543,
             -9.159250259399414,
             -9.0888032913208,
             -9.010483741760254,
             -8.93025016784668,
             -8.846940040588379
            ],
            [
             -9.486245155334473,
             -9.447558403015137,
             -9.405827522277832,
             -9.355100631713867,
             -9.29633903503418,
             -9.229766845703125,
             -9.153593063354492,
             -9.069281578063965,
             -8.976682662963867,
             -8.868127822875977,
             -8.745613098144531
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.333410263061523,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745728492736816,
             -8.606369018554688
            ],
            [
             -9.562636375427246,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "Q-learning: Maximal Q-values for Step 100000"
          }
         },
         "name": "frame_200",
         "traces": [
          0
         ]
        }
       ],
       "layout": {
        "height": 600,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Q-learning: Maximal Q-values for Step 0"
        },
        "updatemenus": [
         {
          "buttons": [
           {
            "args": [
             null,
             {
              "frame": {
               "duration": 50,
               "redraw": true
              },
              "fromcurrent": true
             }
            ],
            "label": "Play",
            "method": "animate"
           },
           {
            "args": [
             [
              null
             ],
             {
              "frame": {
               "duration": 0,
               "redraw": false
              }
             }
            ],
            "label": "Pause",
            "method": "relayout"
           }
          ],
          "type": "buttons"
         }
        ],
        "width": 800,
        "xaxis": {
         "autorange": true,
         "range": [
          0,
          11
         ],
         "title": {
          "text": "X Coordinate"
         }
        },
        "yaxis": {
         "autorange": true,
         "range": [
          4,
          0
         ],
         "title": {
          "text": "Y Coordinate"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plotly.com"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "1: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "xaxis": "x",
         "y": [
          0,
          1,
          2,
          3
         ],
         "yaxis": "y",
         "z": [
          [
           1197,
           1201,
           1200,
           1187,
           1165,
           1136,
           1100,
           1059,
           1009,
           953,
           900
          ],
          [
           1318,
           1272,
           1257,
           1241,
           1213,
           1184,
           1143,
           1105,
           1072,
           1027,
           1006
          ],
          [
           6944,
           6362,
           6232,
           6158,
           6089,
           6044,
           6010,
           5988,
           6005,
           6046,
           6329
          ],
          [
           6848,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Q-learning state visit count"
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "1"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_states, action_keys, obs, rewards, done, q_values = tabular_rollout(key, TIME_STEPS, N_ACTIONS, GRID_SIZE, env, agent, policy)\n",
    "animated_heatmap(q_values, dims=jnp.asarray(GRID_SIZE), agent_name=\"Q-learning\", sample_freq=500, log_scale=False)\n",
    "plot_path(obs, title=\"Q-learning state visit count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plotly.com"
       },
       "data": [
        {
         "hovertemplate": "variable=rewards<br>episode=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "rewards",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "rewards",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352,
          1353,
          1354,
          1355,
          1356,
          1357,
          1358,
          1359,
          1360,
          1361,
          1362,
          1363,
          1364,
          1365,
          1366,
          1367,
          1368,
          1369,
          1370,
          1371,
          1372,
          1373,
          1374,
          1375,
          1376,
          1377,
          1378,
          1379,
          1380,
          1381,
          1382,
          1383,
          1384,
          1385,
          1386,
          1387,
          1388,
          1389,
          1390,
          1391,
          1392,
          1393,
          1394,
          1395,
          1396,
          1397,
          1398,
          1399,
          1400,
          1401,
          1402,
          1403,
          1404,
          1405,
          1406,
          1407,
          1408,
          1409,
          1410,
          1411,
          1412,
          1413,
          1414,
          1415,
          1416,
          1417,
          1418,
          1419,
          1420,
          1421,
          1422,
          1423,
          1424,
          1425,
          1426,
          1427,
          1428,
          1429,
          1430,
          1431,
          1432,
          1433,
          1434,
          1435,
          1436,
          1437,
          1438,
          1439,
          1440,
          1441,
          1442,
          1443,
          1444,
          1445,
          1446,
          1447,
          1448,
          1449,
          1450,
          1451,
          1452,
          1453,
          1454,
          1455,
          1456,
          1457,
          1458,
          1459,
          1460,
          1461,
          1462,
          1463,
          1464,
          1465,
          1466,
          1467,
          1468,
          1469,
          1470,
          1471,
          1472,
          1473,
          1474,
          1475,
          1476,
          1477,
          1478,
          1479,
          1480,
          1481,
          1482,
          1483,
          1484,
          1485,
          1486,
          1487,
          1488,
          1489,
          1490,
          1491,
          1492,
          1493,
          1494,
          1495,
          1496,
          1497,
          1498,
          1499,
          1500,
          1501,
          1502,
          1503,
          1504,
          1505,
          1506,
          1507,
          1508,
          1509,
          1510,
          1511,
          1512,
          1513,
          1514,
          1515,
          1516,
          1517,
          1518,
          1519,
          1520,
          1521,
          1522,
          1523,
          1524,
          1525,
          1526,
          1527,
          1528,
          1529,
          1530,
          1531,
          1532,
          1533,
          1534,
          1535,
          1536,
          1537,
          1538,
          1539,
          1540,
          1541,
          1542,
          1543,
          1544,
          1545,
          1546,
          1547,
          1548,
          1549,
          1550,
          1551,
          1552,
          1553,
          1554,
          1555,
          1556,
          1557,
          1558,
          1559,
          1560,
          1561,
          1562,
          1563,
          1564,
          1565,
          1566,
          1567,
          1568,
          1569,
          1570,
          1571,
          1572,
          1573,
          1574,
          1575,
          1576,
          1577,
          1578,
          1579,
          1580,
          1581,
          1582,
          1583,
          1584,
          1585,
          1586,
          1587,
          1588,
          1589,
          1590,
          1591,
          1592,
          1593,
          1594,
          1595,
          1596,
          1597,
          1598,
          1599,
          1600,
          1601,
          1602,
          1603,
          1604,
          1605,
          1606,
          1607,
          1608,
          1609,
          1610,
          1611,
          1612,
          1613,
          1614,
          1615,
          1616,
          1617,
          1618,
          1619,
          1620,
          1621,
          1622,
          1623,
          1624,
          1625,
          1626,
          1627,
          1628,
          1629,
          1630,
          1631,
          1632,
          1633,
          1634,
          1635,
          1636,
          1637,
          1638,
          1639,
          1640,
          1641,
          1642,
          1643,
          1644,
          1645,
          1646,
          1647,
          1648,
          1649,
          1650,
          1651,
          1652,
          1653,
          1654,
          1655,
          1656,
          1657,
          1658,
          1659,
          1660,
          1661,
          1662,
          1663,
          1664,
          1665,
          1666,
          1667,
          1668,
          1669,
          1670,
          1671,
          1672,
          1673,
          1674,
          1675,
          1676,
          1677,
          1678,
          1679,
          1680,
          1681,
          1682,
          1683,
          1684,
          1685,
          1686,
          1687,
          1688,
          1689,
          1690,
          1691,
          1692,
          1693,
          1694,
          1695,
          1696,
          1697,
          1698,
          1699,
          1700,
          1701,
          1702,
          1703,
          1704,
          1705,
          1706,
          1707,
          1708,
          1709,
          1710,
          1711,
          1712,
          1713,
          1714,
          1715,
          1716,
          1717,
          1718,
          1719,
          1720,
          1721,
          1722,
          1723,
          1724,
          1725,
          1726,
          1727,
          1728,
          1729,
          1730,
          1731,
          1732,
          1733,
          1734,
          1735,
          1736,
          1737,
          1738,
          1739,
          1740,
          1741,
          1742,
          1743,
          1744,
          1745,
          1746,
          1747,
          1748,
          1749,
          1750,
          1751,
          1752,
          1753,
          1754,
          1755,
          1756,
          1757,
          1758,
          1759,
          1760,
          1761,
          1762,
          1763,
          1764,
          1765,
          1766,
          1767,
          1768,
          1769,
          1770,
          1771,
          1772,
          1773,
          1774,
          1775,
          1776,
          1777,
          1778,
          1779,
          1780,
          1781,
          1782,
          1783,
          1784,
          1785,
          1786,
          1787,
          1788,
          1789,
          1790,
          1791,
          1792,
          1793,
          1794,
          1795,
          1796,
          1797,
          1798,
          1799,
          1800,
          1801,
          1802,
          1803,
          1804,
          1805,
          1806,
          1807,
          1808,
          1809,
          1810,
          1811,
          1812,
          1813,
          1814,
          1815,
          1816,
          1817,
          1818,
          1819,
          1820,
          1821,
          1822,
          1823,
          1824,
          1825,
          1826,
          1827,
          1828,
          1829,
          1830,
          1831,
          1832,
          1833,
          1834,
          1835,
          1836,
          1837,
          1838,
          1839,
          1840,
          1841,
          1842,
          1843,
          1844,
          1845,
          1846,
          1847,
          1848,
          1849,
          1850,
          1851,
          1852,
          1853,
          1854,
          1855,
          1856,
          1857,
          1858,
          1859,
          1860,
          1861,
          1862,
          1863,
          1864,
          1865,
          1866,
          1867,
          1868,
          1869,
          1870,
          1871,
          1872,
          1873,
          1874,
          1875,
          1876,
          1877,
          1878,
          1879,
          1880,
          1881,
          1882,
          1883,
          1884,
          1885,
          1886,
          1887,
          1888,
          1889,
          1890,
          1891,
          1892,
          1893,
          1894,
          1895,
          1896,
          1897,
          1898,
          1899,
          1900,
          1901,
          1902,
          1903,
          1904,
          1905,
          1906,
          1907,
          1908,
          1909,
          1910,
          1911,
          1912,
          1913,
          1914,
          1915,
          1916,
          1917,
          1918,
          1919,
          1920,
          1921,
          1922,
          1923,
          1924,
          1925,
          1926,
          1927,
          1928,
          1929,
          1930,
          1931,
          1932,
          1933,
          1934,
          1935,
          1936,
          1937,
          1938,
          1939,
          1940,
          1941,
          1942,
          1943,
          1944,
          1945,
          1946,
          1947,
          1948,
          1949,
          1950,
          1951,
          1952,
          1953,
          1954,
          1955,
          1956,
          1957,
          1958,
          1959,
          1960,
          1961,
          1962,
          1963,
          1964,
          1965,
          1966,
          1967,
          1968,
          1969,
          1970,
          1971,
          1972,
          1973,
          1974,
          1975,
          1976,
          1977,
          1978,
          1979,
          1980,
          1981,
          1982,
          1983,
          1984,
          1985,
          1986,
          1987,
          1988,
          1989,
          1990,
          1991,
          1992,
          1993,
          1994,
          1995,
          1996,
          1997,
          1998,
          1999,
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025,
          2026,
          2027,
          2028,
          2029,
          2030,
          2031,
          2032,
          2033,
          2034,
          2035,
          2036,
          2037,
          2038,
          2039,
          2040,
          2041,
          2042,
          2043,
          2044,
          2045,
          2046,
          2047,
          2048,
          2049,
          2050,
          2051,
          2052,
          2053,
          2054,
          2055,
          2056,
          2057,
          2058,
          2059,
          2060,
          2061,
          2062,
          2063,
          2064,
          2065,
          2066,
          2067,
          2068,
          2069,
          2070,
          2071,
          2072,
          2073,
          2074,
          2075,
          2076,
          2077,
          2078,
          2079,
          2080,
          2081,
          2082,
          2083,
          2084,
          2085,
          2086,
          2087,
          2088,
          2089,
          2090,
          2091,
          2092,
          2093,
          2094,
          2095,
          2096,
          2097,
          2098,
          2099,
          2100,
          2101,
          2102,
          2103,
          2104,
          2105,
          2106,
          2107,
          2108,
          2109,
          2110,
          2111,
          2112,
          2113,
          2114,
          2115,
          2116,
          2117,
          2118,
          2119,
          2120,
          2121,
          2122,
          2123,
          2124,
          2125,
          2126,
          2127,
          2128,
          2129,
          2130,
          2131,
          2132,
          2133,
          2134,
          2135,
          2136,
          2137,
          2138,
          2139,
          2140,
          2141,
          2142,
          2143,
          2144,
          2145,
          2146,
          2147,
          2148,
          2149,
          2150,
          2151,
          2152,
          2153,
          2154,
          2155,
          2156,
          2157,
          2158,
          2159,
          2160,
          2161,
          2162,
          2163,
          2164,
          2165,
          2166,
          2167,
          2168,
          2169,
          2170,
          2171,
          2172,
          2173,
          2174,
          2175,
          2176,
          2177,
          2178,
          2179,
          2180,
          2181,
          2182,
          2183,
          2184,
          2185,
          2186,
          2187,
          2188,
          2189,
          2190,
          2191,
          2192,
          2193,
          2194,
          2195,
          2196,
          2197,
          2198,
          2199,
          2200,
          2201,
          2202,
          2203,
          2204,
          2205,
          2206,
          2207,
          2208,
          2209,
          2210,
          2211,
          2212,
          2213,
          2214,
          2215,
          2216,
          2217,
          2218,
          2219,
          2220,
          2221,
          2222,
          2223,
          2224,
          2225,
          2226,
          2227,
          2228,
          2229,
          2230,
          2231,
          2232,
          2233,
          2234,
          2235,
          2236,
          2237,
          2238,
          2239,
          2240,
          2241,
          2242,
          2243,
          2244,
          2245,
          2246,
          2247,
          2248,
          2249,
          2250,
          2251,
          2252,
          2253,
          2254,
          2255,
          2256,
          2257,
          2258,
          2259,
          2260,
          2261,
          2262,
          2263,
          2264,
          2265,
          2266,
          2267,
          2268,
          2269,
          2270,
          2271,
          2272,
          2273,
          2274,
          2275,
          2276,
          2277,
          2278,
          2279,
          2280,
          2281,
          2282,
          2283,
          2284,
          2285,
          2286,
          2287,
          2288,
          2289,
          2290,
          2291,
          2292,
          2293,
          2294,
          2295,
          2296,
          2297,
          2298,
          2299,
          2300,
          2301,
          2302,
          2303,
          2304,
          2305,
          2306,
          2307,
          2308,
          2309,
          2310,
          2311,
          2312,
          2313,
          2314,
          2315,
          2316,
          2317,
          2318,
          2319,
          2320,
          2321,
          2322,
          2323,
          2324,
          2325,
          2326,
          2327,
          2328,
          2329,
          2330,
          2331,
          2332,
          2333,
          2334,
          2335,
          2336,
          2337,
          2338,
          2339,
          2340,
          2341,
          2342,
          2343,
          2344,
          2345,
          2346,
          2347,
          2348,
          2349,
          2350,
          2351,
          2352,
          2353,
          2354,
          2355,
          2356,
          2357,
          2358,
          2359,
          2360,
          2361,
          2362,
          2363,
          2364,
          2365,
          2366,
          2367,
          2368,
          2369,
          2370,
          2371,
          2372,
          2373,
          2374,
          2375,
          2376,
          2377,
          2378,
          2379,
          2380,
          2381,
          2382,
          2383,
          2384,
          2385,
          2386,
          2387,
          2388,
          2389,
          2390,
          2391,
          2392,
          2393,
          2394,
          2395,
          2396,
          2397,
          2398,
          2399,
          2400,
          2401,
          2402,
          2403,
          2404,
          2405,
          2406,
          2407,
          2408,
          2409,
          2410,
          2411,
          2412,
          2413,
          2414,
          2415,
          2416,
          2417,
          2418,
          2419,
          2420,
          2421,
          2422,
          2423,
          2424,
          2425,
          2426,
          2427,
          2428,
          2429,
          2430,
          2431,
          2432,
          2433,
          2434,
          2435,
          2436,
          2437,
          2438,
          2439,
          2440,
          2441,
          2442,
          2443,
          2444,
          2445,
          2446,
          2447,
          2448,
          2449,
          2450,
          2451,
          2452,
          2453,
          2454,
          2455,
          2456,
          2457,
          2458,
          2459,
          2460,
          2461,
          2462,
          2463,
          2464,
          2465,
          2466,
          2467,
          2468,
          2469,
          2470,
          2471,
          2472,
          2473,
          2474,
          2475,
          2476,
          2477,
          2478,
          2479,
          2480,
          2481,
          2482,
          2483,
          2484,
          2485,
          2486,
          2487,
          2488,
          2489,
          2490,
          2491,
          2492,
          2493,
          2494,
          2495,
          2496,
          2497,
          2498,
          2499,
          2500,
          2501,
          2502,
          2503,
          2504,
          2505,
          2506,
          2507,
          2508,
          2509,
          2510,
          2511,
          2512,
          2513,
          2514,
          2515,
          2516,
          2517,
          2518,
          2519,
          2520,
          2521,
          2522,
          2523,
          2524,
          2525,
          2526,
          2527,
          2528,
          2529,
          2530,
          2531,
          2532,
          2533,
          2534,
          2535,
          2536,
          2537,
          2538,
          2539,
          2540,
          2541,
          2542,
          2543,
          2544,
          2545,
          2546,
          2547,
          2548,
          2549,
          2550,
          2551,
          2552,
          2553,
          2554,
          2555,
          2556,
          2557,
          2558,
          2559,
          2560,
          2561,
          2562,
          2563,
          2564,
          2565,
          2566,
          2567,
          2568,
          2569,
          2570,
          2571,
          2572,
          2573,
          2574,
          2575,
          2576,
          2577,
          2578,
          2579,
          2580,
          2581,
          2582,
          2583,
          2584,
          2585,
          2586,
          2587,
          2588,
          2589,
          2590,
          2591,
          2592,
          2593,
          2594,
          2595,
          2596,
          2597,
          2598,
          2599,
          2600,
          2601,
          2602,
          2603,
          2604,
          2605,
          2606,
          2607,
          2608,
          2609,
          2610,
          2611,
          2612,
          2613,
          2614,
          2615,
          2616,
          2617,
          2618,
          2619,
          2620,
          2621,
          2622,
          2623,
          2624,
          2625,
          2626,
          2627,
          2628,
          2629,
          2630,
          2631,
          2632,
          2633,
          2634,
          2635,
          2636,
          2637,
          2638,
          2639,
          2640,
          2641,
          2642,
          2643,
          2644,
          2645,
          2646,
          2647,
          2648,
          2649,
          2650,
          2651,
          2652,
          2653,
          2654,
          2655,
          2656,
          2657,
          2658,
          2659,
          2660,
          2661,
          2662,
          2663,
          2664,
          2665,
          2666,
          2667,
          2668,
          2669,
          2670,
          2671,
          2672,
          2673,
          2674,
          2675,
          2676,
          2677,
          2678,
          2679,
          2680,
          2681,
          2682,
          2683,
          2684,
          2685,
          2686,
          2687,
          2688,
          2689,
          2690,
          2691,
          2692,
          2693,
          2694,
          2695,
          2696,
          2697,
          2698,
          2699,
          2700,
          2701,
          2702,
          2703,
          2704,
          2705,
          2706,
          2707,
          2708,
          2709,
          2710,
          2711,
          2712,
          2713,
          2714,
          2715,
          2716,
          2717,
          2718,
          2719,
          2720,
          2721,
          2722,
          2723,
          2724,
          2725,
          2726,
          2727,
          2728,
          2729,
          2730,
          2731,
          2732,
          2733,
          2734,
          2735,
          2736,
          2737,
          2738,
          2739,
          2740,
          2741,
          2742,
          2743,
          2744,
          2745,
          2746,
          2747,
          2748,
          2749,
          2750,
          2751,
          2752,
          2753,
          2754,
          2755,
          2756,
          2757,
          2758,
          2759,
          2760,
          2761,
          2762,
          2763,
          2764,
          2765,
          2766,
          2767,
          2768,
          2769,
          2770,
          2771,
          2772,
          2773,
          2774,
          2775,
          2776,
          2777,
          2778,
          2779,
          2780,
          2781,
          2782,
          2783,
          2784,
          2785,
          2786,
          2787,
          2788,
          2789,
          2790,
          2791,
          2792,
          2793,
          2794,
          2795,
          2796,
          2797,
          2798,
          2799,
          2800,
          2801,
          2802,
          2803,
          2804,
          2805,
          2806,
          2807,
          2808,
          2809,
          2810,
          2811,
          2812,
          2813,
          2814,
          2815,
          2816,
          2817,
          2818,
          2819,
          2820,
          2821,
          2822,
          2823,
          2824,
          2825,
          2826,
          2827,
          2828,
          2829,
          2830,
          2831,
          2832,
          2833,
          2834,
          2835,
          2836,
          2837,
          2838,
          2839,
          2840,
          2841,
          2842,
          2843,
          2844,
          2845,
          2846,
          2847,
          2848,
          2849,
          2850,
          2851,
          2852,
          2853,
          2854,
          2855,
          2856,
          2857,
          2858,
          2859,
          2860,
          2861,
          2862,
          2863,
          2864,
          2865,
          2866,
          2867,
          2868,
          2869,
          2870,
          2871,
          2872,
          2873,
          2874,
          2875,
          2876,
          2877,
          2878,
          2879,
          2880,
          2881,
          2882,
          2883,
          2884,
          2885,
          2886,
          2887,
          2888,
          2889,
          2890,
          2891,
          2892,
          2893,
          2894,
          2895,
          2896,
          2897,
          2898,
          2899,
          2900,
          2901,
          2902,
          2903,
          2904,
          2905,
          2906,
          2907,
          2908,
          2909,
          2910,
          2911,
          2912,
          2913,
          2914,
          2915,
          2916,
          2917,
          2918,
          2919,
          2920,
          2921,
          2922,
          2923,
          2924,
          2925,
          2926,
          2927,
          2928,
          2929,
          2930,
          2931,
          2932,
          2933,
          2934,
          2935,
          2936,
          2937,
          2938,
          2939,
          2940,
          2941,
          2942,
          2943,
          2944,
          2945,
          2946,
          2947,
          2948,
          2949,
          2950,
          2951,
          2952,
          2953,
          2954,
          2955,
          2956,
          2957,
          2958,
          2959,
          2960,
          2961,
          2962,
          2963,
          2964,
          2965,
          2966,
          2967,
          2968,
          2969,
          2970,
          2971,
          2972,
          2973,
          2974,
          2975,
          2976,
          2977,
          2978,
          2979,
          2980,
          2981,
          2982,
          2983,
          2984,
          2985,
          2986,
          2987,
          2988,
          2989,
          2990,
          2991,
          2992,
          2993,
          2994,
          2995,
          2996,
          2997,
          2998,
          2999,
          3000,
          3001,
          3002,
          3003,
          3004,
          3005,
          3006,
          3007,
          3008,
          3009,
          3010,
          3011,
          3012,
          3013,
          3014,
          3015,
          3016,
          3017,
          3018,
          3019,
          3020,
          3021,
          3022,
          3023,
          3024,
          3025,
          3026,
          3027,
          3028,
          3029,
          3030,
          3031,
          3032,
          3033,
          3034,
          3035,
          3036,
          3037,
          3038,
          3039,
          3040,
          3041,
          3042,
          3043,
          3044,
          3045,
          3046,
          3047,
          3048,
          3049,
          3050,
          3051,
          3052,
          3053,
          3054,
          3055,
          3056,
          3057,
          3058,
          3059,
          3060,
          3061,
          3062,
          3063,
          3064,
          3065,
          3066,
          3067,
          3068,
          3069,
          3070,
          3071,
          3072,
          3073,
          3074,
          3075,
          3076,
          3077,
          3078,
          3079,
          3080,
          3081,
          3082,
          3083,
          3084,
          3085,
          3086,
          3087,
          3088,
          3089,
          3090,
          3091,
          3092,
          3093,
          3094,
          3095,
          3096,
          3097,
          3098,
          3099,
          3100,
          3101,
          3102,
          3103,
          3104,
          3105,
          3106,
          3107,
          3108,
          3109,
          3110,
          3111,
          3112,
          3113,
          3114,
          3115,
          3116,
          3117,
          3118,
          3119,
          3120,
          3121,
          3122,
          3123,
          3124,
          3125,
          3126,
          3127,
          3128,
          3129,
          3130,
          3131,
          3132,
          3133,
          3134,
          3135,
          3136,
          3137,
          3138,
          3139,
          3140,
          3141,
          3142,
          3143,
          3144,
          3145,
          3146,
          3147,
          3148,
          3149,
          3150,
          3151,
          3152,
          3153,
          3154,
          3155,
          3156,
          3157,
          3158,
          3159,
          3160,
          3161,
          3162,
          3163,
          3164,
          3165,
          3166,
          3167,
          3168,
          3169,
          3170,
          3171,
          3172,
          3173,
          3174,
          3175,
          3176,
          3177,
          3178,
          3179,
          3180,
          3181,
          3182,
          3183,
          3184,
          3185,
          3186,
          3187,
          3188,
          3189,
          3190,
          3191,
          3192,
          3193,
          3194,
          3195,
          3196,
          3197,
          3198,
          3199,
          3200,
          3201,
          3202,
          3203,
          3204,
          3205,
          3206,
          3207,
          3208,
          3209,
          3210,
          3211,
          3212,
          3213,
          3214,
          3215,
          3216,
          3217,
          3218,
          3219,
          3220,
          3221,
          3222,
          3223,
          3224,
          3225,
          3226,
          3227,
          3228,
          3229,
          3230,
          3231,
          3232,
          3233,
          3234,
          3235,
          3236,
          3237,
          3238,
          3239,
          3240,
          3241,
          3242,
          3243,
          3244,
          3245,
          3246,
          3247,
          3248,
          3249,
          3250,
          3251,
          3252,
          3253,
          3254,
          3255,
          3256,
          3257,
          3258,
          3259,
          3260,
          3261,
          3262,
          3263,
          3264,
          3265,
          3266,
          3267,
          3268,
          3269,
          3270,
          3271,
          3272,
          3273,
          3274,
          3275,
          3276,
          3277,
          3278,
          3279,
          3280,
          3281,
          3282,
          3283,
          3284,
          3285,
          3286,
          3287,
          3288,
          3289,
          3290,
          3291,
          3292,
          3293,
          3294,
          3295,
          3296,
          3297,
          3298,
          3299,
          3300,
          3301,
          3302,
          3303,
          3304,
          3305,
          3306,
          3307,
          3308,
          3309,
          3310,
          3311,
          3312,
          3313,
          3314,
          3315,
          3316,
          3317,
          3318,
          3319,
          3320,
          3321,
          3322,
          3323,
          3324,
          3325,
          3326,
          3327,
          3328,
          3329,
          3330,
          3331,
          3332,
          3333,
          3334,
          3335,
          3336,
          3337,
          3338,
          3339,
          3340,
          3341,
          3342,
          3343,
          3344,
          3345,
          3346,
          3347,
          3348,
          3349,
          3350,
          3351,
          3352,
          3353,
          3354,
          3355,
          3356,
          3357,
          3358,
          3359,
          3360,
          3361,
          3362,
          3363,
          3364,
          3365,
          3366,
          3367,
          3368,
          3369,
          3370,
          3371,
          3372,
          3373,
          3374,
          3375,
          3376,
          3377,
          3378,
          3379,
          3380,
          3381,
          3382,
          3383,
          3384,
          3385,
          3386,
          3387,
          3388,
          3389,
          3390,
          3391,
          3392,
          3393,
          3394,
          3395,
          3396,
          3397,
          3398,
          3399,
          3400,
          3401,
          3402,
          3403,
          3404,
          3405,
          3406,
          3407,
          3408,
          3409,
          3410,
          3411,
          3412,
          3413,
          3414,
          3415,
          3416,
          3417,
          3418,
          3419,
          3420,
          3421,
          3422,
          3423,
          3424,
          3425,
          3426,
          3427,
          3428,
          3429,
          3430,
          3431,
          3432,
          3433,
          3434,
          3435,
          3436,
          3437,
          3438,
          3439,
          3440,
          3441,
          3442,
          3443,
          3444,
          3445,
          3446,
          3447,
          3448,
          3449,
          3450,
          3451,
          3452,
          3453,
          3454,
          3455,
          3456,
          3457,
          3458,
          3459,
          3460,
          3461,
          3462,
          3463,
          3464,
          3465,
          3466,
          3467,
          3468,
          3469,
          3470,
          3471,
          3472,
          3473,
          3474,
          3475,
          3476,
          3477,
          3478,
          3479,
          3480,
          3481,
          3482,
          3483,
          3484,
          3485,
          3486,
          3487,
          3488,
          3489,
          3490,
          3491,
          3492,
          3493,
          3494,
          3495,
          3496,
          3497,
          3498,
          3499,
          3500,
          3501,
          3502,
          3503,
          3504,
          3505,
          3506,
          3507,
          3508,
          3509,
          3510,
          3511,
          3512,
          3513,
          3514,
          3515,
          3516,
          3517,
          3518,
          3519,
          3520,
          3521,
          3522,
          3523,
          3524,
          3525,
          3526,
          3527,
          3528,
          3529,
          3530,
          3531,
          3532,
          3533,
          3534,
          3535,
          3536,
          3537,
          3538,
          3539,
          3540,
          3541,
          3542,
          3543,
          3544,
          3545,
          3546,
          3547,
          3548,
          3549,
          3550,
          3551,
          3552,
          3553,
          3554,
          3555,
          3556,
          3557,
          3558,
          3559,
          3560,
          3561,
          3562,
          3563,
          3564,
          3565,
          3566,
          3567,
          3568,
          3569,
          3570,
          3571,
          3572,
          3573,
          3574,
          3575,
          3576,
          3577,
          3578,
          3579,
          3580,
          3581,
          3582,
          3583,
          3584,
          3585,
          3586,
          3587,
          3588,
          3589,
          3590,
          3591,
          3592,
          3593,
          3594,
          3595,
          3596,
          3597,
          3598,
          3599,
          3600,
          3601,
          3602,
          3603,
          3604,
          3605,
          3606,
          3607,
          3608,
          3609,
          3610,
          3611,
          3612,
          3613,
          3614,
          3615,
          3616,
          3617,
          3618,
          3619,
          3620,
          3621,
          3622,
          3623,
          3624,
          3625,
          3626,
          3627,
          3628,
          3629,
          3630,
          3631,
          3632,
          3633,
          3634,
          3635,
          3636,
          3637,
          3638,
          3639,
          3640,
          3641,
          3642,
          3643,
          3644,
          3645,
          3646,
          3647,
          3648,
          3649,
          3650,
          3651,
          3652,
          3653,
          3654,
          3655,
          3656,
          3657,
          3658,
          3659,
          3660,
          3661,
          3662,
          3663,
          3664,
          3665,
          3666,
          3667,
          3668,
          3669,
          3670,
          3671,
          3672,
          3673,
          3674,
          3675,
          3676,
          3677,
          3678,
          3679,
          3680,
          3681,
          3682,
          3683,
          3684,
          3685,
          3686,
          3687,
          3688,
          3689,
          3690,
          3691,
          3692,
          3693,
          3694,
          3695,
          3696,
          3697,
          3698,
          3699,
          3700,
          3701,
          3702,
          3703,
          3704,
          3705,
          3706,
          3707,
          3708,
          3709,
          3710,
          3711,
          3712,
          3713,
          3714,
          3715,
          3716,
          3717,
          3718,
          3719,
          3720,
          3721,
          3722,
          3723,
          3724,
          3725,
          3726,
          3727,
          3728,
          3729,
          3730,
          3731,
          3732,
          3733,
          3734,
          3735,
          3736,
          3737,
          3738,
          3739,
          3740,
          3741,
          3742,
          3743,
          3744,
          3745,
          3746,
          3747,
          3748,
          3749,
          3750,
          3751,
          3752,
          3753,
          3754,
          3755,
          3756,
          3757,
          3758,
          3759,
          3760,
          3761,
          3762,
          3763,
          3764,
          3765,
          3766,
          3767,
          3768,
          3769,
          3770,
          3771,
          3772,
          3773,
          3774,
          3775,
          3776,
          3777,
          3778,
          3779,
          3780,
          3781,
          3782,
          3783,
          3784,
          3785,
          3786,
          3787,
          3788,
          3789,
          3790,
          3791,
          3792,
          3793,
          3794,
          3795,
          3796,
          3797,
          3798,
          3799,
          3800,
          3801,
          3802,
          3803,
          3804,
          3805,
          3806,
          3807,
          3808,
          3809,
          3810,
          3811,
          3812,
          3813,
          3814,
          3815,
          3816,
          3817,
          3818,
          3819,
          3820,
          3821,
          3822,
          3823,
          3824,
          3825,
          3826,
          3827,
          3828,
          3829,
          3830,
          3831,
          3832,
          3833,
          3834,
          3835,
          3836,
          3837,
          3838,
          3839,
          3840,
          3841,
          3842,
          3843,
          3844,
          3845,
          3846,
          3847,
          3848,
          3849,
          3850,
          3851,
          3852,
          3853,
          3854,
          3855,
          3856,
          3857,
          3858,
          3859,
          3860,
          3861,
          3862,
          3863,
          3864,
          3865,
          3866,
          3867,
          3868,
          3869,
          3870,
          3871,
          3872,
          3873,
          3874,
          3875,
          3876,
          3877,
          3878,
          3879,
          3880,
          3881,
          3882,
          3883,
          3884,
          3885,
          3886,
          3887,
          3888,
          3889,
          3890,
          3891,
          3892,
          3893,
          3894,
          3895,
          3896,
          3897,
          3898,
          3899,
          3900,
          3901,
          3902,
          3903,
          3904,
          3905,
          3906,
          3907,
          3908,
          3909,
          3910,
          3911,
          3912,
          3913,
          3914,
          3915,
          3916,
          3917,
          3918,
          3919,
          3920,
          3921,
          3922,
          3923,
          3924,
          3925,
          3926,
          3927,
          3928,
          3929,
          3930,
          3931,
          3932,
          3933,
          3934,
          3935,
          3936,
          3937,
          3938,
          3939,
          3940,
          3941,
          3942,
          3943,
          3944,
          3945,
          3946,
          3947,
          3948,
          3949,
          3950,
          3951,
          3952,
          3953,
          3954,
          3955,
          3956,
          3957,
          3958,
          3959,
          3960,
          3961,
          3962,
          3963,
          3964,
          3965,
          3966,
          3967,
          3968,
          3969,
          3970,
          3971,
          3972,
          3973,
          3974,
          3975,
          3976,
          3977,
          3978,
          3979,
          3980,
          3981,
          3982,
          3983,
          3984,
          3985,
          3986,
          3987,
          3988,
          3989,
          3990,
          3991,
          3992,
          3993,
          3994,
          3995,
          3996,
          3997,
          3998,
          3999,
          4000,
          4001,
          4002,
          4003,
          4004,
          4005,
          4006,
          4007,
          4008,
          4009,
          4010,
          4011,
          4012,
          4013,
          4014,
          4015,
          4016,
          4017,
          4018,
          4019,
          4020,
          4021,
          4022,
          4023,
          4024,
          4025,
          4026,
          4027,
          4028,
          4029,
          4030,
          4031,
          4032,
          4033,
          4034,
          4035,
          4036,
          4037,
          4038,
          4039,
          4040,
          4041,
          4042,
          4043,
          4044,
          4045,
          4046,
          4047,
          4048,
          4049,
          4050,
          4051,
          4052,
          4053,
          4054,
          4055,
          4056,
          4057,
          4058,
          4059,
          4060,
          4061,
          4062,
          4063,
          4064,
          4065,
          4066,
          4067,
          4068,
          4069,
          4070,
          4071,
          4072,
          4073,
          4074,
          4075,
          4076,
          4077,
          4078,
          4079,
          4080,
          4081,
          4082,
          4083,
          4084,
          4085,
          4086,
          4087,
          4088,
          4089,
          4090,
          4091,
          4092,
          4093,
          4094,
          4095,
          4096,
          4097,
          4098,
          4099,
          4100,
          4101,
          4102,
          4103,
          4104,
          4105,
          4106,
          4107,
          4108,
          4109,
          4110,
          4111,
          4112,
          4113,
          4114,
          4115,
          4116,
          4117,
          4118,
          4119,
          4120,
          4121,
          4122,
          4123,
          4124,
          4125,
          4126,
          4127,
          4128,
          4129,
          4130,
          4131,
          4132,
          4133,
          4134,
          4135,
          4136,
          4137,
          4138,
          4139,
          4140,
          4141,
          4142,
          4143,
          4144,
          4145,
          4146,
          4147,
          4148,
          4149,
          4150,
          4151,
          4152,
          4153,
          4154,
          4155,
          4156,
          4157,
          4158,
          4159,
          4160,
          4161,
          4162,
          4163,
          4164,
          4165,
          4166,
          4167,
          4168,
          4169,
          4170,
          4171,
          4172,
          4173,
          4174,
          4175,
          4176,
          4177,
          4178,
          4179,
          4180,
          4181,
          4182,
          4183,
          4184,
          4185,
          4186,
          4187,
          4188,
          4189,
          4190,
          4191,
          4192,
          4193,
          4194,
          4195,
          4196,
          4197,
          4198,
          4199,
          4200,
          4201,
          4202,
          4203,
          4204,
          4205,
          4206,
          4207,
          4208,
          4209,
          4210,
          4211,
          4212,
          4213,
          4214,
          4215,
          4216,
          4217,
          4218,
          4219,
          4220,
          4221,
          4222,
          4223,
          4224,
          4225,
          4226,
          4227,
          4228,
          4229,
          4230,
          4231,
          4232,
          4233,
          4234,
          4235,
          4236,
          4237,
          4238,
          4239,
          4240,
          4241,
          4242,
          4243,
          4244,
          4245,
          4246,
          4247,
          4248,
          4249,
          4250,
          4251,
          4252,
          4253,
          4254,
          4255,
          4256,
          4257,
          4258,
          4259,
          4260,
          4261,
          4262,
          4263,
          4264,
          4265,
          4266,
          4267,
          4268,
          4269,
          4270,
          4271,
          4272,
          4273,
          4274,
          4275,
          4276,
          4277,
          4278,
          4279,
          4280,
          4281,
          4282,
          4283,
          4284,
          4285,
          4286,
          4287,
          4288,
          4289,
          4290,
          4291,
          4292,
          4293,
          4294,
          4295,
          4296,
          4297,
          4298,
          4299,
          4300,
          4301,
          4302,
          4303,
          4304,
          4305,
          4306,
          4307,
          4308,
          4309,
          4310,
          4311,
          4312,
          4313,
          4314,
          4315,
          4316,
          4317,
          4318,
          4319,
          4320,
          4321,
          4322,
          4323,
          4324,
          4325,
          4326,
          4327,
          4328,
          4329,
          4330,
          4331,
          4332,
          4333,
          4334,
          4335,
          4336,
          4337,
          4338,
          4339,
          4340,
          4341,
          4342,
          4343,
          4344,
          4345,
          4346,
          4347,
          4348,
          4349,
          4350,
          4351,
          4352,
          4353,
          4354,
          4355,
          4356,
          4357,
          4358,
          4359,
          4360,
          4361,
          4362,
          4363,
          4364,
          4365,
          4366,
          4367,
          4368,
          4369,
          4370,
          4371,
          4372,
          4373,
          4374,
          4375,
          4376,
          4377,
          4378,
          4379,
          4380,
          4381,
          4382,
          4383,
          4384,
          4385,
          4386,
          4387,
          4388,
          4389,
          4390,
          4391,
          4392,
          4393,
          4394,
          4395,
          4396,
          4397,
          4398,
          4399,
          4400,
          4401,
          4402,
          4403,
          4404,
          4405,
          4406,
          4407,
          4408,
          4409,
          4410,
          4411,
          4412,
          4413,
          4414,
          4415,
          4416,
          4417,
          4418,
          4419,
          4420,
          4421,
          4422,
          4423,
          4424,
          4425,
          4426,
          4427,
          4428,
          4429,
          4430,
          4431,
          4432,
          4433,
          4434,
          4435,
          4436,
          4437,
          4438,
          4439,
          4440,
          4441,
          4442,
          4443,
          4444,
          4445,
          4446,
          4447,
          4448,
          4449,
          4450,
          4451,
          4452,
          4453,
          4454,
          4455,
          4456,
          4457,
          4458,
          4459,
          4460,
          4461,
          4462,
          4463,
          4464,
          4465,
          4466,
          4467,
          4468,
          4469,
          4470,
          4471,
          4472,
          4473,
          4474,
          4475,
          4476,
          4477,
          4478,
          4479,
          4480,
          4481,
          4482,
          4483,
          4484,
          4485,
          4486,
          4487,
          4488,
          4489,
          4490,
          4491,
          4492,
          4493,
          4494,
          4495,
          4496,
          4497,
          4498,
          4499,
          4500,
          4501,
          4502,
          4503,
          4504,
          4505,
          4506,
          4507,
          4508,
          4509,
          4510,
          4511,
          4512,
          4513,
          4514,
          4515,
          4516,
          4517,
          4518,
          4519,
          4520,
          4521,
          4522,
          4523,
          4524,
          4525,
          4526,
          4527,
          4528,
          4529,
          4530,
          4531,
          4532,
          4533,
          4534,
          4535,
          4536,
          4537,
          4538,
          4539,
          4540,
          4541,
          4542,
          4543,
          4544,
          4545,
          4546,
          4547,
          4548,
          4549,
          4550,
          4551,
          4552,
          4553,
          4554,
          4555,
          4556,
          4557,
          4558,
          4559,
          4560,
          4561,
          4562,
          4563,
          4564,
          4565,
          4566,
          4567,
          4568,
          4569,
          4570,
          4571,
          4572,
          4573,
          4574,
          4575,
          4576,
          4577,
          4578,
          4579,
          4580,
          4581,
          4582,
          4583,
          4584,
          4585,
          4586,
          4587,
          4588,
          4589,
          4590,
          4591,
          4592,
          4593,
          4594,
          4595,
          4596,
          4597,
          4598,
          4599,
          4600,
          4601,
          4602,
          4603,
          4604,
          4605,
          4606,
          4607,
          4608,
          4609,
          4610,
          4611,
          4612,
          4613,
          4614,
          4615,
          4616,
          4617,
          4618,
          4619,
          4620,
          4621,
          4622,
          4623,
          4624,
          4625,
          4626,
          4627,
          4628,
          4629,
          4630,
          4631,
          4632,
          4633,
          4634,
          4635,
          4636,
          4637,
          4638,
          4639,
          4640,
          4641,
          4642,
          4643,
          4644,
          4645,
          4646,
          4647,
          4648,
          4649,
          4650,
          4651,
          4652,
          4653,
          4654,
          4655,
          4656,
          4657,
          4658,
          4659,
          4660,
          4661,
          4662,
          4663,
          4664,
          4665,
          4666,
          4667,
          4668,
          4669,
          4670,
          4671,
          4672,
          4673,
          4674,
          4675,
          4676,
          4677,
          4678,
          4679,
          4680,
          4681,
          4682,
          4683,
          4684,
          4685,
          4686,
          4687,
          4688,
          4689,
          4690,
          4691,
          4692,
          4693,
          4694,
          4695,
          4696,
          4697,
          4698,
          4699,
          4700,
          4701,
          4702,
          4703,
          4704,
          4705,
          4706,
          4707,
          4708,
          4709,
          4710,
          4711,
          4712,
          4713,
          4714,
          4715,
          4716,
          4717,
          4718,
          4719,
          4720,
          4721,
          4722,
          4723,
          4724,
          4725,
          4726,
          4727,
          4728,
          4729,
          4730,
          4731,
          4732,
          4733,
          4734,
          4735,
          4736,
          4737,
          4738,
          4739,
          4740,
          4741,
          4742,
          4743,
          4744,
          4745,
          4746,
          4747,
          4748,
          4749,
          4750,
          4751,
          4752,
          4753,
          4754,
          4755,
          4756,
          4757,
          4758,
          4759,
          4760,
          4761,
          4762,
          4763,
          4764,
          4765,
          4766,
          4767,
          4768,
          4769,
          4770,
          4771,
          4772,
          4773,
          4774,
          4775,
          4776,
          4777,
          4778,
          4779,
          4780,
          4781,
          4782,
          4783,
          4784,
          4785,
          4786,
          4787,
          4788,
          4789,
          4790,
          4791,
          4792,
          4793,
          4794,
          4795,
          4796,
          4797,
          4798,
          4799,
          4800,
          4801,
          4802,
          4803,
          4804,
          4805,
          4806,
          4807,
          4808,
          4809,
          4810,
          4811,
          4812,
          4813,
          4814,
          4815,
          4816,
          4817,
          4818,
          4819,
          4820,
          4821,
          4822,
          4823,
          4824,
          4825,
          4826,
          4827,
          4828,
          4829,
          4830,
          4831,
          4832,
          4833,
          4834,
          4835,
          4836,
          4837,
          4838,
          4839,
          4840,
          4841,
          4842,
          4843,
          4844,
          4845,
          4846,
          4847,
          4848,
          4849,
          4850,
          4851,
          4852,
          4853,
          4854,
          4855,
          4856,
          4857,
          4858,
          4859,
          4860,
          4861,
          4862,
          4863,
          4864,
          4865,
          4866,
          4867,
          4868,
          4869,
          4870,
          4871,
          4872,
          4873,
          4874,
          4875,
          4876,
          4877,
          4878,
          4879,
          4880,
          4881,
          4882,
          4883,
          4884,
          4885,
          4886,
          4887,
          4888,
          4889,
          4890,
          4891,
          4892,
          4893,
          4894,
          4895,
          4896,
          4897,
          4898,
          4899,
          4900,
          4901,
          4902,
          4903,
          4904,
          4905,
          4906,
          4907,
          4908,
          4909,
          4910,
          4911,
          4912,
          4913,
          4914,
          4915,
          4916,
          4917,
          4918,
          4919,
          4920,
          4921,
          4922,
          4923,
          4924,
          4925,
          4926,
          4927,
          4928,
          4929,
          4930,
          4931,
          4932,
          4933,
          4934,
          4935,
          4936,
          4937,
          4938,
          4939,
          4940,
          4941,
          4942,
          4943,
          4944,
          4945,
          4946,
          4947,
          4948,
          4949,
          4950,
          4951,
          4952,
          4953,
          4954,
          4955,
          4956,
          4957,
          4958,
          4959,
          4960,
          4961,
          4962,
          4963,
          4964,
          4965,
          4966,
          4967,
          4968,
          4969,
          4970,
          4971,
          4972,
          4973,
          4974,
          4975,
          4976,
          4977,
          4978,
          4979,
          4980,
          4981,
          4982,
          4983,
          4984,
          4985,
          4986,
          4987,
          4988,
          4989,
          4990,
          4991,
          4992,
          4993,
          4994,
          4995,
          4996,
          4997,
          4998,
          4999,
          5000,
          5001,
          5002,
          5003,
          5004,
          5005,
          5006,
          5007,
          5008,
          5009,
          5010,
          5011,
          5012,
          5013,
          5014,
          5015,
          5016,
          5017,
          5018,
          5019,
          5020,
          5021,
          5022,
          5023,
          5024,
          5025,
          5026,
          5027,
          5028,
          5029,
          5030,
          5031,
          5032,
          5033,
          5034,
          5035,
          5036,
          5037,
          5038,
          5039,
          5040,
          5041,
          5042,
          5043,
          5044,
          5045,
          5046,
          5047,
          5048,
          5049,
          5050,
          5051,
          5052,
          5053,
          5054,
          5055,
          5056,
          5057,
          5058,
          5059,
          5060,
          5061,
          5062,
          5063,
          5064,
          5065,
          5066,
          5067,
          5068,
          5069,
          5070,
          5071,
          5072,
          5073,
          5074,
          5075,
          5076,
          5077,
          5078,
          5079,
          5080,
          5081,
          5082,
          5083,
          5084,
          5085,
          5086,
          5087,
          5088,
          5089,
          5090,
          5091,
          5092,
          5093,
          5094,
          5095,
          5096,
          5097,
          5098,
          5099,
          5100,
          5101,
          5102,
          5103,
          5104,
          5105,
          5106,
          5107,
          5108,
          5109,
          5110,
          5111,
          5112,
          5113,
          5114,
          5115,
          5116,
          5117,
          5118,
          5119,
          5120,
          5121,
          5122,
          5123,
          5124,
          5125,
          5126,
          5127,
          5128,
          5129,
          5130,
          5131,
          5132,
          5133,
          5134,
          5135,
          5136,
          5137,
          5138,
          5139,
          5140,
          5141,
          5142,
          5143,
          5144,
          5145,
          5146,
          5147,
          5148,
          5149,
          5150,
          5151,
          5152,
          5153,
          5154,
          5155,
          5156,
          5157,
          5158,
          5159,
          5160,
          5161,
          5162,
          5163,
          5164,
          5165,
          5166,
          5167,
          5168,
          5169,
          5170,
          5171,
          5172,
          5173,
          5174,
          5175,
          5176,
          5177,
          5178,
          5179,
          5180,
          5181,
          5182,
          5183,
          5184,
          5185,
          5186,
          5187,
          5188,
          5189,
          5190,
          5191,
          5192,
          5193,
          5194,
          5195,
          5196,
          5197,
          5198,
          5199,
          5200,
          5201,
          5202,
          5203,
          5204,
          5205,
          5206,
          5207,
          5208,
          5209,
          5210,
          5211,
          5212,
          5213,
          5214,
          5215,
          5216,
          5217,
          5218,
          5219,
          5220,
          5221,
          5222,
          5223,
          5224,
          5225,
          5226,
          5227,
          5228,
          5229,
          5230,
          5231,
          5232,
          5233,
          5234,
          5235,
          5236,
          5237,
          5238,
          5239,
          5240,
          5241,
          5242,
          5243,
          5244,
          5245,
          5246,
          5247,
          5248,
          5249,
          5250,
          5251,
          5252,
          5253,
          5254,
          5255,
          5256,
          5257,
          5258,
          5259,
          5260,
          5261,
          5262,
          5263,
          5264,
          5265,
          5266,
          5267,
          5268,
          5269,
          5270,
          5271,
          5272,
          5273,
          5274,
          5275,
          5276,
          5277,
          5278,
          5279,
          5280,
          5281,
          5282,
          5283,
          5284,
          5285,
          5286,
          5287,
          5288,
          5289,
          5290,
          5291,
          5292,
          5293,
          5294,
          5295,
          5296,
          5297,
          5298,
          5299,
          5300,
          5301,
          5302,
          5303,
          5304,
          5305,
          5306,
          5307,
          5308,
          5309,
          5310,
          5311,
          5312,
          5313,
          5314,
          5315,
          5316,
          5317,
          5318,
          5319,
          5320,
          5321,
          5322,
          5323,
          5324,
          5325,
          5326,
          5327,
          5328,
          5329,
          5330,
          5331,
          5332,
          5333,
          5334,
          5335,
          5336,
          5337,
          5338,
          5339,
          5340,
          5341,
          5342,
          5343,
          5344,
          5345,
          5346,
          5347,
          5348,
          5349,
          5350,
          5351,
          5352,
          5353,
          5354,
          5355,
          5356,
          5357,
          5358,
          5359,
          5360,
          5361,
          5362,
          5363,
          5364,
          5365,
          5366,
          5367,
          5368,
          5369,
          5370,
          5371,
          5372,
          5373,
          5374,
          5375,
          5376,
          5377,
          5378,
          5379,
          5380,
          5381,
          5382,
          5383,
          5384,
          5385,
          5386,
          5387,
          5388,
          5389,
          5390,
          5391,
          5392,
          5393,
          5394,
          5395,
          5396,
          5397,
          5398,
          5399,
          5400,
          5401,
          5402,
          5403,
          5404,
          5405,
          5406,
          5407,
          5408,
          5409,
          5410,
          5411,
          5412,
          5413,
          5414,
          5415,
          5416,
          5417,
          5418,
          5419,
          5420,
          5421,
          5422,
          5423,
          5424,
          5425,
          5426,
          5427,
          5428,
          5429,
          5430,
          5431,
          5432,
          5433,
          5434,
          5435,
          5436,
          5437,
          5438,
          5439,
          5440,
          5441,
          5442,
          5443,
          5444,
          5445,
          5446,
          5447,
          5448,
          5449,
          5450,
          5451,
          5452,
          5453,
          5454,
          5455,
          5456,
          5457,
          5458,
          5459,
          5460,
          5461,
          5462,
          5463,
          5464,
          5465,
          5466,
          5467,
          5468,
          5469,
          5470,
          5471,
          5472,
          5473,
          5474,
          5475,
          5476,
          5477,
          5478,
          5479,
          5480,
          5481,
          5482,
          5483,
          5484,
          5485,
          5486,
          5487,
          5488,
          5489,
          5490,
          5491,
          5492,
          5493,
          5494,
          5495,
          5496,
          5497,
          5498,
          5499,
          5500,
          5501,
          5502,
          5503,
          5504,
          5505,
          5506,
          5507,
          5508,
          5509,
          5510,
          5511,
          5512,
          5513,
          5514,
          5515,
          5516,
          5517,
          5518,
          5519,
          5520,
          5521,
          5522,
          5523,
          5524,
          5525,
          5526,
          5527,
          5528,
          5529,
          5530,
          5531,
          5532,
          5533,
          5534,
          5535,
          5536,
          5537,
          5538,
          5539,
          5540,
          5541,
          5542,
          5543,
          5544,
          5545,
          5546,
          5547,
          5548,
          5549,
          5550,
          5551,
          5552,
          5553,
          5554,
          5555,
          5556,
          5557,
          5558,
          5559,
          5560,
          5561,
          5562,
          5563,
          5564,
          5565,
          5566,
          5567,
          5568,
          5569,
          5570,
          5571,
          5572,
          5573,
          5574,
          5575,
          5576,
          5577,
          5578,
          5579,
          5580,
          5581,
          5582,
          5583,
          5584,
          5585,
          5586,
          5587,
          5588,
          5589,
          5590,
          5591,
          5592,
          5593,
          5594,
          5595,
          5596,
          5597,
          5598,
          5599,
          5600,
          5601,
          5602,
          5603,
          5604,
          5605,
          5606,
          5607,
          5608,
          5609,
          5610,
          5611,
          5612,
          5613,
          5614,
          5615,
          5616,
          5617,
          5618,
          5619,
          5620,
          5621,
          5622,
          5623,
          5624,
          5625,
          5626,
          5627,
          5628,
          5629,
          5630,
          5631,
          5632,
          5633,
          5634,
          5635,
          5636,
          5637,
          5638,
          5639,
          5640,
          5641,
          5642,
          5643,
          5644,
          5645,
          5646,
          5647,
          5648,
          5649,
          5650,
          5651,
          5652,
          5653,
          5654,
          5655,
          5656,
          5657,
          5658,
          5659,
          5660,
          5661,
          5662,
          5663,
          5664,
          5665,
          5666,
          5667,
          5668,
          5669,
          5670,
          5671,
          5672,
          5673,
          5674,
          5675,
          5676,
          5677,
          5678,
          5679,
          5680,
          5681,
          5682,
          5683,
          5684,
          5685,
          5686,
          5687,
          5688,
          5689,
          5690,
          5691,
          5692,
          5693,
          5694,
          5695,
          5696,
          5697,
          5698,
          5699,
          5700,
          5701,
          5702,
          5703,
          5704,
          5705,
          5706,
          5707,
          5708,
          5709,
          5710,
          5711,
          5712,
          5713,
          5714,
          5715,
          5716,
          5717,
          5718,
          5719,
          5720,
          5721,
          5722,
          5723,
          5724,
          5725,
          5726,
          5727,
          5728,
          5729,
          5730,
          5731,
          5732,
          5733,
          5734,
          5735,
          5736,
          5737,
          5738,
          5739,
          5740,
          5741,
          5742,
          5743,
          5744,
          5745,
          5746,
          5747,
          5748,
          5749,
          5750,
          5751,
          5752,
          5753,
          5754,
          5755,
          5756,
          5757,
          5758,
          5759,
          5760,
          5761,
          5762,
          5763,
          5764,
          5765,
          5766,
          5767,
          5768,
          5769,
          5770,
          5771,
          5772,
          5773,
          5774,
          5775,
          5776,
          5777,
          5778,
          5779,
          5780,
          5781,
          5782,
          5783,
          5784,
          5785,
          5786,
          5787,
          5788,
          5789,
          5790,
          5791,
          5792,
          5793,
          5794,
          5795,
          5796,
          5797,
          5798,
          5799,
          5800,
          5801,
          5802,
          5803,
          5804,
          5805,
          5806,
          5807,
          5808,
          5809,
          5810,
          5811,
          5812,
          5813,
          5814,
          5815,
          5816,
          5817,
          5818,
          5819,
          5820,
          5821,
          5822,
          5823,
          5824,
          5825,
          5826,
          5827,
          5828,
          5829,
          5830,
          5831,
          5832,
          5833,
          5834,
          5835,
          5836,
          5837,
          5838,
          5839,
          5840,
          5841,
          5842,
          5843,
          5844,
          5845,
          5846,
          5847,
          5848,
          5849,
          5850,
          5851,
          5852,
          5853,
          5854,
          5855,
          5856,
          5857,
          5858,
          5859,
          5860,
          5861,
          5862,
          5863,
          5864,
          5865,
          5866,
          5867,
          5868,
          5869,
          5870,
          5871,
          5872,
          5873,
          5874,
          5875,
          5876,
          5877,
          5878,
          5879,
          5880,
          5881,
          5882,
          5883,
          5884,
          5885,
          5886,
          5887,
          5888,
          5889,
          5890,
          5891,
          5892,
          5893,
          5894,
          5895,
          5896,
          5897,
          5898,
          5899,
          5900,
          5901,
          5902,
          5903,
          5904,
          5905,
          5906,
          5907,
          5908,
          5909,
          5910,
          5911,
          5912,
          5913,
          5914,
          5915,
          5916,
          5917,
          5918,
          5919,
          5920,
          5921,
          5922,
          5923,
          5924,
          5925,
          5926,
          5927,
          5928,
          5929,
          5930,
          5931,
          5932,
          5933,
          5934,
          5935,
          5936,
          5937,
          5938,
          5939,
          5940,
          5941,
          5942,
          5943,
          5944,
          5945,
          5946,
          5947,
          5948,
          5949,
          5950,
          5951,
          5952,
          5953,
          5954,
          5955,
          5956,
          5957,
          5958,
          5959,
          5960,
          5961,
          5962,
          5963,
          5964,
          5965,
          5966,
          5967,
          5968,
          5969,
          5970,
          5971,
          5972,
          5973,
          5974,
          5975,
          5976,
          5977,
          5978,
          5979,
          5980
         ],
         "xaxis": "x",
         "y": [
          -103,
          -101,
          -141,
          -126,
          -108,
          -128,
          -230,
          -167,
          -66,
          -228,
          -132,
          -203,
          -113,
          -287,
          -233,
          -185,
          -214,
          -165,
          -73,
          -218,
          -256,
          -139,
          -229,
          -124,
          -145,
          -180,
          -153,
          -203,
          -218,
          -71,
          -252,
          -95,
          -185,
          -154,
          -198,
          -116,
          -154,
          -186,
          -119,
          -258,
          -124,
          -147,
          -163,
          -119,
          -150,
          -130,
          -185,
          -130,
          -196,
          -131,
          -117,
          -111,
          -171,
          -131,
          -182,
          -164,
          -128,
          -123,
          -198,
          -72,
          -156,
          -174,
          -125,
          -114,
          -118,
          -180,
          -73,
          -128,
          -228,
          -57,
          -155,
          -130,
          -120,
          -100,
          -184,
          -86,
          -122,
          -163,
          -72,
          -127,
          -149,
          -88,
          -155,
          -121,
          -99,
          -151,
          -119,
          -60,
          -170,
          -95,
          -62,
          -199,
          -53,
          -110,
          -123,
          -90,
          -151,
          -121,
          -59,
          -136,
          -109,
          -149,
          -39,
          -117,
          -74,
          -157,
          -46,
          -122,
          -152,
          -94,
          -73,
          -122,
          -119,
          -116,
          -66,
          -107,
          -116,
          -102,
          -74,
          -103,
          -64,
          -113,
          -119,
          -107,
          -70,
          -127,
          -73,
          -70,
          -118,
          -85,
          -176,
          -77,
          -55,
          -67,
          -127,
          -95,
          -109,
          -67,
          -83,
          -61,
          -66,
          -125,
          -78,
          -49,
          -101,
          -125,
          -45,
          -122,
          -57,
          -96,
          -78,
          -117,
          -60,
          -62,
          -111,
          -75,
          -86,
          -93,
          -36,
          -73,
          -61,
          -128,
          -61,
          -56,
          -85,
          -49,
          -128,
          -43,
          -75,
          -67,
          -89,
          -48,
          -48,
          -111,
          -32,
          -123,
          -44,
          -48,
          -200,
          -42,
          -47,
          -103,
          -54,
          -77,
          -48,
          -85,
          -87,
          -45,
          -25,
          -58,
          -158,
          -82,
          -51,
          -35,
          -68,
          -73,
          -54,
          -87,
          -28,
          -80,
          -79,
          -65,
          -51,
          -64,
          -49,
          -36,
          -87,
          -45,
          -53,
          -84,
          -64,
          -52,
          -103,
          -57,
          -52,
          -29,
          -64,
          -73,
          -65,
          -58,
          -40,
          -70,
          -44,
          -72,
          -37,
          -51,
          -88,
          -47,
          -31,
          -57,
          -29,
          -61,
          -67,
          -63,
          -50,
          -57,
          -37,
          -64,
          -28,
          -49,
          -50,
          -89,
          -33,
          -24,
          -76,
          -32,
          -45,
          -64,
          -67,
          -38,
          -51,
          -42,
          -45,
          -38,
          -73,
          -54,
          -31,
          -49,
          -53,
          -38,
          -44,
          -52,
          -57,
          -34,
          -28,
          -74,
          -48,
          -45,
          -24,
          -40,
          -51,
          -65,
          -34,
          -31,
          -73,
          -48,
          -37,
          -30,
          -69,
          -37,
          -31,
          -38,
          -56,
          -139,
          -43,
          -41,
          -29,
          -50,
          -39,
          -109,
          -29,
          -42,
          -22,
          -143,
          -43,
          -41,
          -42,
          -27,
          -38,
          -43,
          -48,
          -20,
          -57,
          -39,
          -35,
          -37,
          -39,
          -49,
          -48,
          -16,
          -55,
          -31,
          -21,
          -47,
          -60,
          -47,
          -23,
          -47,
          -20,
          -35,
          -50,
          -47,
          -13,
          -39,
          -49,
          -28,
          -39,
          -53,
          -47,
          -22,
          -20,
          -36,
          -45,
          -35,
          -53,
          -31,
          -37,
          -21,
          -27,
          -42,
          -48,
          -40,
          -37,
          -40,
          -37,
          -21,
          -30,
          -57,
          -20,
          -27,
          -57,
          -31,
          -28,
          -21,
          -52,
          -21,
          -39,
          -33,
          -21,
          -32,
          -39,
          -44,
          -28,
          -45,
          -27,
          -27,
          -35,
          -34,
          -33,
          -37,
          -34,
          -110,
          -26,
          -31,
          -37,
          -36,
          -28,
          -47,
          -20,
          -32,
          -28,
          -34,
          -27,
          -23,
          -38,
          -32,
          -35,
          -30,
          -26,
          -20,
          -48,
          -40,
          -34,
          -16,
          -27,
          -19,
          -45,
          -17,
          -32,
          -21,
          -26,
          -40,
          -42,
          -23,
          -41,
          -24,
          -27,
          -33,
          -17,
          -35,
          -34,
          -31,
          -26,
          -25,
          -30,
          -47,
          -23,
          -29,
          -38,
          -19,
          -17,
          -16,
          -31,
          -43,
          -15,
          -40,
          -25,
          -40,
          -26,
          -26,
          -14,
          -28,
          -25,
          -106,
          -26,
          -27,
          -47,
          -21,
          -19,
          -23,
          -41,
          -16,
          -45,
          -18,
          -20,
          -25,
          -14,
          -36,
          -27,
          -27,
          -35,
          -16,
          -24,
          -15,
          -31,
          -40,
          -26,
          -22,
          -27,
          -32,
          -19,
          -26,
          -22,
          -24,
          -26,
          -14,
          -29,
          -30,
          -19,
          -38,
          -24,
          -28,
          -25,
          -19,
          -19,
          -23,
          -30,
          -24,
          -29,
          -39,
          -22,
          -20,
          -17,
          -25,
          -26,
          -46,
          -17,
          -21,
          -18,
          -26,
          -22,
          -19,
          -20,
          -25,
          -28,
          -25,
          -13,
          -23,
          -23,
          -38,
          -17,
          -17,
          -23,
          -23,
          -24,
          -20,
          -26,
          -21,
          -20,
          -22,
          -23,
          -41,
          -17,
          -31,
          -13,
          -26,
          -23,
          -24,
          -24,
          -16,
          -15,
          -19,
          -35,
          -39,
          -19,
          -17,
          -17,
          -15,
          -22,
          -30,
          -20,
          -13,
          -26,
          -23,
          -13,
          -40,
          -15,
          -22,
          -26,
          -21,
          -25,
          -15,
          -31,
          -16,
          -14,
          -15,
          -24,
          -17,
          -27,
          -12,
          -28,
          -44,
          -11,
          -21,
          -15,
          -18,
          -26,
          -26,
          -12,
          -23,
          -17,
          -106,
          -23,
          -23,
          -27,
          -17,
          -15,
          -36,
          -13,
          -13,
          -26,
          -14,
          -21,
          -25,
          -17,
          -17,
          -22,
          -27,
          -16,
          -100,
          -14,
          -13,
          -13,
          -24,
          -33,
          -18,
          -13,
          -14,
          -12,
          -25,
          -29,
          -36,
          -15,
          -26,
          -27,
          -14,
          -16,
          -13,
          -18,
          -21,
          -18,
          -11,
          -11,
          -16,
          -24,
          -23,
          -19,
          -18,
          -13,
          -19,
          -24,
          -38,
          -13,
          -19,
          -23,
          -15,
          -13,
          -15,
          -22,
          -100,
          -12,
          -22,
          -27,
          -35,
          -13,
          -19,
          -13,
          -12,
          -15,
          -17,
          -19,
          -15,
          -22,
          -14,
          -26,
          -15,
          -11,
          -29,
          -16,
          -13,
          -19,
          -17,
          -26,
          -13,
          -25,
          -13,
          -11,
          -17,
          -23,
          -11,
          -13,
          -19,
          -14,
          -11,
          -35,
          -20,
          -13,
          -15,
          -17,
          -12,
          -25,
          -13,
          -14,
          -12,
          -14,
          -13,
          -24,
          -26,
          -24,
          -19,
          -15,
          -12,
          -14,
          -13,
          -32,
          -13,
          -13,
          -18,
          -19,
          -11,
          -19,
          -13,
          -18,
          -18,
          -24,
          -11,
          -19,
          -105,
          -20,
          -11,
          -22,
          -15,
          -15,
          -11,
          -27,
          -11,
          -17,
          -14,
          -23,
          -15,
          -18,
          -102,
          -13,
          -11,
          -11,
          -11,
          -26,
          -25,
          -11,
          -11,
          -24,
          -13,
          -15,
          -11,
          -12,
          -20,
          -11,
          -15,
          -17,
          -15,
          -16,
          -13,
          -15,
          -16,
          -109,
          -15,
          -11,
          -18,
          -14,
          -12,
          -18,
          -13,
          -22,
          -13,
          -34,
          -17,
          -11,
          -13,
          -11,
          -11,
          -19,
          -11,
          -11,
          -15,
          -31,
          -19,
          -13,
          -11,
          -11,
          -17,
          -11,
          -11,
          -14,
          -17,
          -13,
          -13,
          -11,
          -26,
          -31,
          -13,
          -11,
          -11,
          -13,
          -11,
          -15,
          -11,
          -19,
          -114,
          -11,
          -17,
          -13,
          -11,
          -11,
          -11,
          -17,
          -13,
          -11,
          -11,
          -11,
          -15,
          -18,
          -15,
          -12,
          -13,
          -13,
          -11,
          -29,
          -11,
          -12,
          -11,
          -104,
          -11,
          -17,
          -19,
          -11,
          -11,
          -11,
          -16,
          -29,
          -11,
          -11,
          -13,
          -15,
          -11,
          -17,
          -14,
          -11,
          -17,
          -11,
          -11,
          -14,
          -11,
          -14,
          -24,
          -11,
          -11,
          -11,
          -14,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -23,
          -17,
          -11,
          -11,
          -17,
          -11,
          -11,
          -17,
          -12,
          -11,
          -12,
          -13,
          -11,
          -11,
          -11,
          -12,
          -15,
          -11,
          -11,
          -13,
          -17,
          -11,
          -13,
          -11,
          -14,
          -22,
          -13,
          -11,
          -13,
          -11,
          -20,
          -11,
          -29,
          -18,
          -13,
          -13,
          -25,
          -13,
          -11,
          -11,
          -13,
          -110,
          -11,
          -11,
          -13,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -12,
          -13,
          -11,
          -13,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -18,
          -11,
          -17,
          -11,
          -14,
          -11,
          -11,
          -13,
          -13,
          -11,
          -11,
          -11,
          -15,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -23,
          -11,
          -11,
          -13,
          -13,
          -19,
          -11,
          -11,
          -11,
          -11,
          -11,
          -15,
          -11,
          -11,
          -15,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -23,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -15,
          -11,
          -13,
          -11,
          -11,
          -11,
          -13,
          -12,
          -11,
          -11,
          -18,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -20,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -18,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -104,
          -13,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -13,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -26,
          -13,
          -11,
          -11,
          -15,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -108,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -102,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -20,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -20,
          -11,
          -11,
          -11,
          -102,
          -109,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -102,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -100,
          -11,
          -11,
          -14,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -103,
          -15,
          -108,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -108,
          -11,
          -103,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -105,
          -11,
          -15,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -110,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -16,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -104,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -100,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -24,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -108,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -105,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -21,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -23,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -19,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -109,
          -106,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -14,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -15,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -110,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -104,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -109,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -13,
          -13,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -17,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -11,
          -11,
          -11,
          -11,
          -100,
          -13,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -105,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -105,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -26,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -107,
          -11,
          -11,
          -11,
          -11,
          -11,
          -104,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -107,
          -11,
          -11,
          -11,
          -11,
          -15,
          -13,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -13,
          -13,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -12,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -105,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -107,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -104,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -110,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -13,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -104,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -109,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -17,
          -11,
          -106,
          -11,
          -11,
          -11,
          -24,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -104,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -105,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -19,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -107,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -15,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -13,
          -11,
          -14,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -107,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -13,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -105,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -107,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -102,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -100,
          -11,
          -11,
          -107,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -103,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -15,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -13,
          -103,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -107,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -107,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -18,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -103,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -16,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -110,
          -109,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -15,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -16,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -107,
          -11,
          -12,
          -11,
          -11,
          -11,
          -13,
          -104,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -20,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -20,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -18,
          -11,
          -11,
          -11,
          -13,
          -11,
          -110,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -107,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -15,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -13,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -105,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -103,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -11,
          -108,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -17,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -21,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -110,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -109,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -13,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -15,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -104,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -102,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -100,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -109,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -14,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -107,
          -11,
          -104,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -109,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -15,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -100,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -107,
          -11,
          -13,
          -20,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -110,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -102,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -100,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -107,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -13,
          -21,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -102,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -18,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -104,
          -11,
          -11,
          -11,
          -11,
          -15,
          -11,
          -11,
          -104,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -22,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -103,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -11,
          -11,
          -11,
          -11,
          -109,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -103,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -104,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -105,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -104,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -12,
          -11,
          -11,
          -11,
          -103,
          -11,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -104,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -105,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -14,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -109,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -21,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -102,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -17,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -110,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -107,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -13,
          -13,
          -11,
          -105,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -109,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -15,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -16,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -107,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -110,
          -110,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -106,
          -102,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -23,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -12,
          -100,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -22,
          -11,
          -11,
          -11,
          -11,
          -107,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -105,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -107,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -102,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -104,
          -11,
          -11,
          -11,
          -15,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -104,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -107,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -110,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -23,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -108,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -18,
          -13,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -104,
          -11,
          -11,
          -102,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -108,
          -11,
          -11,
          -11,
          -100,
          -11,
          -11,
          -11,
          -11,
          -13,
          -107,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -107,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -108,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -107,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -102,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -110,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -12,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -16,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -103,
          -109,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -102,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -13,
          -11,
          -11,
          -11,
          -11,
          -11,
          -106,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -102,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -11,
          -4
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "episode"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trajectories = pd.DataFrame(obs)\n",
    "trajectories[\"episode\"] = done.cumsum()\n",
    "trajectories[\"episode\"] = trajectories[\"episode\"].shift().fillna(0)\n",
    "trajectories[\"rewards\"] = rewards\n",
    "\n",
    "rewards_per_ep = trajectories[[\"rewards\", \"episode\"]].groupby(\"episode\").agg(\"sum\")\n",
    "px.line(rewards_per_ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryanp\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\jax-rl-KPtyfD6I-py3.10\\lib\\site-packages\\jax\\_src\\ops\\scatter.py:94: FutureWarning:\n",
      "\n",
      "scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "\n",
      "Running for 100,000 iterations: 100%|██████████| 100000/100000 [05:43<00:00, 291.06it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plotly.com"
       },
       "data": [
        {
         "type": "heatmap",
         "z": [
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ]
         ]
        }
       ],
       "frames": [
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ],
            [
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ],
            [
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ],
            [
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "30 Q-learning: Maximal Q-values for Step 0"
          }
         },
         "name": "frame_0",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -5.723023891448975,
             -5.688549041748047,
             -5.637223720550537,
             -5.5670342445373535,
             -5.496579170227051,
             -5.423272132873535,
             -5.340137958526611,
             -5.272772312164307,
             -5.198912620544434,
             -5.133114337921143,
             -5.081281661987305
            ],
            [
             -5.7643537521362305,
             -5.706194877624512,
             -5.64601993560791,
             -5.572422981262207,
             -5.501420497894287,
             -5.4220871925354,
             -5.3422346115112305,
             -5.266080856323242,
             -5.185637474060059,
             -5.104121685028076,
             -5.035346508026123
            ],
            [
             -5.852475643157959,
             -5.744593143463135,
             -5.655660629272461,
             -5.574807643890381,
             -5.499118328094482,
             -5.4245924949646,
             -5.3426079750061035,
             -5.2618608474731445,
             -5.170519828796387,
             -5.0734992027282715,
             -4.935168743133545
            ],
            [
             -6.028432369232178,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "30 Q-learning: Maximal Q-values for Step 10000"
          }
         },
         "name": "frame_1",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -8.123119354248047,
             -8.094405174255371,
             -8.046648025512695,
             -7.992222785949707,
             -7.9326171875,
             -7.8685622215271,
             -7.801253795623779,
             -7.732586860656738,
             -7.6621994972229,
             -7.598240375518799,
             -7.552696704864502
            ],
            [
             -8.154012680053711,
             -8.109395027160645,
             -8.054265975952148,
             -7.9964985847473145,
             -7.934996604919434,
             -7.867574691772461,
             -7.799010276794434,
             -7.726625919342041,
             -7.648966312408447,
             -7.5718560218811035,
             -7.500828266143799
            ],
            [
             -8.216315269470215,
             -8.135025978088379,
             -8.065340042114258,
             -8.000956535339355,
             -7.936576843261719,
             -7.868831157684326,
             -7.796228885650635,
             -7.715732097625732,
             -7.630677223205566,
             -7.526020050048828,
             -7.38834810256958
            ],
            [
             -8.322789192199707,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "30 Q-learning: Maximal Q-values for Step 20000"
          }
         },
         "name": "frame_2",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.151588439941406,
             -9.122881889343262,
             -9.08043098449707,
             -9.028210639953613,
             -8.97016429901123,
             -8.905195236206055,
             -8.833612442016602,
             -8.75784683227539,
             -8.679905891418457,
             -8.603652000427246,
             -8.5427827835083
            ],
            [
             -9.17831039428711,
             -9.138920783996582,
             -9.089835166931152,
             -9.033787727355957,
             -8.970866203308105,
             -8.902814865112305,
             -8.826606750488281,
             -8.744898796081543,
             -8.654881477355957,
             -8.562201499938965,
             -8.46962833404541
            ],
            [
             -9.225361824035645,
             -9.164617538452148,
             -9.104162216186523,
             -9.040827751159668,
             -8.973333358764648,
             -8.899786949157715,
             -8.817068099975586,
             -8.72282600402832,
             -8.61467170715332,
             -8.488529205322266,
             -8.343810081481934
            ],
            [
             -9.28799819946289,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "30 Q-learning: Maximal Q-values for Step 30000"
          }
         },
         "name": "frame_3",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.439624786376953,
             -9.406432151794434,
             -9.362738609313965,
             -9.311701774597168,
             -9.254807472229004,
             -9.192057609558105,
             -9.123464584350586,
             -9.0497407913208,
             -8.971426963806152,
             -8.89117431640625,
             -8.815991401672363
            ],
            [
             -9.468546867370605,
             -9.426046371459961,
             -9.375916481018066,
             -9.319326400756836,
             -9.256523132324219,
             -9.186844825744629,
             -9.110740661621094,
             -9.026896476745605,
             -8.935235977172852,
             -8.835708618164062,
             -8.729721069335938
            ],
            [
             -9.510246276855469,
             -9.456249237060547,
             -9.396260261535645,
             -9.329621315002441,
             -9.255562782287598,
             -9.173283576965332,
             -9.081852912902832,
             -8.98025894165039,
             -8.867382049560547,
             -8.741958618164062,
             -8.602595329284668
            ],
            [
             -9.558855056762695,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "30 Q-learning: Maximal Q-values for Step 40000"
          }
         },
         "name": "frame_4",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.445331573486328,
             -9.412595748901367,
             -9.369359970092773,
             -9.319344520568848,
             -9.262845039367676,
             -9.200521469116211,
             -9.133017539978027,
             -9.059889793395996,
             -8.982012748718262,
             -8.901724815368652,
             -8.82688045501709
            ],
            [
             -9.474279403686523,
             -9.432819366455078,
             -9.383283615112305,
             -9.327401161193848,
             -9.265608787536621,
             -9.197599411010742,
             -9.122526168823242,
             -9.039593696594238,
             -8.948561668395996,
             -8.849115371704102,
             -8.739997863769531
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.33341121673584,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745729446411133,
             -8.606369018554688
            ],
            [
             -9.56263542175293,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "30 Q-learning: Maximal Q-values for Step 50000"
          }
         },
         "name": "frame_5",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.448022842407227,
             -9.415873527526855,
             -9.37321662902832,
             -9.323525428771973,
             -9.268025398254395,
             -9.206462860107422,
             -9.139758110046387,
             -9.067361831665039,
             -8.990028381347656,
             -8.910125732421875,
             -8.833977699279785
            ],
            [
             -9.47694206237793,
             -9.436006546020508,
             -9.388161659240723,
             -9.333565711975098,
             -9.272296905517578,
             -9.205273628234863,
             -9.13149642944336,
             -9.048763275146484,
             -8.957359313964844,
             -8.856670379638672,
             -8.743297576904297
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.33341121673584,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745729446411133,
             -8.606369018554688
            ],
            [
             -9.56263542175293,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "30 Q-learning: Maximal Q-values for Step 60000"
          }
         },
         "name": "frame_6",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.45083236694336,
             -9.41861343383789,
             -9.37690258026123,
             -9.328104972839355,
             -9.273016929626465,
             -9.211997985839844,
             -9.14529037475586,
             -9.073312759399414,
             -8.996131896972656,
             -8.916143417358398,
             -8.838701248168945
            ],
            [
             -9.479168891906738,
             -9.439810752868652,
             -9.392794609069824,
             -9.33914852142334,
             -9.279126167297363,
             -9.212739944458008,
             -9.13899040222168,
             -9.055961608886719,
             -8.963961601257324,
             -8.861247062683105,
             -8.74463939666748
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.33341121673584,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745729446411133,
             -8.606369018554688
            ],
            [
             -9.56263542175293,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "30 Q-learning: Maximal Q-values for Step 70000"
          }
         },
         "name": "frame_7",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.453134536743164,
             -9.422028541564941,
             -9.380735397338867,
             -9.332625389099121,
             -9.27828311920166,
             -9.218088150024414,
             -9.152005195617676,
             -9.079974174499512,
             -9.002655029296875,
             -8.921869277954102,
             -8.84287166595459
            ],
            [
             -9.481884956359863,
             -9.44323444366455,
             -9.397459983825684,
             -9.344842910766602,
             -9.285994529724121,
             -9.219931602478027,
             -9.145941734313965,
             -9.062488555908203,
             -8.969464302062988,
             -8.864608764648438,
             -8.745237350463867
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.33341121673584,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745729446411133,
             -8.606369018554688
            ],
            [
             -9.56263542175293,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "30 Q-learning: Maximal Q-values for Step 80000"
          }
         },
         "name": "frame_8",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.45610523223877,
             -9.425284385681152,
             -9.384482383728027,
             -9.336719512939453,
             -9.282905578613281,
             -9.223041534423828,
             -9.15684986114502,
             -9.085012435913086,
             -9.007611274719238,
             -8.926321983337402,
             -8.84587287902832
            ],
            [
             -9.484579086303711,
             -9.447359085083008,
             -9.401639938354492,
             -9.350008964538574,
             -9.291047096252441,
             -9.225475311279297,
             -9.151082038879395,
             -9.067300796508789,
             -8.973222732543945,
             -8.866671562194824,
             -8.745501518249512
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.33341121673584,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745729446411133,
             -8.606369018554688
            ],
            [
             -9.56263542175293,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "30 Q-learning: Maximal Q-values for Step 90000"
          }
         },
         "name": "frame_9",
         "traces": [
          0
         ]
        },
        {
         "data": [
          {
           "type": "heatmap",
           "z": [
            [
             -9.458824157714844,
             -9.428411483764648,
             -9.388071060180664,
             -9.340767860412598,
             -9.287395477294922,
             -9.227540016174316,
             -9.161767959594727,
             -9.08980655670166,
             -9.011895179748535,
             -8.929769515991211,
             -8.847957611083984
            ],
            [
             -9.48709774017334,
             -9.450663566589355,
             -9.40593147277832,
             -9.354521751403809,
             -9.296274185180664,
             -9.230518341064453,
             -9.155801773071289,
             -9.071463584899902,
             -8.976065635681152,
             -8.86807632446289,
             -8.745613098144531
            ],
            [
             -9.514044761657715,
             -9.460054397583008,
             -9.400065422058105,
             -9.33341121673584,
             -9.25934886932373,
             -9.177059173583984,
             -9.085625648498535,
             -8.98403263092041,
             -8.8711519241333,
             -8.745729446411133,
             -8.606369018554688
            ],
            [
             -9.56263542175293,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0,
             0
            ]
           ]
          }
         ],
         "layout": {
          "title": {
           "text": "30 Q-learning: Maximal Q-values for Step 100000"
          }
         },
         "name": "frame_10",
         "traces": [
          0
         ]
        }
       ],
       "layout": {
        "height": 600,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "30 Q-learning: Maximal Q-values for Step 0"
        },
        "updatemenus": [
         {
          "buttons": [
           {
            "args": [
             null,
             {
              "frame": {
               "duration": 50,
               "redraw": true
              },
              "fromcurrent": true
             }
            ],
            "label": "Play",
            "method": "animate"
           },
           {
            "args": [
             [
              null
             ],
             {
              "frame": {
               "duration": 0,
               "redraw": false
              }
             }
            ],
            "label": "Pause",
            "method": "relayout"
           }
          ],
          "type": "buttons"
         }
        ],
        "width": 800,
        "xaxis": {
         "autorange": true,
         "range": [
          0,
          11
         ],
         "title": {
          "text": "X Coordinate"
         }
        },
        "yaxis": {
         "autorange": true,
         "range": [
          4,
          0
         ],
         "title": {
          "text": "Y Coordinate"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_ENV = 30\n",
    "\n",
    "key = random.PRNGKey(SEED)\n",
    "keys = random.split(key, N_ENV)\n",
    "\n",
    "all_obs, all_rewards, all_done, all_q_values = tabular_parallel_rollout(\n",
    "    keys, TIME_STEPS, N_ACTIONS, GRID_SIZE, N_ENV, env, agent, policy\n",
    ")\n",
    "animated_heatmap(jnp.mean(all_q_values, axis=-1), \n",
    "                 dims=jnp.asarray(GRID_SIZE), \n",
    "                 agent_name=f\"{N_ENV} Q-learning\", \n",
    "                 sample_freq=10_000, \n",
    "                 log_scale=False\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plotly.com"
       },
       "data": [
        {
         "hovertemplate": "variable=0<br>Episodes=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "0",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "0",
         "showlegend": true,
         "type": "scattergl",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352,
          1353,
          1354,
          1355,
          1356,
          1357,
          1358,
          1359,
          1360,
          1361,
          1362,
          1363,
          1364,
          1365,
          1366,
          1367,
          1368,
          1369,
          1370,
          1371,
          1372,
          1373,
          1374,
          1375,
          1376,
          1377,
          1378,
          1379,
          1380,
          1381,
          1382,
          1383,
          1384,
          1385,
          1386,
          1387,
          1388,
          1389,
          1390,
          1391,
          1392,
          1393,
          1394,
          1395,
          1396,
          1397,
          1398,
          1399,
          1400,
          1401,
          1402,
          1403,
          1404,
          1405,
          1406,
          1407,
          1408,
          1409,
          1410,
          1411,
          1412,
          1413,
          1414,
          1415,
          1416,
          1417,
          1418,
          1419,
          1420,
          1421,
          1422,
          1423,
          1424,
          1425,
          1426,
          1427,
          1428,
          1429,
          1430,
          1431,
          1432,
          1433,
          1434,
          1435,
          1436,
          1437,
          1438,
          1439,
          1440,
          1441,
          1442,
          1443,
          1444,
          1445,
          1446,
          1447,
          1448,
          1449,
          1450,
          1451,
          1452,
          1453,
          1454,
          1455,
          1456,
          1457,
          1458,
          1459,
          1460,
          1461,
          1462,
          1463,
          1464,
          1465,
          1466,
          1467,
          1468,
          1469,
          1470,
          1471,
          1472,
          1473,
          1474,
          1475,
          1476,
          1477,
          1478,
          1479,
          1480,
          1481,
          1482,
          1483,
          1484,
          1485,
          1486,
          1487,
          1488,
          1489,
          1490,
          1491,
          1492,
          1493,
          1494,
          1495,
          1496,
          1497,
          1498,
          1499,
          1500,
          1501,
          1502,
          1503,
          1504,
          1505,
          1506,
          1507,
          1508,
          1509,
          1510,
          1511,
          1512,
          1513,
          1514,
          1515,
          1516,
          1517,
          1518,
          1519,
          1520,
          1521,
          1522,
          1523,
          1524,
          1525,
          1526,
          1527,
          1528,
          1529,
          1530,
          1531,
          1532,
          1533,
          1534,
          1535,
          1536,
          1537,
          1538,
          1539,
          1540,
          1541,
          1542,
          1543,
          1544,
          1545,
          1546,
          1547,
          1548,
          1549,
          1550,
          1551,
          1552,
          1553,
          1554,
          1555,
          1556,
          1557,
          1558,
          1559,
          1560,
          1561,
          1562,
          1563,
          1564,
          1565,
          1566,
          1567,
          1568,
          1569,
          1570,
          1571,
          1572,
          1573,
          1574,
          1575,
          1576,
          1577,
          1578,
          1579,
          1580,
          1581,
          1582,
          1583,
          1584,
          1585,
          1586,
          1587,
          1588,
          1589,
          1590,
          1591,
          1592,
          1593,
          1594,
          1595,
          1596,
          1597,
          1598,
          1599,
          1600,
          1601,
          1602,
          1603,
          1604,
          1605,
          1606,
          1607,
          1608,
          1609,
          1610,
          1611,
          1612,
          1613,
          1614,
          1615,
          1616,
          1617,
          1618,
          1619,
          1620,
          1621,
          1622,
          1623,
          1624,
          1625,
          1626,
          1627,
          1628,
          1629,
          1630,
          1631,
          1632,
          1633,
          1634,
          1635,
          1636,
          1637,
          1638,
          1639,
          1640,
          1641,
          1642,
          1643,
          1644,
          1645,
          1646,
          1647,
          1648,
          1649,
          1650,
          1651,
          1652,
          1653,
          1654,
          1655,
          1656,
          1657,
          1658,
          1659,
          1660,
          1661,
          1662,
          1663,
          1664,
          1665,
          1666,
          1667,
          1668,
          1669,
          1670,
          1671,
          1672,
          1673,
          1674,
          1675,
          1676,
          1677,
          1678,
          1679,
          1680,
          1681,
          1682,
          1683,
          1684,
          1685,
          1686,
          1687,
          1688,
          1689,
          1690,
          1691,
          1692,
          1693,
          1694,
          1695,
          1696,
          1697,
          1698,
          1699,
          1700,
          1701,
          1702,
          1703,
          1704,
          1705,
          1706,
          1707,
          1708,
          1709,
          1710,
          1711,
          1712,
          1713,
          1714,
          1715,
          1716,
          1717,
          1718,
          1719,
          1720,
          1721,
          1722,
          1723,
          1724,
          1725,
          1726,
          1727,
          1728,
          1729,
          1730,
          1731,
          1732,
          1733,
          1734,
          1735,
          1736,
          1737,
          1738,
          1739,
          1740,
          1741,
          1742,
          1743,
          1744,
          1745,
          1746,
          1747,
          1748,
          1749,
          1750,
          1751,
          1752,
          1753,
          1754,
          1755,
          1756,
          1757,
          1758,
          1759,
          1760,
          1761,
          1762,
          1763,
          1764,
          1765,
          1766,
          1767,
          1768,
          1769,
          1770,
          1771,
          1772,
          1773,
          1774,
          1775,
          1776,
          1777,
          1778,
          1779,
          1780,
          1781,
          1782,
          1783,
          1784,
          1785,
          1786,
          1787,
          1788,
          1789,
          1790,
          1791,
          1792,
          1793,
          1794,
          1795,
          1796,
          1797,
          1798,
          1799,
          1800,
          1801,
          1802,
          1803,
          1804,
          1805,
          1806,
          1807,
          1808,
          1809,
          1810,
          1811,
          1812,
          1813,
          1814,
          1815,
          1816,
          1817,
          1818,
          1819,
          1820,
          1821,
          1822,
          1823,
          1824,
          1825,
          1826,
          1827,
          1828,
          1829,
          1830,
          1831,
          1832,
          1833,
          1834,
          1835,
          1836,
          1837,
          1838,
          1839,
          1840,
          1841,
          1842,
          1843,
          1844,
          1845,
          1846,
          1847,
          1848,
          1849,
          1850,
          1851,
          1852,
          1853,
          1854,
          1855,
          1856,
          1857,
          1858,
          1859,
          1860,
          1861,
          1862,
          1863,
          1864,
          1865,
          1866,
          1867,
          1868,
          1869,
          1870,
          1871,
          1872,
          1873,
          1874,
          1875,
          1876,
          1877,
          1878,
          1879,
          1880,
          1881,
          1882,
          1883,
          1884,
          1885,
          1886,
          1887,
          1888,
          1889,
          1890,
          1891,
          1892,
          1893,
          1894,
          1895,
          1896,
          1897,
          1898,
          1899,
          1900,
          1901,
          1902,
          1903,
          1904,
          1905,
          1906,
          1907,
          1908,
          1909,
          1910,
          1911,
          1912,
          1913,
          1914,
          1915,
          1916,
          1917,
          1918,
          1919,
          1920,
          1921,
          1922,
          1923,
          1924,
          1925,
          1926,
          1927,
          1928,
          1929,
          1930,
          1931,
          1932,
          1933,
          1934,
          1935,
          1936,
          1937,
          1938,
          1939,
          1940,
          1941,
          1942,
          1943,
          1944,
          1945,
          1946,
          1947,
          1948,
          1949,
          1950,
          1951,
          1952,
          1953,
          1954,
          1955,
          1956,
          1957,
          1958,
          1959,
          1960,
          1961,
          1962,
          1963,
          1964,
          1965,
          1966,
          1967,
          1968,
          1969,
          1970,
          1971,
          1972,
          1973,
          1974,
          1975,
          1976,
          1977,
          1978,
          1979,
          1980,
          1981,
          1982,
          1983,
          1984,
          1985,
          1986,
          1987,
          1988,
          1989,
          1990,
          1991,
          1992,
          1993,
          1994,
          1995,
          1996,
          1997,
          1998,
          1999,
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025,
          2026,
          2027,
          2028,
          2029,
          2030,
          2031,
          2032,
          2033,
          2034,
          2035,
          2036,
          2037,
          2038,
          2039,
          2040,
          2041,
          2042,
          2043,
          2044,
          2045,
          2046,
          2047,
          2048,
          2049,
          2050,
          2051,
          2052,
          2053,
          2054,
          2055,
          2056,
          2057,
          2058,
          2059,
          2060,
          2061,
          2062,
          2063,
          2064,
          2065,
          2066,
          2067,
          2068,
          2069,
          2070,
          2071,
          2072,
          2073,
          2074,
          2075,
          2076,
          2077,
          2078,
          2079,
          2080,
          2081,
          2082,
          2083,
          2084,
          2085,
          2086,
          2087,
          2088,
          2089,
          2090,
          2091,
          2092,
          2093,
          2094,
          2095,
          2096,
          2097,
          2098,
          2099,
          2100,
          2101,
          2102,
          2103,
          2104,
          2105,
          2106,
          2107,
          2108,
          2109,
          2110,
          2111,
          2112,
          2113,
          2114,
          2115,
          2116,
          2117,
          2118,
          2119,
          2120,
          2121,
          2122,
          2123,
          2124,
          2125,
          2126,
          2127,
          2128,
          2129,
          2130,
          2131,
          2132,
          2133,
          2134,
          2135,
          2136,
          2137,
          2138,
          2139,
          2140,
          2141,
          2142,
          2143,
          2144,
          2145,
          2146,
          2147,
          2148,
          2149,
          2150,
          2151,
          2152,
          2153,
          2154,
          2155,
          2156,
          2157,
          2158,
          2159,
          2160,
          2161,
          2162,
          2163,
          2164,
          2165,
          2166,
          2167,
          2168,
          2169,
          2170,
          2171,
          2172,
          2173,
          2174,
          2175,
          2176,
          2177,
          2178,
          2179,
          2180,
          2181,
          2182,
          2183,
          2184,
          2185,
          2186,
          2187,
          2188,
          2189,
          2190,
          2191,
          2192,
          2193,
          2194,
          2195,
          2196,
          2197,
          2198,
          2199,
          2200,
          2201,
          2202,
          2203,
          2204,
          2205,
          2206,
          2207,
          2208,
          2209,
          2210,
          2211,
          2212,
          2213,
          2214,
          2215,
          2216,
          2217,
          2218,
          2219,
          2220,
          2221,
          2222,
          2223,
          2224,
          2225,
          2226,
          2227,
          2228,
          2229,
          2230,
          2231,
          2232,
          2233,
          2234,
          2235,
          2236,
          2237,
          2238,
          2239,
          2240,
          2241,
          2242,
          2243,
          2244,
          2245,
          2246,
          2247,
          2248,
          2249,
          2250,
          2251,
          2252,
          2253,
          2254,
          2255,
          2256,
          2257,
          2258,
          2259,
          2260,
          2261,
          2262,
          2263,
          2264,
          2265,
          2266,
          2267,
          2268,
          2269,
          2270,
          2271,
          2272,
          2273,
          2274,
          2275,
          2276,
          2277,
          2278,
          2279,
          2280,
          2281,
          2282,
          2283,
          2284,
          2285,
          2286,
          2287,
          2288,
          2289,
          2290,
          2291,
          2292,
          2293,
          2294,
          2295,
          2296,
          2297,
          2298,
          2299,
          2300,
          2301,
          2302,
          2303,
          2304,
          2305,
          2306,
          2307,
          2308,
          2309,
          2310,
          2311,
          2312,
          2313,
          2314,
          2315,
          2316,
          2317,
          2318,
          2319,
          2320,
          2321,
          2322,
          2323,
          2324,
          2325,
          2326,
          2327,
          2328,
          2329,
          2330,
          2331,
          2332,
          2333,
          2334,
          2335,
          2336,
          2337,
          2338,
          2339,
          2340,
          2341,
          2342,
          2343,
          2344,
          2345,
          2346,
          2347,
          2348,
          2349,
          2350,
          2351,
          2352,
          2353,
          2354,
          2355,
          2356,
          2357,
          2358,
          2359,
          2360,
          2361,
          2362,
          2363,
          2364,
          2365,
          2366,
          2367,
          2368,
          2369,
          2370,
          2371,
          2372,
          2373,
          2374,
          2375,
          2376,
          2377,
          2378,
          2379,
          2380,
          2381,
          2382,
          2383,
          2384,
          2385,
          2386,
          2387,
          2388,
          2389,
          2390,
          2391,
          2392,
          2393,
          2394,
          2395,
          2396,
          2397,
          2398,
          2399,
          2400,
          2401,
          2402,
          2403,
          2404,
          2405,
          2406,
          2407,
          2408,
          2409,
          2410,
          2411,
          2412,
          2413,
          2414,
          2415,
          2416,
          2417,
          2418,
          2419,
          2420,
          2421,
          2422,
          2423,
          2424,
          2425,
          2426,
          2427,
          2428,
          2429,
          2430,
          2431,
          2432,
          2433,
          2434,
          2435,
          2436,
          2437,
          2438,
          2439,
          2440,
          2441,
          2442,
          2443,
          2444,
          2445,
          2446,
          2447,
          2448,
          2449,
          2450,
          2451,
          2452,
          2453,
          2454,
          2455,
          2456,
          2457,
          2458,
          2459,
          2460,
          2461,
          2462,
          2463,
          2464,
          2465,
          2466,
          2467,
          2468,
          2469,
          2470,
          2471,
          2472,
          2473,
          2474,
          2475,
          2476,
          2477,
          2478,
          2479,
          2480,
          2481,
          2482,
          2483,
          2484,
          2485,
          2486,
          2487,
          2488,
          2489,
          2490,
          2491,
          2492,
          2493,
          2494,
          2495,
          2496,
          2497,
          2498,
          2499,
          2500,
          2501,
          2502,
          2503,
          2504,
          2505,
          2506,
          2507,
          2508,
          2509,
          2510,
          2511,
          2512,
          2513,
          2514,
          2515,
          2516,
          2517,
          2518,
          2519,
          2520,
          2521,
          2522,
          2523,
          2524,
          2525,
          2526,
          2527,
          2528,
          2529,
          2530,
          2531,
          2532,
          2533,
          2534,
          2535,
          2536,
          2537,
          2538,
          2539,
          2540,
          2541,
          2542,
          2543,
          2544,
          2545,
          2546,
          2547,
          2548,
          2549,
          2550,
          2551,
          2552,
          2553,
          2554,
          2555,
          2556,
          2557,
          2558,
          2559,
          2560,
          2561,
          2562,
          2563,
          2564,
          2565,
          2566,
          2567,
          2568,
          2569,
          2570,
          2571,
          2572,
          2573,
          2574,
          2575,
          2576,
          2577,
          2578,
          2579,
          2580,
          2581,
          2582,
          2583,
          2584,
          2585,
          2586,
          2587,
          2588,
          2589,
          2590,
          2591,
          2592,
          2593,
          2594,
          2595,
          2596,
          2597,
          2598,
          2599,
          2600,
          2601,
          2602,
          2603,
          2604,
          2605,
          2606,
          2607,
          2608,
          2609,
          2610,
          2611,
          2612,
          2613,
          2614,
          2615,
          2616,
          2617,
          2618,
          2619,
          2620,
          2621,
          2622,
          2623,
          2624,
          2625,
          2626,
          2627,
          2628,
          2629,
          2630,
          2631,
          2632,
          2633,
          2634,
          2635,
          2636,
          2637,
          2638,
          2639,
          2640,
          2641,
          2642,
          2643,
          2644,
          2645,
          2646,
          2647,
          2648,
          2649,
          2650,
          2651,
          2652,
          2653,
          2654,
          2655,
          2656,
          2657,
          2658,
          2659,
          2660,
          2661,
          2662,
          2663,
          2664,
          2665,
          2666,
          2667,
          2668,
          2669,
          2670,
          2671,
          2672,
          2673,
          2674,
          2675,
          2676,
          2677,
          2678,
          2679,
          2680,
          2681,
          2682,
          2683,
          2684,
          2685,
          2686,
          2687,
          2688,
          2689,
          2690,
          2691,
          2692,
          2693,
          2694,
          2695,
          2696,
          2697,
          2698,
          2699,
          2700,
          2701,
          2702,
          2703,
          2704,
          2705,
          2706,
          2707,
          2708,
          2709,
          2710,
          2711,
          2712,
          2713,
          2714,
          2715,
          2716,
          2717,
          2718,
          2719,
          2720,
          2721,
          2722,
          2723,
          2724,
          2725,
          2726,
          2727,
          2728,
          2729,
          2730,
          2731,
          2732,
          2733,
          2734,
          2735,
          2736,
          2737,
          2738,
          2739,
          2740,
          2741,
          2742,
          2743,
          2744,
          2745,
          2746,
          2747,
          2748,
          2749,
          2750,
          2751,
          2752,
          2753,
          2754,
          2755,
          2756,
          2757,
          2758,
          2759,
          2760,
          2761,
          2762,
          2763,
          2764,
          2765,
          2766,
          2767,
          2768,
          2769,
          2770,
          2771,
          2772,
          2773,
          2774,
          2775,
          2776,
          2777,
          2778,
          2779,
          2780,
          2781,
          2782,
          2783,
          2784,
          2785,
          2786,
          2787,
          2788,
          2789,
          2790,
          2791,
          2792,
          2793,
          2794,
          2795,
          2796,
          2797,
          2798,
          2799,
          2800,
          2801,
          2802,
          2803,
          2804,
          2805,
          2806,
          2807,
          2808,
          2809,
          2810,
          2811,
          2812,
          2813,
          2814,
          2815,
          2816,
          2817,
          2818,
          2819,
          2820,
          2821,
          2822,
          2823,
          2824,
          2825,
          2826,
          2827,
          2828,
          2829,
          2830,
          2831,
          2832,
          2833,
          2834,
          2835,
          2836,
          2837,
          2838,
          2839,
          2840,
          2841,
          2842,
          2843,
          2844,
          2845,
          2846,
          2847,
          2848,
          2849,
          2850,
          2851,
          2852,
          2853,
          2854,
          2855,
          2856,
          2857,
          2858,
          2859,
          2860,
          2861,
          2862,
          2863,
          2864,
          2865,
          2866,
          2867,
          2868,
          2869,
          2870,
          2871,
          2872,
          2873,
          2874,
          2875,
          2876,
          2877,
          2878,
          2879,
          2880,
          2881,
          2882,
          2883,
          2884,
          2885,
          2886,
          2887,
          2888,
          2889,
          2890,
          2891,
          2892,
          2893,
          2894,
          2895,
          2896,
          2897,
          2898,
          2899,
          2900,
          2901,
          2902,
          2903,
          2904,
          2905,
          2906,
          2907,
          2908,
          2909,
          2910,
          2911,
          2912,
          2913,
          2914,
          2915,
          2916,
          2917,
          2918,
          2919,
          2920,
          2921,
          2922,
          2923,
          2924,
          2925,
          2926,
          2927,
          2928,
          2929,
          2930,
          2931,
          2932,
          2933,
          2934,
          2935,
          2936,
          2937,
          2938,
          2939,
          2940,
          2941,
          2942,
          2943,
          2944,
          2945,
          2946,
          2947,
          2948,
          2949,
          2950,
          2951,
          2952,
          2953,
          2954,
          2955,
          2956,
          2957,
          2958,
          2959,
          2960,
          2961,
          2962,
          2963,
          2964,
          2965,
          2966,
          2967,
          2968,
          2969,
          2970,
          2971,
          2972,
          2973,
          2974,
          2975,
          2976,
          2977,
          2978,
          2979,
          2980,
          2981,
          2982,
          2983,
          2984,
          2985,
          2986,
          2987,
          2988,
          2989,
          2990,
          2991,
          2992,
          2993,
          2994,
          2995,
          2996,
          2997,
          2998,
          2999,
          3000,
          3001,
          3002,
          3003,
          3004,
          3005,
          3006,
          3007,
          3008,
          3009,
          3010,
          3011,
          3012,
          3013,
          3014,
          3015,
          3016,
          3017,
          3018,
          3019,
          3020,
          3021,
          3022,
          3023,
          3024,
          3025,
          3026,
          3027,
          3028,
          3029,
          3030,
          3031,
          3032,
          3033,
          3034,
          3035,
          3036,
          3037,
          3038,
          3039,
          3040,
          3041,
          3042,
          3043,
          3044,
          3045,
          3046,
          3047,
          3048,
          3049,
          3050,
          3051,
          3052,
          3053,
          3054,
          3055,
          3056,
          3057,
          3058,
          3059,
          3060,
          3061,
          3062,
          3063,
          3064,
          3065,
          3066,
          3067,
          3068,
          3069,
          3070,
          3071,
          3072,
          3073,
          3074,
          3075,
          3076,
          3077,
          3078,
          3079,
          3080,
          3081,
          3082,
          3083,
          3084,
          3085,
          3086,
          3087,
          3088,
          3089,
          3090,
          3091,
          3092,
          3093,
          3094,
          3095,
          3096,
          3097,
          3098,
          3099,
          3100,
          3101,
          3102,
          3103,
          3104,
          3105,
          3106,
          3107,
          3108,
          3109,
          3110,
          3111,
          3112,
          3113,
          3114,
          3115,
          3116,
          3117,
          3118,
          3119,
          3120,
          3121,
          3122,
          3123,
          3124,
          3125,
          3126,
          3127,
          3128,
          3129,
          3130,
          3131,
          3132,
          3133,
          3134,
          3135,
          3136,
          3137,
          3138,
          3139,
          3140,
          3141,
          3142,
          3143,
          3144,
          3145,
          3146,
          3147,
          3148,
          3149,
          3150,
          3151,
          3152,
          3153,
          3154,
          3155,
          3156,
          3157,
          3158,
          3159,
          3160,
          3161,
          3162,
          3163,
          3164,
          3165,
          3166,
          3167,
          3168,
          3169,
          3170,
          3171,
          3172,
          3173,
          3174,
          3175,
          3176,
          3177,
          3178,
          3179,
          3180,
          3181,
          3182,
          3183,
          3184,
          3185,
          3186,
          3187,
          3188,
          3189,
          3190,
          3191,
          3192,
          3193,
          3194,
          3195,
          3196,
          3197,
          3198,
          3199,
          3200,
          3201,
          3202,
          3203,
          3204,
          3205,
          3206,
          3207,
          3208,
          3209,
          3210,
          3211,
          3212,
          3213,
          3214,
          3215,
          3216,
          3217,
          3218,
          3219,
          3220,
          3221,
          3222,
          3223,
          3224,
          3225,
          3226,
          3227,
          3228,
          3229,
          3230,
          3231,
          3232,
          3233,
          3234,
          3235,
          3236,
          3237,
          3238,
          3239,
          3240,
          3241,
          3242,
          3243,
          3244,
          3245,
          3246,
          3247,
          3248,
          3249,
          3250,
          3251,
          3252,
          3253,
          3254,
          3255,
          3256,
          3257,
          3258,
          3259,
          3260,
          3261,
          3262,
          3263,
          3264,
          3265,
          3266,
          3267,
          3268,
          3269,
          3270,
          3271,
          3272,
          3273,
          3274,
          3275,
          3276,
          3277,
          3278,
          3279,
          3280,
          3281,
          3282,
          3283,
          3284,
          3285,
          3286,
          3287,
          3288,
          3289,
          3290,
          3291,
          3292,
          3293,
          3294,
          3295,
          3296,
          3297,
          3298,
          3299,
          3300,
          3301,
          3302,
          3303,
          3304,
          3305,
          3306,
          3307,
          3308,
          3309,
          3310,
          3311,
          3312,
          3313,
          3314,
          3315,
          3316,
          3317,
          3318,
          3319,
          3320,
          3321,
          3322,
          3323,
          3324,
          3325,
          3326,
          3327,
          3328,
          3329,
          3330,
          3331,
          3332,
          3333,
          3334,
          3335,
          3336,
          3337,
          3338,
          3339,
          3340,
          3341,
          3342,
          3343,
          3344,
          3345,
          3346,
          3347,
          3348,
          3349,
          3350,
          3351,
          3352,
          3353,
          3354,
          3355,
          3356,
          3357,
          3358,
          3359,
          3360,
          3361,
          3362,
          3363,
          3364,
          3365,
          3366,
          3367,
          3368,
          3369,
          3370,
          3371,
          3372,
          3373,
          3374,
          3375,
          3376,
          3377,
          3378,
          3379,
          3380,
          3381,
          3382,
          3383,
          3384,
          3385,
          3386,
          3387,
          3388,
          3389,
          3390,
          3391,
          3392,
          3393,
          3394,
          3395,
          3396,
          3397,
          3398,
          3399,
          3400,
          3401,
          3402,
          3403,
          3404,
          3405,
          3406,
          3407,
          3408,
          3409,
          3410,
          3411,
          3412,
          3413,
          3414,
          3415,
          3416,
          3417,
          3418,
          3419,
          3420,
          3421,
          3422,
          3423,
          3424,
          3425,
          3426,
          3427,
          3428,
          3429,
          3430,
          3431,
          3432,
          3433,
          3434,
          3435,
          3436,
          3437,
          3438,
          3439,
          3440,
          3441,
          3442,
          3443,
          3444,
          3445,
          3446,
          3447,
          3448,
          3449,
          3450,
          3451,
          3452,
          3453,
          3454,
          3455,
          3456,
          3457,
          3458,
          3459,
          3460,
          3461,
          3462,
          3463,
          3464,
          3465,
          3466,
          3467,
          3468,
          3469,
          3470,
          3471,
          3472,
          3473,
          3474,
          3475,
          3476,
          3477,
          3478,
          3479,
          3480,
          3481,
          3482,
          3483,
          3484,
          3485,
          3486,
          3487,
          3488,
          3489,
          3490,
          3491,
          3492,
          3493,
          3494,
          3495,
          3496,
          3497,
          3498,
          3499,
          3500,
          3501,
          3502,
          3503,
          3504,
          3505,
          3506,
          3507,
          3508,
          3509,
          3510,
          3511,
          3512,
          3513,
          3514,
          3515,
          3516,
          3517,
          3518,
          3519,
          3520,
          3521,
          3522,
          3523,
          3524,
          3525,
          3526,
          3527,
          3528,
          3529,
          3530,
          3531,
          3532,
          3533,
          3534,
          3535,
          3536,
          3537,
          3538,
          3539,
          3540,
          3541,
          3542,
          3543,
          3544,
          3545,
          3546,
          3547,
          3548,
          3549,
          3550,
          3551,
          3552,
          3553,
          3554,
          3555,
          3556,
          3557,
          3558,
          3559,
          3560,
          3561,
          3562,
          3563,
          3564,
          3565,
          3566,
          3567,
          3568,
          3569,
          3570,
          3571,
          3572,
          3573,
          3574,
          3575,
          3576,
          3577,
          3578,
          3579,
          3580,
          3581,
          3582,
          3583,
          3584,
          3585,
          3586,
          3587,
          3588,
          3589,
          3590,
          3591,
          3592,
          3593,
          3594,
          3595,
          3596,
          3597,
          3598,
          3599,
          3600,
          3601,
          3602,
          3603,
          3604,
          3605,
          3606,
          3607,
          3608,
          3609,
          3610,
          3611,
          3612,
          3613,
          3614,
          3615,
          3616,
          3617,
          3618,
          3619,
          3620,
          3621,
          3622,
          3623,
          3624,
          3625,
          3626,
          3627,
          3628,
          3629,
          3630,
          3631,
          3632,
          3633,
          3634,
          3635,
          3636,
          3637,
          3638,
          3639,
          3640,
          3641,
          3642,
          3643,
          3644,
          3645,
          3646,
          3647,
          3648,
          3649,
          3650,
          3651,
          3652,
          3653,
          3654,
          3655,
          3656,
          3657,
          3658,
          3659,
          3660,
          3661,
          3662,
          3663,
          3664,
          3665,
          3666,
          3667,
          3668,
          3669,
          3670,
          3671,
          3672,
          3673,
          3674,
          3675,
          3676,
          3677,
          3678,
          3679,
          3680,
          3681,
          3682,
          3683,
          3684,
          3685,
          3686,
          3687,
          3688,
          3689,
          3690,
          3691,
          3692,
          3693,
          3694,
          3695,
          3696,
          3697,
          3698,
          3699,
          3700,
          3701,
          3702,
          3703,
          3704,
          3705,
          3706,
          3707,
          3708,
          3709,
          3710,
          3711,
          3712,
          3713,
          3714,
          3715,
          3716,
          3717,
          3718,
          3719,
          3720,
          3721,
          3722,
          3723,
          3724,
          3725,
          3726,
          3727,
          3728,
          3729,
          3730,
          3731,
          3732,
          3733,
          3734,
          3735,
          3736,
          3737,
          3738,
          3739,
          3740,
          3741,
          3742,
          3743,
          3744,
          3745,
          3746,
          3747,
          3748,
          3749,
          3750,
          3751,
          3752,
          3753,
          3754,
          3755,
          3756,
          3757,
          3758,
          3759,
          3760,
          3761,
          3762,
          3763,
          3764,
          3765,
          3766,
          3767,
          3768,
          3769,
          3770,
          3771,
          3772,
          3773,
          3774,
          3775,
          3776,
          3777,
          3778,
          3779,
          3780,
          3781,
          3782,
          3783,
          3784,
          3785,
          3786,
          3787,
          3788,
          3789,
          3790,
          3791,
          3792,
          3793,
          3794,
          3795,
          3796,
          3797,
          3798,
          3799,
          3800,
          3801,
          3802,
          3803,
          3804,
          3805,
          3806,
          3807,
          3808,
          3809,
          3810,
          3811,
          3812,
          3813,
          3814,
          3815,
          3816,
          3817,
          3818,
          3819,
          3820,
          3821,
          3822,
          3823,
          3824,
          3825,
          3826,
          3827,
          3828,
          3829,
          3830,
          3831,
          3832,
          3833,
          3834,
          3835,
          3836,
          3837,
          3838,
          3839,
          3840,
          3841,
          3842,
          3843,
          3844,
          3845,
          3846,
          3847,
          3848,
          3849,
          3850,
          3851,
          3852,
          3853,
          3854,
          3855,
          3856,
          3857,
          3858,
          3859,
          3860,
          3861,
          3862,
          3863,
          3864,
          3865,
          3866,
          3867,
          3868,
          3869,
          3870,
          3871,
          3872,
          3873,
          3874,
          3875,
          3876,
          3877,
          3878,
          3879,
          3880,
          3881,
          3882,
          3883,
          3884,
          3885,
          3886,
          3887,
          3888,
          3889,
          3890,
          3891,
          3892,
          3893,
          3894,
          3895,
          3896,
          3897,
          3898,
          3899,
          3900,
          3901,
          3902,
          3903,
          3904,
          3905,
          3906,
          3907,
          3908,
          3909,
          3910,
          3911,
          3912,
          3913,
          3914,
          3915,
          3916,
          3917,
          3918,
          3919,
          3920,
          3921,
          3922,
          3923,
          3924,
          3925,
          3926,
          3927,
          3928,
          3929,
          3930,
          3931,
          3932,
          3933,
          3934,
          3935,
          3936,
          3937,
          3938,
          3939,
          3940,
          3941,
          3942,
          3943,
          3944,
          3945,
          3946,
          3947,
          3948,
          3949,
          3950,
          3951,
          3952,
          3953,
          3954,
          3955,
          3956,
          3957,
          3958,
          3959,
          3960,
          3961,
          3962,
          3963,
          3964,
          3965,
          3966,
          3967,
          3968,
          3969,
          3970,
          3971,
          3972,
          3973,
          3974,
          3975,
          3976,
          3977,
          3978,
          3979,
          3980,
          3981,
          3982,
          3983,
          3984,
          3985,
          3986,
          3987,
          3988,
          3989,
          3990,
          3991,
          3992,
          3993,
          3994,
          3995,
          3996,
          3997,
          3998,
          3999,
          4000,
          4001,
          4002,
          4003,
          4004,
          4005,
          4006,
          4007,
          4008,
          4009,
          4010,
          4011,
          4012,
          4013,
          4014,
          4015,
          4016,
          4017,
          4018,
          4019,
          4020,
          4021,
          4022,
          4023,
          4024,
          4025,
          4026,
          4027,
          4028,
          4029,
          4030,
          4031,
          4032,
          4033,
          4034,
          4035,
          4036,
          4037,
          4038,
          4039,
          4040,
          4041,
          4042,
          4043,
          4044,
          4045,
          4046,
          4047,
          4048,
          4049,
          4050,
          4051,
          4052,
          4053,
          4054,
          4055,
          4056,
          4057,
          4058,
          4059,
          4060,
          4061,
          4062,
          4063,
          4064,
          4065,
          4066,
          4067,
          4068,
          4069,
          4070,
          4071,
          4072,
          4073,
          4074,
          4075,
          4076,
          4077,
          4078,
          4079,
          4080,
          4081,
          4082,
          4083,
          4084,
          4085,
          4086,
          4087,
          4088,
          4089,
          4090,
          4091,
          4092,
          4093,
          4094,
          4095,
          4096,
          4097,
          4098,
          4099,
          4100,
          4101,
          4102,
          4103,
          4104,
          4105,
          4106,
          4107,
          4108,
          4109,
          4110,
          4111,
          4112,
          4113,
          4114,
          4115,
          4116,
          4117,
          4118,
          4119,
          4120,
          4121,
          4122,
          4123,
          4124,
          4125,
          4126,
          4127,
          4128,
          4129,
          4130,
          4131,
          4132,
          4133,
          4134,
          4135,
          4136,
          4137,
          4138,
          4139,
          4140,
          4141,
          4142,
          4143,
          4144,
          4145,
          4146,
          4147,
          4148,
          4149,
          4150,
          4151,
          4152,
          4153,
          4154,
          4155,
          4156,
          4157,
          4158,
          4159,
          4160,
          4161,
          4162,
          4163,
          4164,
          4165,
          4166,
          4167,
          4168,
          4169,
          4170,
          4171,
          4172,
          4173,
          4174,
          4175,
          4176,
          4177,
          4178,
          4179,
          4180,
          4181,
          4182,
          4183,
          4184,
          4185,
          4186,
          4187,
          4188,
          4189,
          4190,
          4191,
          4192,
          4193,
          4194,
          4195,
          4196,
          4197,
          4198,
          4199,
          4200,
          4201,
          4202,
          4203,
          4204,
          4205,
          4206,
          4207,
          4208,
          4209,
          4210,
          4211,
          4212,
          4213,
          4214,
          4215,
          4216,
          4217,
          4218,
          4219,
          4220,
          4221,
          4222,
          4223,
          4224,
          4225,
          4226,
          4227,
          4228,
          4229,
          4230,
          4231,
          4232,
          4233,
          4234,
          4235,
          4236,
          4237,
          4238,
          4239,
          4240,
          4241,
          4242,
          4243,
          4244,
          4245,
          4246,
          4247,
          4248,
          4249,
          4250,
          4251,
          4252,
          4253,
          4254,
          4255,
          4256,
          4257,
          4258,
          4259,
          4260,
          4261,
          4262,
          4263,
          4264,
          4265,
          4266,
          4267,
          4268,
          4269,
          4270,
          4271,
          4272,
          4273,
          4274,
          4275,
          4276,
          4277,
          4278,
          4279,
          4280,
          4281,
          4282,
          4283,
          4284,
          4285,
          4286,
          4287,
          4288,
          4289,
          4290,
          4291,
          4292,
          4293,
          4294,
          4295,
          4296,
          4297,
          4298,
          4299,
          4300,
          4301,
          4302,
          4303,
          4304,
          4305,
          4306,
          4307,
          4308,
          4309,
          4310,
          4311,
          4312,
          4313,
          4314,
          4315,
          4316,
          4317,
          4318,
          4319,
          4320,
          4321,
          4322,
          4323,
          4324,
          4325,
          4326,
          4327,
          4328,
          4329,
          4330,
          4331,
          4332,
          4333,
          4334,
          4335,
          4336,
          4337,
          4338,
          4339,
          4340,
          4341,
          4342,
          4343,
          4344,
          4345,
          4346,
          4347,
          4348,
          4349,
          4350,
          4351,
          4352,
          4353,
          4354,
          4355,
          4356,
          4357,
          4358,
          4359,
          4360,
          4361,
          4362,
          4363,
          4364,
          4365,
          4366,
          4367,
          4368,
          4369,
          4370,
          4371,
          4372,
          4373,
          4374,
          4375,
          4376,
          4377,
          4378,
          4379,
          4380,
          4381,
          4382,
          4383,
          4384,
          4385,
          4386,
          4387,
          4388,
          4389,
          4390,
          4391,
          4392,
          4393,
          4394,
          4395,
          4396,
          4397,
          4398,
          4399,
          4400,
          4401,
          4402,
          4403,
          4404,
          4405,
          4406,
          4407,
          4408,
          4409,
          4410,
          4411,
          4412,
          4413,
          4414,
          4415,
          4416,
          4417,
          4418,
          4419,
          4420,
          4421,
          4422,
          4423,
          4424,
          4425,
          4426,
          4427,
          4428,
          4429,
          4430,
          4431,
          4432,
          4433,
          4434,
          4435,
          4436,
          4437,
          4438,
          4439,
          4440,
          4441,
          4442,
          4443,
          4444,
          4445,
          4446,
          4447,
          4448,
          4449,
          4450,
          4451,
          4452,
          4453,
          4454,
          4455,
          4456,
          4457,
          4458,
          4459,
          4460,
          4461,
          4462,
          4463,
          4464,
          4465,
          4466,
          4467,
          4468,
          4469,
          4470,
          4471,
          4472,
          4473,
          4474,
          4475,
          4476,
          4477,
          4478,
          4479,
          4480,
          4481,
          4482,
          4483,
          4484,
          4485,
          4486,
          4487,
          4488,
          4489,
          4490,
          4491,
          4492,
          4493,
          4494,
          4495,
          4496,
          4497,
          4498,
          4499,
          4500,
          4501,
          4502,
          4503,
          4504,
          4505,
          4506,
          4507,
          4508,
          4509,
          4510,
          4511,
          4512,
          4513,
          4514,
          4515,
          4516,
          4517,
          4518,
          4519,
          4520,
          4521,
          4522,
          4523,
          4524,
          4525,
          4526,
          4527,
          4528,
          4529,
          4530,
          4531,
          4532,
          4533,
          4534,
          4535,
          4536,
          4537,
          4538,
          4539,
          4540,
          4541,
          4542,
          4543,
          4544,
          4545,
          4546,
          4547,
          4548,
          4549,
          4550,
          4551,
          4552,
          4553,
          4554,
          4555,
          4556,
          4557,
          4558,
          4559,
          4560,
          4561,
          4562,
          4563,
          4564,
          4565,
          4566,
          4567,
          4568,
          4569,
          4570,
          4571,
          4572,
          4573,
          4574,
          4575,
          4576,
          4577,
          4578,
          4579,
          4580,
          4581,
          4582,
          4583,
          4584,
          4585,
          4586,
          4587,
          4588,
          4589,
          4590,
          4591,
          4592,
          4593,
          4594,
          4595,
          4596,
          4597,
          4598,
          4599,
          4600,
          4601,
          4602,
          4603,
          4604,
          4605,
          4606,
          4607,
          4608,
          4609,
          4610,
          4611,
          4612,
          4613,
          4614,
          4615,
          4616,
          4617,
          4618,
          4619,
          4620,
          4621,
          4622,
          4623,
          4624,
          4625,
          4626,
          4627,
          4628,
          4629,
          4630,
          4631,
          4632,
          4633,
          4634,
          4635,
          4636,
          4637,
          4638,
          4639,
          4640,
          4641,
          4642,
          4643,
          4644,
          4645,
          4646,
          4647,
          4648,
          4649,
          4650,
          4651,
          4652,
          4653,
          4654,
          4655,
          4656,
          4657,
          4658,
          4659,
          4660,
          4661,
          4662,
          4663,
          4664,
          4665,
          4666,
          4667,
          4668,
          4669,
          4670,
          4671,
          4672,
          4673,
          4674,
          4675,
          4676,
          4677,
          4678,
          4679,
          4680,
          4681,
          4682,
          4683,
          4684,
          4685,
          4686,
          4687,
          4688,
          4689,
          4690,
          4691,
          4692,
          4693,
          4694,
          4695,
          4696,
          4697,
          4698,
          4699,
          4700,
          4701,
          4702,
          4703,
          4704,
          4705,
          4706,
          4707,
          4708,
          4709,
          4710,
          4711,
          4712,
          4713,
          4714,
          4715,
          4716,
          4717,
          4718,
          4719,
          4720,
          4721,
          4722,
          4723,
          4724,
          4725,
          4726,
          4727,
          4728,
          4729,
          4730,
          4731,
          4732,
          4733,
          4734,
          4735,
          4736,
          4737,
          4738,
          4739,
          4740,
          4741,
          4742,
          4743,
          4744,
          4745,
          4746,
          4747,
          4748,
          4749,
          4750,
          4751,
          4752,
          4753,
          4754,
          4755,
          4756,
          4757,
          4758,
          4759,
          4760,
          4761,
          4762,
          4763,
          4764,
          4765,
          4766,
          4767,
          4768,
          4769,
          4770,
          4771,
          4772,
          4773,
          4774,
          4775,
          4776,
          4777,
          4778,
          4779,
          4780,
          4781,
          4782,
          4783,
          4784,
          4785,
          4786,
          4787,
          4788,
          4789,
          4790,
          4791,
          4792,
          4793,
          4794,
          4795,
          4796,
          4797,
          4798,
          4799,
          4800,
          4801,
          4802,
          4803,
          4804,
          4805,
          4806,
          4807,
          4808,
          4809,
          4810,
          4811,
          4812,
          4813,
          4814,
          4815,
          4816,
          4817,
          4818,
          4819,
          4820,
          4821,
          4822,
          4823,
          4824,
          4825,
          4826,
          4827,
          4828,
          4829,
          4830,
          4831,
          4832,
          4833,
          4834,
          4835,
          4836,
          4837,
          4838,
          4839,
          4840,
          4841,
          4842,
          4843,
          4844,
          4845,
          4846,
          4847,
          4848,
          4849,
          4850,
          4851,
          4852,
          4853,
          4854,
          4855,
          4856,
          4857,
          4858,
          4859,
          4860,
          4861,
          4862,
          4863,
          4864,
          4865,
          4866,
          4867,
          4868,
          4869,
          4870,
          4871,
          4872,
          4873,
          4874,
          4875,
          4876,
          4877,
          4878,
          4879,
          4880,
          4881,
          4882,
          4883,
          4884,
          4885,
          4886,
          4887,
          4888,
          4889,
          4890,
          4891,
          4892,
          4893,
          4894,
          4895,
          4896,
          4897,
          4898,
          4899,
          4900,
          4901,
          4902,
          4903,
          4904,
          4905,
          4906,
          4907,
          4908,
          4909,
          4910,
          4911,
          4912,
          4913,
          4914,
          4915,
          4916,
          4917,
          4918,
          4919,
          4920,
          4921,
          4922,
          4923,
          4924,
          4925,
          4926,
          4927,
          4928,
          4929,
          4930,
          4931,
          4932,
          4933,
          4934,
          4935,
          4936,
          4937,
          4938,
          4939,
          4940,
          4941,
          4942,
          4943,
          4944,
          4945,
          4946,
          4947,
          4948,
          4949,
          4950,
          4951,
          4952,
          4953,
          4954,
          4955,
          4956,
          4957,
          4958,
          4959,
          4960,
          4961,
          4962,
          4963,
          4964,
          4965,
          4966,
          4967,
          4968,
          4969,
          4970,
          4971,
          4972,
          4973,
          4974,
          4975,
          4976,
          4977,
          4978,
          4979,
          4980,
          4981,
          4982,
          4983,
          4984,
          4985,
          4986,
          4987,
          4988,
          4989,
          4990,
          4991,
          4992,
          4993,
          4994,
          4995,
          4996,
          4997,
          4998,
          4999
         ],
         "xaxis": "x",
         "y": [
          -106.73333333333333,
          -118.43333333333334,
          -121.83333333333333,
          -133.06666666666666,
          -144.96666666666667,
          -134.93333333333334,
          -172.36666666666667,
          -163.8,
          -159.6,
          -179.76666666666668,
          -153.9,
          -181.93333333333334,
          -201.83333333333334,
          -232.66666666666666,
          -208.7,
          -186.8,
          -170.16666666666666,
          -180.5,
          -157.3,
          -186.06666666666666,
          -175.43333333333334,
          -175.1,
          -168.23333333333332,
          -171.76666666666668,
          -152.46666666666667,
          -176.66666666666666,
          -169.13333333333333,
          -165.3,
          -172.1,
          -162.6,
          -152.5,
          -179.1,
          -137.96666666666667,
          -174.5,
          -154.7,
          -155.4,
          -141.2,
          -188.5,
          -158.43333333333334,
          -149.7,
          -150.43333333333334,
          -154.9,
          -148.93333333333334,
          -146.56666666666666,
          -168.83333333333334,
          -142.7,
          -149.16666666666666,
          -151.36666666666667,
          -140.7,
          -147.93333333333334,
          -143.1,
          -164.83333333333334,
          -137.93333333333334,
          -145.8,
          -142.13333333333333,
          -140.66666666666666,
          -149.83333333333334,
          -134.63333333333333,
          -134.1,
          -151.33333333333334,
          -146.9,
          -124.16666666666667,
          -142.4,
          -139.1,
          -134.93333333333334,
          -136.53333333333333,
          -140.5,
          -127.8,
          -135.56666666666666,
          -131.96666666666667,
          -138.26666666666668,
          -133.8,
          -120.9,
          -126.63333333333334,
          -130.26666666666668,
          -130.9,
          -128,
          -116,
          -118.06666666666666,
          -135.56666666666666,
          -124.86666666666666,
          -116.4,
          -121.53333333333333,
          -125.16666666666667,
          -122.23333333333333,
          -111.66666666666667,
          -121.43333333333334,
          -127,
          -108.06666666666666,
          -121.33333333333333,
          -120.4,
          -124.16666666666667,
          -109,
          -122.13333333333334,
          -108.63333333333334,
          -109.2,
          -119.46666666666667,
          -111.83333333333333,
          -112.8,
          -116.2,
          -103.63333333333334,
          -105.96666666666667,
          -123,
          -97,
          -108,
          -113.53333333333333,
          -93.83333333333333,
          -111.93333333333334,
          -106.2,
          -98.96666666666667,
          -104.5,
          -98.1,
          -93.93333333333334,
          -107.2,
          -103.6,
          -97.1,
          -98.13333333333334,
          -99.3,
          -102.3,
          -102.63333333333334,
          -90.2,
          -99.93333333333334,
          -103.23333333333333,
          -90.76666666666667,
          -91.13333333333334,
          -112.96666666666667,
          -82.43333333333334,
          -99.7,
          -92.83333333333333,
          -94.46666666666667,
          -84.43333333333334,
          -96.03333333333333,
          -80.76666666666667,
          -92.83333333333333,
          -84.56666666666666,
          -90.23333333333333,
          -79.73333333333333,
          -91.36666666666666,
          -98.96666666666667,
          -81.66666666666667,
          -86.6,
          -80.23333333333333,
          -83.66666666666667,
          -76.4,
          -97.83333333333333,
          -77.53333333333333,
          -80.03333333333333,
          -94.16666666666667,
          -79.86666666666666,
          -77.3,
          -89.9,
          -83.66666666666667,
          -88.43333333333334,
          -77.36666666666666,
          -78.73333333333333,
          -83.86666666666666,
          -78.7,
          -80.53333333333333,
          -77.23333333333333,
          -77.2,
          -76.43333333333334,
          -80.56666666666666,
          -74,
          -84.86666666666666,
          -64.7,
          -81.46666666666667,
          -76.26666666666667,
          -78,
          -68.76666666666667,
          -78.3,
          -70.63333333333334,
          -73.23333333333333,
          -71.16666666666667,
          -66.9,
          -79.4,
          -74.9,
          -71.53333333333333,
          -69.83333333333333,
          -61.46666666666667,
          -69.56666666666666,
          -81.06666666666666,
          -64.33333333333333,
          -68.9,
          -70.33333333333333,
          -67.56666666666666,
          -71.86666666666666,
          -61.53333333333333,
          -69.56666666666666,
          -70.76666666666667,
          -68.46666666666667,
          -65.8,
          -70.16666666666667,
          -64.96666666666667,
          -63.03333333333333,
          -62.86666666666667,
          -69.4,
          -62.9,
          -57.1,
          -66.86666666666666,
          -64.4,
          -61.5,
          -67.6,
          -64.5,
          -60.333333333333336,
          -65.96666666666667,
          -56.63333333333333,
          -70.13333333333334,
          -60.666666666666664,
          -57.666666666666664,
          -54.4,
          -64.1,
          -52.86666666666667,
          -61.266666666666666,
          -66.86666666666666,
          -58.3,
          -61.43333333333333,
          -66.7,
          -57.46666666666667,
          -58.86666666666667,
          -58.666666666666664,
          -57.43333333333333,
          -58.43333333333333,
          -57.56666666666667,
          -59.63333333333333,
          -53,
          -54.2,
          -57.766666666666666,
          -58.86666666666667,
          -55.1,
          -48.733333333333334,
          -54.53333333333333,
          -54.03333333333333,
          -50.36666666666667,
          -50.96666666666667,
          -57.96666666666667,
          -57.43333333333333,
          -55.733333333333334,
          -50.36666666666667,
          -53.9,
          -50.166666666666664,
          -56.43333333333333,
          -58.06666666666667,
          -57.06666666666667,
          -50.3,
          -53.5,
          -51.86666666666667,
          -50.03333333333333,
          -47.36666666666667,
          -58.36666666666667,
          -44.666666666666664,
          -49.266666666666666,
          -54.733333333333334,
          -50.43333333333333,
          -52.333333333333336,
          -49.166666666666664,
          -48.46666666666667,
          -56.7,
          -49.766666666666666,
          -51.833333333333336,
          -49.7,
          -50.63333333333333,
          -47.03333333333333,
          -54.63333333333333,
          -46.3,
          -55.333333333333336,
          -43.166666666666664,
          -52.266666666666666,
          -42.8,
          -50.9,
          -48.766666666666666,
          -48.1,
          -48.7,
          -46.96666666666667,
          -46.766666666666666,
          -45.6,
          -42,
          -43.3,
          -47.1,
          -50.6,
          -41,
          -46.93333333333333,
          -47.6,
          -39.53333333333333,
          -49.6,
          -45.6,
          -44.43333333333333,
          -48.766666666666666,
          -45.6,
          -42.266666666666666,
          -42.4,
          -49.13333333333333,
          -36.46666666666667,
          -39.06666666666667,
          -46.5,
          -45.233333333333334,
          -41.93333333333333,
          -48.93333333333333,
          -37.9,
          -43,
          -43.833333333333336,
          -37.43333333333333,
          -38.166666666666664,
          -43.06666666666667,
          -48.5,
          -39.266666666666666,
          -45.8,
          -39.666666666666664,
          -40.7,
          -44.333333333333336,
          -36.833333333333336,
          -40.46666666666667,
          -44.9,
          -35.5,
          -40.43333333333333,
          -38.3,
          -37.53333333333333,
          -42.3,
          -36.2,
          -37.1,
          -40.03333333333333,
          -44.5,
          -41.5,
          -40.06666666666667,
          -43.1,
          -41.4,
          -37.93333333333333,
          -36.36666666666667,
          -35.13333333333333,
          -38.53333333333333,
          -37.36666666666667,
          -36.46666666666667,
          -37.96666666666667,
          -40.333333333333336,
          -35.9,
          -35.233333333333334,
          -39.86666666666667,
          -34.7,
          -39.166666666666664,
          -36.233333333333334,
          -37.333333333333336,
          -36,
          -35.4,
          -36.7,
          -33.833333333333336,
          -38.8,
          -38.3,
          -35.5,
          -34.666666666666664,
          -39.166666666666664,
          -37.53333333333333,
          -32.2,
          -36.06666666666667,
          -32.13333333333333,
          -36.5,
          -36.93333333333333,
          -32.4,
          -37.96666666666667,
          -31.5,
          -35.63333333333333,
          -32,
          -29.233333333333334,
          -35.1,
          -37.5,
          -32.6,
          -32.833333333333336,
          -33.8,
          -32.96666666666667,
          -34.5,
          -39.06666666666667,
          -31.8,
          -37.53333333333333,
          -31.666666666666668,
          -36.9,
          -31.466666666666665,
          -29.666666666666668,
          -34.833333333333336,
          -33.266666666666666,
          -33.733333333333334,
          -30.7,
          -33.63333333333333,
          -34.36666666666667,
          -33,
          -34.6,
          -30.633333333333333,
          -32.13333333333333,
          -32.8,
          -31.2,
          -31.533333333333335,
          -31.8,
          -29.066666666666666,
          -34.96666666666667,
          -33.46666666666667,
          -31.966666666666665,
          -31.033333333333335,
          -28.8,
          -31.966666666666665,
          -29.7,
          -31.1,
          -35.36666666666667,
          -31.833333333333332,
          -26.333333333333332,
          -31.433333333333334,
          -31.366666666666667,
          -31.3,
          -34.266666666666666,
          -30.733333333333334,
          -28.033333333333335,
          -28.633333333333333,
          -31.3,
          -29.666666666666668,
          -28.433333333333334,
          -30.266666666666666,
          -35.63333333333333,
          -29.066666666666666,
          -31.9,
          -31.933333333333334,
          -29.566666666666666,
          -28.366666666666667,
          -26.966666666666665,
          -27.833333333333332,
          -28.233333333333334,
          -31.9,
          -31.633333333333333,
          -27.7,
          -33.166666666666664,
          -35.7,
          -30.033333333333335,
          -27.133333333333333,
          -29.733333333333334,
          -28.733333333333334,
          -31.066666666666666,
          -28.066666666666666,
          -27.333333333333332,
          -31.8,
          -28.6,
          -28.2,
          -31,
          -31.3,
          -29.033333333333335,
          -22.866666666666667,
          -30.8,
          -29.266666666666666,
          -28.133333333333333,
          -26.366666666666667,
          -31.333333333333332,
          -25.5,
          -30.066666666666666,
          -33.43333333333333,
          -25.266666666666666,
          -28.033333333333335,
          -38.03333333333333,
          -33.36666666666667,
          -30.7,
          -27.966666666666665,
          -24.133333333333333,
          -34.1,
          -29.033333333333335,
          -31.7,
          -26.9,
          -29.666666666666668,
          -36.43333333333333,
          -32.53333333333333,
          -26.266666666666666,
          -24.733333333333334,
          -24.066666666666666,
          -30.866666666666667,
          -24.566666666666666,
          -23.733333333333334,
          -26.466666666666665,
          -25.266666666666666,
          -23.666666666666668,
          -28.433333333333334,
          -25.633333333333333,
          -23.8,
          -24.833333333333332,
          -30.8,
          -25.333333333333332,
          -27.2,
          -26.1,
          -23.333333333333332,
          -26.533333333333335,
          -25.266666666666666,
          -22.433333333333334,
          -22.566666666666666,
          -26.2,
          -27.666666666666668,
          -28.466666666666665,
          -26.833333333333332,
          -35.63333333333333,
          -22.866666666666667,
          -25.4,
          -26.633333333333333,
          -21.3,
          -33.36666666666667,
          -29.1,
          -29.633333333333333,
          -25.3,
          -25.766666666666666,
          -25.133333333333333,
          -29.233333333333334,
          -22.833333333333332,
          -24,
          -26.033333333333335,
          -22.266666666666666,
          -24.433333333333334,
          -24.833333333333332,
          -25.166666666666668,
          -23.3,
          -30.433333333333334,
          -23.366666666666667,
          -26.266666666666666,
          -21.866666666666667,
          -28.233333333333334,
          -25.166666666666668,
          -29.866666666666667,
          -25.2,
          -25.233333333333334,
          -21.566666666666666,
          -21,
          -26.7,
          -20.866666666666667,
          -25.966666666666665,
          -22.9,
          -26.8,
          -30,
          -20.333333333333332,
          -22.133333333333333,
          -26.133333333333333,
          -20.466666666666665,
          -23.033333333333335,
          -21.433333333333334,
          -25.033333333333335,
          -20.866666666666667,
          -25.266666666666666,
          -22.733333333333334,
          -23.7,
          -23.133333333333333,
          -22.166666666666668,
          -21.766666666666666,
          -21.433333333333334,
          -27.766666666666666,
          -22.766666666666666,
          -24.7,
          -20.166666666666668,
          -21.466666666666665,
          -25.666666666666668,
          -23.066666666666666,
          -18.433333333333334,
          -27.333333333333332,
          -27.5,
          -18.7,
          -24.5,
          -20.433333333333334,
          -21.866666666666667,
          -26.666666666666668,
          -21.133333333333333,
          -21.466666666666665,
          -20.7,
          -20.033333333333335,
          -25.233333333333334,
          -18.466666666666665,
          -26.833333333333332,
          -21.4,
          -19.3,
          -18.733333333333334,
          -23.733333333333334,
          -27.533333333333335,
          -19.166666666666668,
          -22.433333333333334,
          -20.366666666666667,
          -21.266666666666666,
          -24.6,
          -19.633333333333333,
          -20.033333333333335,
          -20.2,
          -23.8,
          -23.033333333333335,
          -27.2,
          -20.933333333333334,
          -22.133333333333333,
          -17.8,
          -23.533333333333335,
          -20.566666666666666,
          -17.966666666666665,
          -24,
          -21.466666666666665,
          -21.966666666666665,
          -20.433333333333334,
          -20.6,
          -23.966666666666665,
          -18.133333333333333,
          -17.2,
          -25,
          -19.266666666666666,
          -22.8,
          -24.433333333333334,
          -20.7,
          -20.166666666666668,
          -25.466666666666665,
          -18.433333333333334,
          -23.033333333333335,
          -21.8,
          -18.6,
          -21.966666666666665,
          -22.6,
          -18.4,
          -23.2,
          -18.033333333333335,
          -19.366666666666667,
          -18.2,
          -19.233333333333334,
          -21.3,
          -18.466666666666665,
          -17.933333333333334,
          -22.433333333333334,
          -20.533333333333335,
          -17,
          -24.033333333333335,
          -19.266666666666666,
          -21.566666666666666,
          -19.566666666666666,
          -19.866666666666667,
          -21.666666666666668,
          -17.366666666666667,
          -21.333333333333332,
          -21.866666666666667,
          -27.133333333333333,
          -23.7,
          -25.466666666666665,
          -18.8,
          -18.433333333333334,
          -18.833333333333332,
          -19.3,
          -15.4,
          -20.933333333333334,
          -17.866666666666667,
          -20.133333333333333,
          -18.733333333333334,
          -20.666666666666668,
          -20.533333333333335,
          -18.933333333333334,
          -19.766666666666666,
          -21.1,
          -16.6,
          -18,
          -20.866666666666667,
          -17.7,
          -20.4,
          -18.466666666666665,
          -20.666666666666668,
          -27.9,
          -22.2,
          -20.566666666666666,
          -19,
          -17.6,
          -19.9,
          -17.9,
          -18.466666666666665,
          -15.933333333333334,
          -17.033333333333335,
          -17.133333333333333,
          -16.333333333333332,
          -18.266666666666666,
          -17.666666666666668,
          -17.466666666666665,
          -18.566666666666666,
          -20.666666666666668,
          -19.8,
          -21.6,
          -17.3,
          -18.033333333333335,
          -18.466666666666665,
          -20.266666666666666,
          -20.2,
          -21.666666666666668,
          -18.8,
          -16.4,
          -16.166666666666668,
          -15.8,
          -17.433333333333334,
          -15.866666666666667,
          -18.533333333333335,
          -15.833333333333334,
          -19.2,
          -20.133333333333333,
          -19.866666666666667,
          -19.566666666666666,
          -16.466666666666665,
          -18.133333333333333,
          -18.7,
          -18.866666666666667,
          -16.5,
          -20.566666666666666,
          -21.666666666666668,
          -18.8,
          -23.466666666666665,
          -19.133333333333333,
          -24.1,
          -16.066666666666666,
          -18.166666666666668,
          -19.366666666666667,
          -16.033333333333335,
          -20.933333333333334,
          -20.033333333333335,
          -19.3,
          -14.1,
          -15.2,
          -13.866666666666667,
          -20.466666666666665,
          -15.733333333333333,
          -21.866666666666667,
          -16.033333333333335,
          -16.266666666666666,
          -19.366666666666667,
          -13.6,
          -25.233333333333334,
          -17.066666666666666,
          -15.4,
          -15.766666666666667,
          -15.533333333333333,
          -16.5,
          -14.866666666666667,
          -19.4,
          -18.266666666666666,
          -18.233333333333334,
          -14.6,
          -14.8,
          -25.066666666666666,
          -22.166666666666668,
          -21.866666666666667,
          -16.666666666666668,
          -18.733333333333334,
          -16.2,
          -13.933333333333334,
          -16.066666666666666,
          -15.666666666666666,
          -15.833333333333334,
          -15.333333333333334,
          -22.333333333333332,
          -22.433333333333334,
          -17.666666666666668,
          -15.033333333333333,
          -17.966666666666665,
          -14.7,
          -16.733333333333334,
          -13.966666666666667,
          -14.666666666666666,
          -18.566666666666666,
          -14.533333333333333,
          -16.8,
          -15.533333333333333,
          -13.8,
          -14.8,
          -15.833333333333334,
          -12.6,
          -14.466666666666667,
          -13.566666666666666,
          -18.566666666666666,
          -15.066666666666666,
          -19.933333333333334,
          -19.066666666666666,
          -17.7,
          -14.266666666666667,
          -14.866666666666667,
          -18.666666666666668,
          -15.466666666666667,
          -13.233333333333333,
          -21.466666666666665,
          -17.933333333333334,
          -14.9,
          -17.1,
          -18.533333333333335,
          -14.366666666666667,
          -13.8,
          -19.866666666666667,
          -12.7,
          -13.366666666666667,
          -20.6,
          -17.1,
          -13.8,
          -19.566666666666666,
          -20.066666666666666,
          -17.866666666666667,
          -18.166666666666668,
          -17.7,
          -13.133333333333333,
          -14.366666666666667,
          -16.666666666666668,
          -14.233333333333333,
          -13.366666666666667,
          -20.366666666666667,
          -19.366666666666667,
          -13.233333333333333,
          -16.233333333333334,
          -17.7,
          -16.433333333333334,
          -16.7,
          -17.1,
          -13.7,
          -12.533333333333333,
          -14,
          -15.033333333333333,
          -14.333333333333334,
          -13.466666666666667,
          -19.233333333333334,
          -15,
          -23.066666666666666,
          -19.366666666666667,
          -16.4,
          -17.033333333333335,
          -16.433333333333334,
          -13.233333333333333,
          -14.266666666666667,
          -16.266666666666666,
          -12.966666666666667,
          -13.633333333333333,
          -19.7,
          -13.266666666666667,
          -12.4,
          -15.833333333333334,
          -13.8,
          -15.2,
          -15.833333333333334,
          -12.433333333333334,
          -13.133333333333333,
          -15.5,
          -16.166666666666668,
          -12.966666666666667,
          -14.5,
          -19.833333333333332,
          -12.966666666666667,
          -17.833333333333332,
          -18.666666666666668,
          -12.566666666666666,
          -16.933333333333334,
          -12.933333333333334,
          -13.8,
          -13.833333333333334,
          -12.1,
          -13.266666666666667,
          -16.066666666666666,
          -12.833333333333334,
          -12.433333333333334,
          -13.4,
          -13.666666666666666,
          -14.066666666666666,
          -12.1,
          -19.633333333333333,
          -13.1,
          -12.733333333333333,
          -20.333333333333332,
          -16.933333333333334,
          -16.166666666666668,
          -13.733333333333333,
          -16.5,
          -16.4,
          -12.7,
          -13.333333333333334,
          -15.966666666666667,
          -13.7,
          -17.9,
          -12.066666666666666,
          -16.433333333333334,
          -15.433333333333334,
          -12.4,
          -11.833333333333334,
          -16.066666666666666,
          -15.3,
          -11.933333333333334,
          -16.166666666666668,
          -16.733333333333334,
          -11.966666666666667,
          -12.7,
          -16.1,
          -11.9,
          -13.1,
          -16.333333333333332,
          -17.933333333333334,
          -12.5,
          -15.766666666666667,
          -12.6,
          -15.666666666666666,
          -14.733333333333333,
          -12.233333333333333,
          -15.1,
          -12.133333333333333,
          -12,
          -12.1,
          -15.6,
          -12.433333333333334,
          -13,
          -16.2,
          -11.566666666666666,
          -13.733333333333333,
          -21.833333333333332,
          -12.266666666666667,
          -12.533333333333333,
          -15.466666666666667,
          -19.266666666666666,
          -14.966666666666667,
          -18.2,
          -11.466666666666667,
          -11.833333333333334,
          -17.9,
          -11.833333333333334,
          -12.633333333333333,
          -18.766666666666666,
          -18.366666666666667,
          -18.5,
          -14.9,
          -11.833333333333334,
          -14.633333333333333,
          -15.366666666666667,
          -11.766666666666667,
          -15,
          -17.4,
          -11.766666666666667,
          -15.133333333333333,
          -12.466666666666667,
          -18.7,
          -18.433333333333334,
          -18.5,
          -15.9,
          -11.933333333333334,
          -11.766666666666667,
          -16.366666666666667,
          -15.1,
          -15.266666666666667,
          -15.533333333333333,
          -11.933333333333334,
          -11.833333333333334,
          -18.066666666666666,
          -17.7,
          -15.166666666666666,
          -12.633333333333333,
          -15.933333333333334,
          -15.3,
          -12.066666666666666,
          -15.633333333333333,
          -15.233333333333333,
          -12.733333333333333,
          -11.366666666666667,
          -11.533333333333333,
          -11.7,
          -11.966666666666667,
          -12.566666666666666,
          -11.4,
          -12.133333333333333,
          -14.566666666666666,
          -14.866666666666667,
          -11.766666666666667,
          -14.966666666666667,
          -12.166666666666666,
          -19.033333333333335,
          -15.033333333333333,
          -11.933333333333334,
          -12.166666666666666,
          -12.6,
          -14.233333333333333,
          -15.566666666666666,
          -11.533333333333333,
          -14.666666666666666,
          -15.5,
          -17.266666666666666,
          -17.766666666666666,
          -12.233333333333333,
          -14.566666666666666,
          -14.633333333333333,
          -11.7,
          -17.533333333333335,
          -17.266666666666666,
          -11.333333333333334,
          -11.466666666666667,
          -15.366666666666667,
          -14.433333333333334,
          -14.266666666666667,
          -17.566666666666666,
          -14.866666666666667,
          -14.866666666666667,
          -14.466666666666667,
          -11.3,
          -15.333333333333334,
          -11.9,
          -12.466666666666667,
          -14.3,
          -17.866666666666667,
          -12.066666666666666,
          -14.333333333333334,
          -17.566666666666666,
          -11.433333333333334,
          -21.033333333333335,
          -15.133333333333333,
          -11.366666666666667,
          -11.433333333333334,
          -15.166666666666666,
          -17.566666666666666,
          -11.733333333333333,
          -11.2,
          -14.333333333333334,
          -11.733333333333333,
          -11.833333333333334,
          -14.866666666666667,
          -11.433333333333334,
          -15.3,
          -11.133333333333333,
          -14.966666666666667,
          -11.4,
          -11.8,
          -14.233333333333333,
          -18.166666666666668,
          -11.333333333333334,
          -15.266666666666667,
          -11.133333333333333,
          -14.433333333333334,
          -12.133333333333333,
          -14.866666666666667,
          -14.6,
          -11.566666666666666,
          -11.5,
          -14.433333333333334,
          -21.033333333333335,
          -17.366666666666667,
          -14.566666666666666,
          -14.733333333333333,
          -14.533333333333333,
          -15,
          -11.133333333333333,
          -14.4,
          -11.633333333333333,
          -11.166666666666666,
          -14.1,
          -11.266666666666667,
          -18.466666666666665,
          -14.4,
          -14.366666666666667,
          -11.2,
          -11.6,
          -20.333333333333332,
          -18.2,
          -11.866666666666667,
          -12.033333333333333,
          -11.333333333333334,
          -14.233333333333333,
          -20.433333333333334,
          -11.166666666666666,
          -17.4,
          -11.466666666666667,
          -14.733333333333333,
          -14.533333333333333,
          -11.2,
          -11.166666666666666,
          -11.2,
          -12.4,
          -11.1,
          -11.533333333333333,
          -17.166666666666668,
          -20.7,
          -14.233333333333333,
          -11.3,
          -11.133333333333333,
          -11,
          -11.4,
          -11.2,
          -14.4,
          -11.2,
          -11.033333333333333,
          -11.166666666666666,
          -15.1,
          -14.433333333333334,
          -14.666666666666666,
          -11.466666666666667,
          -11.6,
          -11.166666666666666,
          -14.533333333333333,
          -18.333333333333332,
          -17.566666666666666,
          -17.9,
          -17.833333333333332,
          -14.166666666666666,
          -12.066666666666666,
          -11,
          -11.066666666666666,
          -14.666666666666666,
          -11.9,
          -11.2,
          -11.466666666666667,
          -17.333333333333332,
          -11.733333333333333,
          -11.166666666666666,
          -11.2,
          -11.6,
          -14.366666666666667,
          -14.233333333333333,
          -11,
          -14.133333333333333,
          -11.733333333333333,
          -11.5,
          -14.066666666666666,
          -11.133333333333333,
          -11.133333333333333,
          -14.5,
          -11.066666666666666,
          -14.6,
          -17.9,
          -11.466666666666667,
          -17.166666666666668,
          -11.3,
          -11.333333333333334,
          -18,
          -17.4,
          -14.8,
          -14.466666666666667,
          -11.066666666666666,
          -11.633333333333333,
          -11.066666666666666,
          -11.2,
          -11,
          -14.3,
          -11.3,
          -11.4,
          -14.233333333333333,
          -11.066666666666666,
          -14.2,
          -11.333333333333334,
          -14.3,
          -11.133333333333333,
          -14.4,
          -14.5,
          -11.2,
          -11.4,
          -17.6,
          -11.266666666666667,
          -17.333333333333332,
          -14.233333333333333,
          -14.333333333333334,
          -11.133333333333333,
          -14.3,
          -17.5,
          -14.366666666666667,
          -17.3,
          -14.566666666666666,
          -14.366666666666667,
          -11.133333333333333,
          -11,
          -11.466666666666667,
          -14.366666666666667,
          -11.333333333333334,
          -14.3,
          -14.5,
          -14.7,
          -11.266666666666667,
          -14.9,
          -23.633333333333333,
          -14.3,
          -11.333333333333334,
          -14.4,
          -11.133333333333333,
          -15,
          -14.2,
          -11.066666666666666,
          -11.533333333333333,
          -11.2,
          -11,
          -11.066666666666666,
          -11.266666666666667,
          -14.233333333333333,
          -11.266666666666667,
          -11.6,
          -11.4,
          -14.266666666666667,
          -14.333333333333334,
          -14.433333333333334,
          -18.066666666666666,
          -17.466666666666665,
          -14.433333333333334,
          -14.233333333333333,
          -14.3,
          -11.3,
          -11.5,
          -14.166666666666666,
          -14.266666666666667,
          -11.3,
          -14.3,
          -26.566666666666666,
          -14.233333333333333,
          -14.3,
          -17.5,
          -11.433333333333334,
          -17.5,
          -14.766666666666667,
          -11.066666666666666,
          -17.433333333333334,
          -11.066666666666666,
          -14.466666666666667,
          -11,
          -14.2,
          -11.6,
          -14.633333333333333,
          -14.366666666666667,
          -14.1,
          -11.333333333333334,
          -14.666666666666666,
          -14.6,
          -11.166666666666666,
          -17.433333333333334,
          -17.5,
          -11.4,
          -20.6,
          -11.366666666666667,
          -11.166666666666666,
          -14.266666666666667,
          -14.366666666666667,
          -11.233333333333333,
          -11.933333333333334,
          -17.366666666666667,
          -14.233333333333333,
          -11.133333333333333,
          -11.133333333333333,
          -14.266666666666667,
          -14.2,
          -14.266666666666667,
          -14.366666666666667,
          -14.366666666666667,
          -14.333333333333334,
          -14.5,
          -14.6,
          -17.566666666666666,
          -20.333333333333332,
          -14.033333333333333,
          -11.066666666666666,
          -11,
          -14.233333333333333,
          -14.233333333333333,
          -14.2,
          -14.2,
          -11,
          -11.966666666666667,
          -11,
          -11.1,
          -17.633333333333333,
          -11.1,
          -11.366666666666667,
          -14.466666666666667,
          -17.433333333333334,
          -11.066666666666666,
          -11.1,
          -14.266666666666667,
          -11.066666666666666,
          -11.2,
          -14.033333333333333,
          -11.266666666666667,
          -11.066666666666666,
          -14.566666666666666,
          -14.233333333333333,
          -17.266666666666666,
          -11.3,
          -17.533333333333335,
          -11.2,
          -14.266666666666667,
          -11.2,
          -11.466666666666667,
          -14.266666666666667,
          -14.133333333333333,
          -11,
          -14.4,
          -11.066666666666666,
          -14.366666666666667,
          -11.2,
          -14.366666666666667,
          -11.633333333333333,
          -11.066666666666666,
          -14.366666666666667,
          -14.333333333333334,
          -14.133333333333333,
          -14.333333333333334,
          -14.8,
          -11.266666666666667,
          -11.266666666666667,
          -20.633333333333333,
          -11.2,
          -14.3,
          -14.233333333333333,
          -11.733333333333333,
          -14.7,
          -14.366666666666667,
          -14.2,
          -11.133333333333333,
          -14.166666666666666,
          -11.6,
          -11.133333333333333,
          -14.5,
          -14.366666666666667,
          -11.133333333333333,
          -11,
          -11.133333333333333,
          -11.1,
          -14.166666666666666,
          -11.066666666666666,
          -14.166666666666666,
          -11.533333333333333,
          -14.333333333333334,
          -14.333333333333334,
          -20.7,
          -17.3,
          -14.033333333333333,
          -20.866666666666667,
          -14.566666666666666,
          -14.233333333333333,
          -11.133333333333333,
          -14.366666666666667,
          -11.2,
          -17.266666666666666,
          -11.3,
          -11.366666666666667,
          -11,
          -11.133333333333333,
          -11.5,
          -17.833333333333332,
          -17.5,
          -17.233333333333334,
          -11.2,
          -14.233333333333333,
          -17.333333333333332,
          -14.9,
          -11.133333333333333,
          -14.066666666666666,
          -11,
          -14.233333333333333,
          -17.5,
          -11,
          -14.266666666666667,
          -11.066666666666666,
          -17.266666666666666,
          -11.166666666666666,
          -14.633333333333333,
          -11.1,
          -14.3,
          -11.3,
          -14.233333333333333,
          -14.266666666666667,
          -14.5,
          -20.533333333333335,
          -14.566666666666666,
          -11.433333333333334,
          -11,
          -14.266666666666667,
          -11.066666666666666,
          -14.3,
          -14.2,
          -14.3,
          -11.366666666666667,
          -14.5,
          -14.466666666666667,
          -11.133333333333333,
          -14.166666666666666,
          -11.333333333333334,
          -17.5,
          -17.333333333333332,
          -14.466666666666667,
          -11.233333333333333,
          -11.033333333333333,
          -11.2,
          -11.2,
          -14.466666666666667,
          -11.333333333333334,
          -11.133333333333333,
          -11.066666666666666,
          -17.533333333333335,
          -14.1,
          -11.333333333333334,
          -17.5,
          -17.5,
          -14.3,
          -14.1,
          -14.666666666666666,
          -20.766666666666666,
          -11.066666666666666,
          -17.633333333333333,
          -14.066666666666666,
          -17.8,
          -11.133333333333333,
          -11.133333333333333,
          -11.1,
          -11.033333333333333,
          -11.033333333333333,
          -20.5,
          -11,
          -11.066666666666666,
          -14.3,
          -11.1,
          -11.466666666666667,
          -12.066666666666666,
          -11.133333333333333,
          -11,
          -14.433333333333334,
          -14.2,
          -14.366666666666667,
          -11.233333333333333,
          -11,
          -11.3,
          -14.433333333333334,
          -14.333333333333334,
          -17.3,
          -14.4,
          -17.7,
          -11.066666666666666,
          -11,
          -14.266666666666667,
          -17.4,
          -14.766666666666667,
          -11.066666666666666,
          -14.166666666666666,
          -20.433333333333334,
          -14.366666666666667,
          -11.266666666666667,
          -14.066666666666666,
          -20.733333333333334,
          -14.133333333333333,
          -11.266666666666667,
          -11.133333333333333,
          -14.333333333333334,
          -11.333333333333334,
          -11.266666666666667,
          -11.066666666666666,
          -14.466666666666667,
          -14.133333333333333,
          -20.4,
          -17.366666666666667,
          -11.133333333333333,
          -11.666666666666666,
          -14.333333333333334,
          -14.166666666666666,
          -20.866666666666667,
          -11.066666666666666,
          -14.233333333333333,
          -14.066666666666666,
          -11.133333333333333,
          -18,
          -11,
          -11,
          -11.1,
          -17.533333333333335,
          -11.066666666666666,
          -17.366666666666667,
          -11.7,
          -11,
          -14.5,
          -11.2,
          -11.366666666666667,
          -11.133333333333333,
          -20.4,
          -14.166666666666666,
          -11.133333333333333,
          -14.2,
          -11.466666666666667,
          -11.066666666666666,
          -11.3,
          -14.266666666666667,
          -14.233333333333333,
          -11,
          -11.033333333333333,
          -14.333333333333334,
          -14.3,
          -14.033333333333333,
          -14.1,
          -11.2,
          -11.2,
          -14.2,
          -17.233333333333334,
          -11,
          -11.1,
          -14.766666666666667,
          -11.333333333333334,
          -20.6,
          -14.433333333333334,
          -11.066666666666666,
          -17.333333333333332,
          -14.466666666666667,
          -11.333333333333334,
          -14.133333333333333,
          -14.266666666666667,
          -11.266666666666667,
          -14.433333333333334,
          -14.733333333333333,
          -11,
          -17.733333333333334,
          -11.2,
          -11.133333333333333,
          -14.866666666666667,
          -11.633333333333333,
          -11.066666666666666,
          -14.266666666666667,
          -11.666666666666666,
          -17.766666666666666,
          -14.1,
          -14.333333333333334,
          -11.566666666666666,
          -11.066666666666666,
          -14.3,
          -11.166666666666666,
          -20.333333333333332,
          -11.4,
          -11,
          -11.133333333333333,
          -14.4,
          -11.066666666666666,
          -14.033333333333333,
          -14.5,
          -11.066666666666666,
          -17.2,
          -17.833333333333332,
          -11.333333333333334,
          -20.666666666666668,
          -14.7,
          -11.466666666666667,
          -11.066666666666666,
          -14.2,
          -11,
          -14.933333333333334,
          -11.566666666666666,
          -14.266666666666667,
          -14.533333333333333,
          -14.133333333333333,
          -11.333333333333334,
          -14.3,
          -11.233333333333333,
          -14.166666666666666,
          -17.8,
          -20.6,
          -14.266666666666667,
          -11.066666666666666,
          -14,
          -14.333333333333334,
          -17.3,
          -11.333333333333334,
          -17.4,
          -11.566666666666666,
          -14.233333333333333,
          -17.566666666666666,
          -11.066666666666666,
          -14.233333333333333,
          -14.333333333333334,
          -11.2,
          -14.5,
          -11.066666666666666,
          -11.1,
          -11.066666666666666,
          -14.7,
          -14.1,
          -14.166666666666666,
          -11.2,
          -17.666666666666668,
          -11.1,
          -11.033333333333333,
          -17.566666666666666,
          -11.6,
          -13.966666666666667,
          -14.366666666666667,
          -14.833333333333334,
          -11.066666666666666,
          -14.1,
          -11.066666666666666,
          -11.466666666666667,
          -11.233333333333333,
          -11.033333333333333,
          -17.233333333333334,
          -11.266666666666667,
          -11.2,
          -20.566666666666666,
          -11,
          -11.266666666666667,
          -11.033333333333333,
          -11,
          -11.233333333333333,
          -15.133333333333333,
          -14.233333333333333,
          -17.166666666666668,
          -14.2,
          -14.266666666666667,
          -11.266666666666667,
          -14.133333333333333,
          -17.566666666666666,
          -11.066666666666666,
          -17.433333333333334,
          -14.466666666666667,
          -11.233333333333333,
          -14.166666666666666,
          -11,
          -14.166666666666666,
          -11,
          -11.266666666666667,
          -11.133333333333333,
          -11.066666666666666,
          -17.666666666666668,
          -11.2,
          -11.066666666666666,
          -14.233333333333333,
          -11.133333333333333,
          -11.2,
          -14.333333333333334,
          -14.633333333333333,
          -14.066666666666666,
          -17.5,
          -11.2,
          -11,
          -11.033333333333333,
          -11.133333333333333,
          -11.3,
          -11.566666666666666,
          -14.3,
          -11.2,
          -11.066666666666666,
          -14.233333333333333,
          -11,
          -14.4,
          -14.2,
          -11.333333333333334,
          -11.3,
          -11,
          -14.433333333333334,
          -11.566666666666666,
          -14.133333333333333,
          -11.166666666666666,
          -11.366666666666667,
          -11.1,
          -11.233333333333333,
          -17.466666666666665,
          -11.066666666666666,
          -14.1,
          -11.166666666666666,
          -11.033333333333333,
          -17.466666666666665,
          -11.166666666666666,
          -11,
          -17.333333333333332,
          -17.966666666666665,
          -17.266666666666666,
          -11.133333333333333,
          -11.1,
          -14.3,
          -14.5,
          -14.5,
          -14.166666666666666,
          -14.3,
          -11.133333333333333,
          -11.2,
          -11.133333333333333,
          -11.3,
          -27,
          -17.733333333333334,
          -17.466666666666665,
          -17.3,
          -14.233333333333333,
          -11.233333333333333,
          -11.133333333333333,
          -11.133333333333333,
          -20.966666666666665,
          -23.7,
          -11.066666666666666,
          -14.4,
          -18,
          -11,
          -11.033333333333333,
          -14.366666666666667,
          -11.133333333333333,
          -14.033333333333333,
          -21.1,
          -11.133333333333333,
          -14.233333333333333,
          -14.2,
          -11.133333333333333,
          -14.6,
          -14.166666666666666,
          -11.333333333333334,
          -11.133333333333333,
          -11.066666666666666,
          -11.133333333333333,
          -14.333333333333334,
          -11.466666666666667,
          -11.466666666666667,
          -11.133333333333333,
          -14.233333333333333,
          -17.6,
          -11.233333333333333,
          -14.333333333333334,
          -11.2,
          -11.066666666666666,
          -14.366666666666667,
          -11.066666666666666,
          -17.733333333333334,
          -14.366666666666667,
          -14.733333333333333,
          -14.233333333333333,
          -14.266666666666667,
          -11.133333333333333,
          -17.5,
          -17.4,
          -11.2,
          -17.533333333333335,
          -11,
          -11.1,
          -14.533333333333333,
          -17.333333333333332,
          -11.4,
          -20.633333333333333,
          -14.333333333333334,
          -11.2,
          -17.533333333333335,
          -11.2,
          -13.966666666666667,
          -11.1,
          -11.133333333333333,
          -17.933333333333334,
          -11.4,
          -14.433333333333334,
          -14.5,
          -11.266666666666667,
          -17.166666666666668,
          -11.2,
          -17.566666666666666,
          -11.066666666666666,
          -11,
          -14.5,
          -14.066666666666666,
          -14.333333333333334,
          -14.6,
          -14.133333333333333,
          -14.266666666666667,
          -11.2,
          -14.5,
          -11,
          -11.166666666666666,
          -14.266666666666667,
          -11,
          -14.4,
          -14.466666666666667,
          -14.533333333333333,
          -17.4,
          -11.366666666666667,
          -20.433333333333334,
          -20.433333333333334,
          -11.4,
          -14.333333333333334,
          -11.133333333333333,
          -11.266666666666667,
          -11.1,
          -11,
          -17.366666666666667,
          -11.366666666666667,
          -14.266666666666667,
          -14.666666666666666,
          -11.233333333333333,
          -17.566666666666666,
          -11.133333333333333,
          -17.533333333333335,
          -14.6,
          -14.1,
          -20.433333333333334,
          -11.2,
          -14.033333333333333,
          -14.6,
          -20.466666666666665,
          -14.1,
          -14.333333333333334,
          -17.5,
          -15.166666666666666,
          -11.466666666666667,
          -11.066666666666666,
          -20.633333333333333,
          -11,
          -14.2,
          -17.5,
          -11,
          -14.566666666666666,
          -11.5,
          -14.3,
          -14.3,
          -11.133333333333333,
          -14.4,
          -11,
          -14.3,
          -14.333333333333334,
          -14.466666666666667,
          -11.2,
          -14.166666666666666,
          -11.066666666666666,
          -11.066666666666666,
          -11.066666666666666,
          -11.1,
          -11.133333333333333,
          -14.366666666666667,
          -20.733333333333334,
          -17.4,
          -11,
          -11.233333333333333,
          -17.3,
          -14.1,
          -14.8,
          -14.033333333333333,
          -11.066666666666666,
          -14.3,
          -11,
          -20.133333333333333,
          -14.666666666666666,
          -20.633333333333333,
          -14.066666666666666,
          -17.566666666666666,
          -14.166666666666666,
          -20.733333333333334,
          -14.333333333333334,
          -14.366666666666667,
          -14.133333333333333,
          -11.133333333333333,
          -17.933333333333334,
          -23.366666666666667,
          -14.333333333333334,
          -11.3,
          -13.966666666666667,
          -11.133333333333333,
          -11.266666666666667,
          -11.066666666666666,
          -11.133333333333333,
          -14.2,
          -14.3,
          -14.433333333333334,
          -14.3,
          -11.366666666666667,
          -11,
          -11.3,
          -11,
          -14.233333333333333,
          -11.233333333333333,
          -14.366666666666667,
          -20.3,
          -17.666666666666668,
          -11.066666666666666,
          -11.1,
          -17.366666666666667,
          -17.133333333333333,
          -20.666666666666668,
          -11.133333333333333,
          -11,
          -14.166666666666666,
          -17.8,
          -11.066666666666666,
          -14.166666666666666,
          -14.366666666666667,
          -20.6,
          -17.2,
          -11.2,
          -14.466666666666667,
          -14.3,
          -11,
          -14.466666666666667,
          -17.266666666666666,
          -11.066666666666666,
          -11.433333333333334,
          -17.866666666666667,
          -11,
          -14.233333333333333,
          -11.066666666666666,
          -14.366666666666667,
          -11.333333333333334,
          -14,
          -11,
          -11.533333333333333,
          -11.566666666666666,
          -11.5,
          -17.866666666666667,
          -17.6,
          -11.133333333333333,
          -14.4,
          -14.466666666666667,
          -17.133333333333333,
          -11.1,
          -20.6,
          -17.2,
          -11.133333333333333,
          -14.5,
          -14.233333333333333,
          -14.533333333333333,
          -11.066666666666666,
          -11.3,
          -14.4,
          -14.233333333333333,
          -11.266666666666667,
          -11.066666666666666,
          -11.033333333333333,
          -17.333333333333332,
          -11.266666666666667,
          -11.2,
          -14.5,
          -11.066666666666666,
          -11.2,
          -14.3,
          -17.266666666666666,
          -17.233333333333334,
          -11.4,
          -14.733333333333333,
          -11.066666666666666,
          -11.3,
          -11.066666666666666,
          -11.766666666666667,
          -17.433333333333334,
          -14.1,
          -14.166666666666666,
          -20.366666666666667,
          -14.466666666666667,
          -11,
          -11,
          -14.3,
          -11.133333333333333,
          -11.166666666666666,
          -17.733333333333334,
          -11,
          -14.133333333333333,
          -11,
          -11.166666666666666,
          -14.333333333333334,
          -11.366666666666667,
          -11.366666666666667,
          -14.233333333333333,
          -11.066666666666666,
          -11.066666666666666,
          -11.333333333333334,
          -11.4,
          -11,
          -15.266666666666667,
          -17.666666666666668,
          -20.6,
          -15.066666666666666,
          -17.566666666666666,
          -11.066666666666666,
          -11,
          -20.233333333333334,
          -14.466666666666667,
          -14.3,
          -14.5,
          -11,
          -20.866666666666667,
          -11.066666666666666,
          -14.266666666666667,
          -11.066666666666666,
          -14.233333333333333,
          -14.333333333333334,
          -14.133333333333333,
          -11,
          -11,
          -14.366666666666667,
          -11.1,
          -11.333333333333334,
          -11.066666666666666,
          -14.066666666666666,
          -14.233333333333333,
          -11.366666666666667,
          -14.566666666666666,
          -14.166666666666666,
          -14.4,
          -20.3,
          -11.266666666666667,
          -17.266666666666666,
          -11.133333333333333,
          -14.2,
          -14.3,
          -11.266666666666667,
          -11.666666666666666,
          -14.266666666666667,
          -14.566666666666666,
          -11.3,
          -17.4,
          -11.3,
          -14.3,
          -14.233333333333333,
          -15.633333333333333,
          -17.1,
          -11.2,
          -14.1,
          -14.3,
          -11.366666666666667,
          -11,
          -14.5,
          -14.266666666666667,
          -17.266666666666666,
          -11.4,
          -11.066666666666666,
          -14.5,
          -17.6,
          -11.266666666666667,
          -11.266666666666667,
          -14.366666666666667,
          -11.4,
          -14.3,
          -17.2,
          -11,
          -14.5,
          -11.1,
          -11.066666666666666,
          -14.333333333333334,
          -11.466666666666667,
          -14.2,
          -11.266666666666667,
          -14.166666666666666,
          -17.333333333333332,
          -11.066666666666666,
          -11,
          -11,
          -24.366666666666667,
          -14.133333333333333,
          -14.9,
          -17.333333333333332,
          -14.233333333333333,
          -14.266666666666667,
          -11.1,
          -14.266666666666667,
          -11,
          -11.066666666666666,
          -17.266666666666666,
          -14.733333333333333,
          -14.033333333333333,
          -14.033333333333333,
          -11.066666666666666,
          -11.033333333333333,
          -11.133333333333333,
          -14.533333333333333,
          -14.133333333333333,
          -17.366666666666667,
          -14.3,
          -14.3,
          -14.2,
          -11.066666666666666,
          -17.633333333333333,
          -17.233333333333334,
          -11.6,
          -11,
          -14.266666666666667,
          -17.5,
          -11.266666666666667,
          -14.3,
          -14.4,
          -11.066666666666666,
          -11,
          -14.166666666666666,
          -14.033333333333333,
          -14.266666666666667,
          -11.066666666666666,
          -14.166666666666666,
          -11.066666666666666,
          -11.033333333333333,
          -11.2,
          -20.733333333333334,
          -11.066666666666666,
          -14.7,
          -14.433333333333334,
          -14.3,
          -11.133333333333333,
          -11.2,
          -11.2,
          -14.2,
          -11.133333333333333,
          -14.466666666666667,
          -11.366666666666667,
          -14.1,
          -14.533333333333333,
          -11,
          -14.5,
          -14.333333333333334,
          -11.4,
          -11.266666666666667,
          -14.3,
          -17.433333333333334,
          -14.166666666666666,
          -20.7,
          -11,
          -11.5,
          -14.4,
          -14.366666666666667,
          -11.133333333333333,
          -11.066666666666666,
          -14.3,
          -14.533333333333333,
          -11.066666666666666,
          -14.866666666666667,
          -14.1,
          -23.966666666666665,
          -11.1,
          -20.366666666666667,
          -20.4,
          -14.166666666666666,
          -11.033333333333333,
          -14.266666666666667,
          -11.133333333333333,
          -14.266666666666667,
          -14.166666666666666,
          -11.166666666666666,
          -17.066666666666666,
          -11.333333333333334,
          -11.233333333333333,
          -11.5,
          -11.133333333333333,
          -14.3,
          -17.7,
          -14.233333333333333,
          -11.433333333333334,
          -11.066666666666666,
          -11.3,
          -14.366666666666667,
          -14.2,
          -13.966666666666667,
          -11.266666666666667,
          -11.066666666666666,
          -11.166666666666666,
          -11.066666666666666,
          -14.2,
          -11.766666666666667,
          -17.133333333333333,
          -11.133333333333333,
          -14.2,
          -20.466666666666665,
          -14.3,
          -11.2,
          -11,
          -11,
          -33.3,
          -11.266666666666667,
          -14.866666666666667,
          -11.066666666666666,
          -17.033333333333335,
          -11.266666666666667,
          -11.2,
          -11.133333333333333,
          -11.166666666666666,
          -14.333333333333334,
          -14.133333333333333,
          -11.2,
          -14.166666666666666,
          -14.4,
          -11.233333333333333,
          -11.133333333333333,
          -23.9,
          -20.866666666666667,
          -11.333333333333334,
          -17.166666666666668,
          -17.366666666666667,
          -11.2,
          -11.166666666666666,
          -14.5,
          -11,
          -11.266666666666667,
          -11.266666666666667,
          -14.333333333333334,
          -14.266666666666667,
          -11.066666666666666,
          -14.333333333333334,
          -14.466666666666667,
          -11.133333333333333,
          -14.633333333333333,
          -11,
          -14.166666666666666,
          -11,
          -11.066666666666666,
          -14.333333333333334,
          -17.4,
          -14.3,
          -17.533333333333335,
          -11.466666666666667,
          -14.533333333333333,
          -11.066666666666666,
          -14.166666666666666,
          -11.966666666666667,
          -14.333333333333334,
          -17.333333333333332,
          -11.266666666666667,
          -11.133333333333333,
          -11.033333333333333,
          -14.5,
          -14.3,
          -14.533333333333333,
          -11.133333333333333,
          -11.3,
          -17.666666666666668,
          -14.366666666666667,
          -14.1,
          -17.4,
          -14.1,
          -11.266666666666667,
          -11.3,
          -11.1,
          -11.333333333333334,
          -14.2,
          -14.366666666666667,
          -17.3,
          -11,
          -14.433333333333334,
          -11.733333333333333,
          -14.133333333333333,
          -14.633333333333333,
          -14.366666666666667,
          -14.266666666666667,
          -14.533333333333333,
          -11.4,
          -11.1,
          -14.2,
          -11,
          -11.133333333333333,
          -14.466666666666667,
          -11.133333333333333,
          -14.166666666666666,
          -11,
          -11,
          -14.4,
          -14.4,
          -14.3,
          -14.1,
          -14.433333333333334,
          -14.2,
          -14.3,
          -11,
          -11.4,
          -11.266666666666667,
          -11.2,
          -11.133333333333333,
          -11,
          -11.3,
          -11.566666666666666,
          -14.166666666666666,
          -11.166666666666666,
          -14.333333333333334,
          -20.3,
          -14.366666666666667,
          -14.033333333333333,
          -14.5,
          -17.233333333333334,
          -14.266666666666667,
          -11.533333333333333,
          -11.266666666666667,
          -14.4,
          -11.366666666666667,
          -17.433333333333334,
          -11.266666666666667,
          -11.133333333333333,
          -14.233333333333333,
          -11.433333333333334,
          -14.1,
          -11.166666666666666,
          -14.333333333333334,
          -11.266666666666667,
          -17.6,
          -14.366666666666667,
          -11.533333333333333,
          -14.7,
          -14.233333333333333,
          -23.866666666666667,
          -11.133333333333333,
          -11.033333333333333,
          -18.133333333333333,
          -14.4,
          -14.833333333333334,
          -17.033333333333335,
          -11.133333333333333,
          -14.633333333333333,
          -14.066666666666666,
          -11.066666666666666,
          -11.1,
          -14.4,
          -14.333333333333334,
          -20.733333333333334,
          -11.266666666666667,
          -11.066666666666666,
          -11.066666666666666,
          -20.733333333333334,
          -11.066666666666666,
          -11.066666666666666,
          -11.333333333333334,
          -11.166666666666666,
          -11.266666666666667,
          -11.266666666666667,
          -11,
          -14.066666666666666,
          -11.066666666666666,
          -11.133333333333333,
          -17.233333333333334,
          -14.3,
          -11.2,
          -14.4,
          -14.3,
          -17.466666666666665,
          -11,
          -11.5,
          -14.133333333333333,
          -11.1,
          -14.033333333333333,
          -17.533333333333335,
          -11.233333333333333,
          -11.133333333333333,
          -11.066666666666666,
          -14.5,
          -14.266666666666667,
          -17.166666666666668,
          -11.4,
          -11.566666666666666,
          -11,
          -11.233333333333333,
          -20.466666666666665,
          -14.266666666666667,
          -17.466666666666665,
          -11.533333333333333,
          -11.066666666666666,
          -14.2,
          -11,
          -20.433333333333334,
          -17.8,
          -14.766666666666667,
          -11.266666666666667,
          -14.3,
          -11,
          -11.233333333333333,
          -14.066666666666666,
          -14.4,
          -14.233333333333333,
          -14.266666666666667,
          -14.233333333333333,
          -11.266666666666667,
          -11.033333333333333,
          -14.233333333333333,
          -11.066666666666666,
          -11.2,
          -14.066666666666666,
          -11.066666666666666,
          -14.066666666666666,
          -11.2,
          -11,
          -11,
          -11.4,
          -11.133333333333333,
          -11.133333333333333,
          -14.466666666666667,
          -11.1,
          -14.366666666666667,
          -14.233333333333333,
          -14.1,
          -11.366666666666667,
          -14.466666666666667,
          -11,
          -14.466666666666667,
          -11.1,
          -14.233333333333333,
          -14.466666666666667,
          -14.266666666666667,
          -13.966666666666667,
          -14.2,
          -11.233333333333333,
          -14.233333333333333,
          -11.066666666666666,
          -17.1,
          -14.7,
          -14.333333333333334,
          -14.2,
          -14.266666666666667,
          -11.133333333333333,
          -17.233333333333334,
          -11.133333333333333,
          -11,
          -11.2,
          -11,
          -14.433333333333334,
          -14.133333333333333,
          -14.3,
          -11.166666666666666,
          -11,
          -11.4,
          -14.5,
          -11.133333333333333,
          -11,
          -14.166666666666666,
          -14.3,
          -14.4,
          -14.266666666666667,
          -11.066666666666666,
          -14.033333333333333,
          -14.1,
          -11.033333333333333,
          -17.633333333333333,
          -14.266666666666667,
          -14.733333333333333,
          -11.066666666666666,
          -14.266666666666667,
          -11.133333333333333,
          -17.233333333333334,
          -11.066666666666666,
          -11.733333333333333,
          -14.433333333333334,
          -14.366666666666667,
          -14.3,
          -15.033333333333333,
          -11.133333333333333,
          -14.133333333333333,
          -14.466666666666667,
          -11.1,
          -17.266666666666666,
          -11.066666666666666,
          -14.466666666666667,
          -14.333333333333334,
          -14.4,
          -11.133333333333333,
          -14.266666666666667,
          -11.1,
          -11.1,
          -20.9,
          -11.133333333333333,
          -11.266666666666667,
          -11.4,
          -14.2,
          -14.366666666666667,
          -11.233333333333333,
          -17.4,
          -14.366666666666667,
          -14.266666666666667,
          -14.433333333333334,
          -14.433333333333334,
          -11.533333333333333,
          -14.266666666666667,
          -14.266666666666667,
          -17.233333333333334,
          -17.766666666666666,
          -11.533333333333333,
          -11.066666666666666,
          -11.133333333333333,
          -11.066666666666666,
          -14.3,
          -17.1,
          -11.266666666666667,
          -11.133333333333333,
          -11.066666666666666,
          -11.133333333333333,
          -11.066666666666666,
          -11.1,
          -11.166666666666666,
          -14.266666666666667,
          -11.133333333333333,
          -14.233333333333333,
          -11.133333333333333,
          -11.133333333333333,
          -14.4,
          -14.2,
          -14.5,
          -11.533333333333333,
          -14.433333333333334,
          -14.366666666666667,
          -17.5,
          -14.2,
          -11.2,
          -17.266666666666666,
          -11.133333333333333,
          -14.733333333333333,
          -11.133333333333333,
          -11.133333333333333,
          -17.566666666666666,
          -14.3,
          -14.3,
          -12.133333333333333,
          -14.4,
          -11.133333333333333,
          -11.4,
          -11.033333333333333,
          -14.333333333333334,
          -14.166666666666666,
          -11.266666666666667,
          -11.066666666666666,
          -14.233333333333333,
          -11.1,
          -11.133333333333333,
          -11.133333333333333,
          -14.1,
          -14.266666666666667,
          -20.566666666666666,
          -14.2,
          -11.033333333333333,
          -17.233333333333334,
          -11.433333333333334,
          -14.366666666666667,
          -17.4,
          -14.5,
          -11.433333333333334,
          -17.366666666666667,
          -11,
          -20.766666666666666,
          -11,
          -20.666666666666668,
          -11.2,
          -11.033333333333333,
          -14.533333333333333,
          -17.266666666666666,
          -20.533333333333335,
          -20.566666666666666,
          -14.266666666666667,
          -11.066666666666666,
          -23.833333333333332,
          -11.1,
          -11.2,
          -14.066666666666666,
          -14.4,
          -11.066666666666666,
          -20.4,
          -14.533333333333333,
          -14.3,
          -11,
          -14.333333333333334,
          -11.133333333333333,
          -14.133333333333333,
          -11.066666666666666,
          -11.066666666666666,
          -11,
          -11.133333333333333,
          -14.566666666666666,
          -11.033333333333333,
          -14.433333333333334,
          -14.733333333333333,
          -11.133333333333333,
          -17.333333333333332,
          -11.2,
          -14.466666666666667,
          -11.266666666666667,
          -13.966666666666667,
          -11,
          -14.166666666666666,
          -11.1,
          -17.1,
          -14.166666666666666,
          -11.1,
          -14.666666666666666,
          -14.666666666666666,
          -14.233333333333333,
          -11.133333333333333,
          -11.133333333333333,
          -17.3,
          -11.2,
          -11.4,
          -11.066666666666666,
          -14.6,
          -14.133333333333333,
          -11.133333333333333,
          -14.7,
          -17.5,
          -11.266666666666667,
          -14.733333333333333,
          -17.266666666666666,
          -14.1,
          -14.2,
          -14.366666666666667,
          -11.1,
          -14.266666666666667,
          -11.2,
          -14.433333333333334,
          -11.133333333333333,
          -11.4,
          -14.3,
          -13.966666666666667,
          -14.333333333333334,
          -11.066666666666666,
          -17.466666666666665,
          -11.133333333333333,
          -20.4,
          -11.1,
          -14.533333333333333,
          -11.066666666666666,
          -11.666666666666666,
          -17.566666666666666,
          -17.966666666666665,
          -11.066666666666666,
          -11.066666666666666,
          -20.866666666666667,
          -11.066666666666666,
          -14.333333333333334,
          -14.233333333333333,
          -14.033333333333333,
          -14.133333333333333,
          -20.8,
          -11,
          -11.233333333333333,
          -11.066666666666666,
          -14.266666666666667,
          -11.4,
          -14.166666666666666,
          -11.1,
          -14.7,
          -17.533333333333335,
          -11.133333333333333,
          -11.3,
          -11,
          -11.033333333333333,
          -14.166666666666666,
          -11.066666666666666,
          -11.133333333333333,
          -11.133333333333333,
          -11.2,
          -14.266666666666667,
          -17.633333333333333,
          -11.133333333333333,
          -14.366666666666667,
          -11.1,
          -14.4,
          -11.366666666666667,
          -14.166666666666666,
          -11.133333333333333,
          -14.1,
          -14.433333333333334,
          -14.266666666666667,
          -13.966666666666667,
          -14.166666666666666,
          -11.333333333333334,
          -14.4,
          -14.3,
          -17.466666666666665,
          -14.366666666666667,
          -11.066666666666666,
          -17.4,
          -11.1,
          -14.233333333333333,
          -14.266666666666667,
          -11.5,
          -11.133333333333333,
          -17.333333333333332,
          -11.066666666666666,
          -14.266666666666667,
          -11.3,
          -17.466666666666665,
          -11.133333333333333,
          -14.266666666666667,
          -14.166666666666666,
          -11.066666666666666,
          -11.066666666666666,
          -20.7,
          -14.233333333333333,
          -11.466666666666667,
          -11.333333333333334,
          -11.4,
          -17.4,
          -11.166666666666666,
          -14.266666666666667,
          -14.366666666666667,
          -11.066666666666666,
          -17.633333333333333,
          -11.266666666666667,
          -23.7,
          -11.2,
          -14.133333333333333,
          -11.4,
          -14.3,
          -14.866666666666667,
          -14.7,
          -11.5,
          -14.366666666666667,
          -14.133333333333333,
          -11.066666666666666,
          -11.033333333333333,
          -14.866666666666667,
          -23.7,
          -11,
          -11.133333333333333,
          -14.366666666666667,
          -11,
          -17.4,
          -14.366666666666667,
          -11.066666666666666,
          -14.033333333333333,
          -17.233333333333334,
          -11.166666666666666,
          -11.133333333333333,
          -11.066666666666666,
          -17.666666666666668,
          -11,
          -14.4,
          -11.066666666666666,
          -17.433333333333334,
          -11.3,
          -14.633333333333333,
          -11.066666666666666,
          -11.133333333333333,
          -17.7,
          -14.333333333333334,
          -11.066666666666666,
          -14.3,
          -17.3,
          -14.333333333333334,
          -14.266666666666667,
          -11.066666666666666,
          -17.666666666666668,
          -14.566666666666666,
          -14.466666666666667,
          -17.566666666666666,
          -11.033333333333333,
          -14.766666666666667,
          -11.033333333333333,
          -26.6,
          -20.466666666666665,
          -17.3,
          -14.1,
          -11.233333333333333,
          -17.466666666666665,
          -14.266666666666667,
          -11.433333333333334,
          -14.033333333333333,
          -11.966666666666667,
          -11.066666666666666,
          -23.633333333333333,
          -11.3,
          -11.333333333333334,
          -14.333333333333334,
          -11.1,
          -14.266666666666667,
          -14.433333333333334,
          -11.066666666666666,
          -14.1,
          -17.3,
          -14.2,
          -14.533333333333333,
          -11,
          -14.366666666666667,
          -20.7,
          -14.466666666666667,
          -11.066666666666666,
          -11.066666666666666,
          -11.133333333333333,
          -11.066666666666666,
          -11.2,
          -14.4,
          -11.233333333333333,
          -11.066666666666666,
          -11.066666666666666,
          -14.233333333333333,
          -17.166666666666668,
          -11.033333333333333,
          -14.4,
          -14.166666666666666,
          -18.066666666666666,
          -11.066666666666666,
          -11.233333333333333,
          -14.166666666666666,
          -17.633333333333333,
          -17.533333333333335,
          -11.033333333333333,
          -11.066666666666666,
          -14.1,
          -14.433333333333334,
          -14.066666666666666,
          -11.366666666666667,
          -14.166666666666666,
          -14.766666666666667,
          -14.433333333333334,
          -17.533333333333335,
          -11.066666666666666,
          -14.466666666666667,
          -14.1,
          -11.2,
          -11.1,
          -14.033333333333333,
          -11.333333333333334,
          -14.166666666666666,
          -14.066666666666666,
          -14.466666666666667,
          -14.333333333333334,
          -23.833333333333332,
          -11.066666666666666,
          -11.2,
          -17.266666666666666,
          -11,
          -14.433333333333334,
          -11.233333333333333,
          -14.166666666666666,
          -11.333333333333334,
          -14.366666666666667,
          -11.233333333333333,
          -11.066666666666666,
          -20.566666666666666,
          -14.133333333333333,
          -14.666666666666666,
          -14.266666666666667,
          -14.233333333333333,
          -17.4,
          -11,
          -11.3,
          -14.033333333333333,
          -14.266666666666667,
          -17.3,
          -14.433333333333334,
          -11.066666666666666,
          -11.2,
          -17.233333333333334,
          -14.5,
          -11.166666666666666,
          -11.166666666666666,
          -14.866666666666667,
          -11.2,
          -20.4,
          -14.1,
          -11.2,
          -11.066666666666666,
          -11.233333333333333,
          -11,
          -14.4,
          -14.5,
          -14.533333333333333,
          -11.066666666666666,
          -17.5,
          -11.4,
          -17.433333333333334,
          -11.266666666666667,
          -14.266666666666667,
          -11,
          -11,
          -11.366666666666667,
          -17.766666666666666,
          -11.1,
          -11.1,
          -14.333333333333334,
          -14.333333333333334,
          -17.1,
          -14.033333333333333,
          -14.2,
          -11.133333333333333,
          -17.533333333333335,
          -11.233333333333333,
          -14.3,
          -11.233333333333333,
          -11.366666666666667,
          -14.166666666666666,
          -11.133333333333333,
          -17.133333333333333,
          -14.433333333333334,
          -14.233333333333333,
          -14.233333333333333,
          -11.1,
          -14.3,
          -14.4,
          -14.2,
          -11.2,
          -14.4,
          -11.066666666666666,
          -11.066666666666666,
          -11.2,
          -11.233333333333333,
          -11.433333333333334,
          -20.4,
          -14.5,
          -11.5,
          -14.366666666666667,
          -14.1,
          -11,
          -11.066666666666666,
          -17.433333333333334,
          -14.633333333333333,
          -14.166666666666666,
          -11.166666666666666,
          -11.133333333333333,
          -11,
          -14.133333333333333,
          -17.6,
          -11.133333333333333,
          -14.333333333333334,
          -14.033333333333333,
          -11,
          -14.466666666666667,
          -11.033333333333333,
          -11,
          -14.366666666666667,
          -11.033333333333333,
          -14.366666666666667,
          -14.133333333333333,
          -11,
          -14.233333333333333,
          -17.333333333333332,
          -14.566666666666666,
          -14.333333333333334,
          -11,
          -14.366666666666667,
          -14.4,
          -11.3,
          -11.133333333333333,
          -13.966666666666667,
          -14.333333333333334,
          -14.333333333333334,
          -14.333333333333334,
          -14.266666666666667,
          -14.2,
          -14.5,
          -14.3,
          -14.466666666666667,
          -11,
          -14.3,
          -11.2,
          -14.066666666666666,
          -11.066666666666666,
          -11.666666666666666,
          -14.166666666666666,
          -11.133333333333333,
          -14.166666666666666,
          -11.2,
          -17.4,
          -17.8,
          -14.333333333333334,
          -14.266666666666667,
          -17.266666666666666,
          -11.333333333333334,
          -14.266666666666667,
          -14.233333333333333,
          -11.233333333333333,
          -17.166666666666668,
          -14.6,
          -14.466666666666667,
          -17.633333333333333,
          -14.466666666666667,
          -11.133333333333333,
          -14.133333333333333,
          -11.033333333333333,
          -11.266666666666667,
          -17.8,
          -11.066666666666666,
          -14.333333333333334,
          -11.3,
          -17.433333333333334,
          -17.633333333333333,
          -14.366666666666667,
          -11.1,
          -17.366666666666667,
          -14.1,
          -11.066666666666666,
          -14.2,
          -11.2,
          -11.066666666666666,
          -14.4,
          -11.066666666666666,
          -17.666666666666668,
          -20.466666666666665,
          -11.133333333333333,
          -11,
          -11.066666666666666,
          -11.866666666666667,
          -17.433333333333334,
          -14.266666666666667,
          -11,
          -11.066666666666666,
          -14.233333333333333,
          -14.433333333333334,
          -11.133333333333333,
          -14.133333333333333,
          -11.066666666666666,
          -11.2,
          -14.5,
          -11.2,
          -11.066666666666666,
          -11.066666666666666,
          -14.266666666666667,
          -11.066666666666666,
          -14.3,
          -13.966666666666667,
          -14.333333333333334,
          -14.266666666666667,
          -11.2,
          -11.3,
          -14.5,
          -11.266666666666667,
          -11.066666666666666,
          -14.433333333333334,
          -14.366666666666667,
          -14.533333333333333,
          -11.133333333333333,
          -11.066666666666666,
          -11.133333333333333,
          -11.133333333333333,
          -14.466666666666667,
          -14.366666666666667,
          -14.166666666666666,
          -14.233333333333333,
          -11,
          -17.366666666666667,
          -14.366666666666667,
          -14.433333333333334,
          -14.1,
          -14.166666666666666,
          -14.6,
          -17.133333333333333,
          -11.2,
          -11.066666666666666,
          -20.466666666666665,
          -11.133333333333333,
          -11,
          -14.266666666666667,
          -11.3,
          -11.266666666666667,
          -11.133333333333333,
          -14.333333333333334,
          -14.533333333333333,
          -14.266666666666667,
          -11.166666666666666,
          -14.266666666666667,
          -11.133333333333333,
          -11.133333333333333,
          -11.133333333333333,
          -11.033333333333333,
          -14.3,
          -11.433333333333334,
          -11.266666666666667,
          -14.266666666666667,
          -20.533333333333335,
          -11.2,
          -14.233333333333333,
          -11.133333333333333,
          -14.3,
          -11.1,
          -14.1,
          -14.466666666666667,
          -11.666666666666666,
          -14.366666666666667,
          -11,
          -11.766666666666667,
          -11.2,
          -11.233333333333333,
          -14.533333333333333,
          -14.433333333333334,
          -17.4,
          -11.533333333333333,
          -20.633333333333333,
          -14.366666666666667,
          -14.3,
          -14.266666666666667,
          -14.5,
          -14.3,
          -14.3,
          -14.2,
          -14.266666666666667,
          -17.233333333333334,
          -14.233333333333333,
          -11.133333333333333,
          -17.466666666666665,
          -14.1,
          -14.366666666666667,
          -14.633333333333333,
          -11.066666666666666,
          -17.633333333333333,
          -11.133333333333333,
          -11.1,
          -14.5,
          -14.266666666666667,
          -14.3,
          -11.733333333333333,
          -11.166666666666666,
          -14.1,
          -11.033333333333333,
          -14.166666666666666,
          -14.166666666666666,
          -14.166666666666666,
          -11,
          -11.166666666666666,
          -20.5,
          -20.433333333333334,
          -17.2,
          -14.166666666666666,
          -11,
          -14.3,
          -11.433333333333334,
          -11.333333333333334,
          -11.033333333333333,
          -14.233333333333333,
          -20.366666666666667,
          -11.466666666666667,
          -14.533333333333333,
          -14.466666666666667,
          -14.266666666666667,
          -14.3,
          -17.566666666666666,
          -11.133333333333333,
          -17.1,
          -14.233333333333333,
          -14.266666666666667,
          -11.133333333333333,
          -11.066666666666666,
          -11.3,
          -14.133333333333333,
          -14.4,
          -11.066666666666666,
          -20.4,
          -11,
          -11,
          -11.133333333333333,
          -11.133333333333333,
          -17.466666666666665,
          -14.466666666666667,
          -11.133333333333333,
          -14.433333333333334,
          -11.066666666666666,
          -11.266666666666667,
          -11.166666666666666,
          -11.166666666666666,
          -11.133333333333333,
          -17.7,
          -11.2,
          -11.2,
          -14.4,
          -11,
          -11.266666666666667,
          -11.266666666666667,
          -11.1,
          -17.133333333333333,
          -11.3,
          -17.133333333333333,
          -11.133333333333333,
          -14.3,
          -11.066666666666666,
          -14.5,
          -11,
          -14.566666666666666,
          -14.133333333333333,
          -11.133333333333333,
          -11.2,
          -11.4,
          -11.733333333333333,
          -11.066666666666666,
          -14.5,
          -14.333333333333334,
          -11.1,
          -17.833333333333332,
          -14.433333333333334,
          -14.266666666666667,
          -11.2,
          -14.166666666666666,
          -11,
          -11.2,
          -11,
          -11.066666666666666,
          -11,
          -14.433333333333334,
          -14.466666666666667,
          -11.133333333333333,
          -11.133333333333333,
          -17.833333333333332,
          -14.433333333333334,
          -14.433333333333334,
          -14.566666666666666,
          -11.166666666666666,
          -14.3,
          -14.466666666666667,
          -11.1,
          -17.2,
          -17.4,
          -14.333333333333334,
          -11.133333333333333,
          -11,
          -11.266666666666667,
          -11.3,
          -14.3,
          -14.366666666666667,
          -11.2,
          -14.2,
          -14.166666666666666,
          -11.333333333333334,
          -11.233333333333333,
          -11.3,
          -11.066666666666666,
          -11.266666666666667,
          -14.833333333333334,
          -13.966666666666667,
          -17.7,
          -14.266666666666667,
          -11.2,
          -11.333333333333334,
          -14.1,
          -11.066666666666666,
          -17.633333333333333,
          -20.666666666666668,
          -11.066666666666666,
          -14.233333333333333,
          -14.366666666666667,
          -11,
          -14.6,
          -14.133333333333333,
          -17.333333333333332,
          -11.1,
          -20.7,
          -11.166666666666666,
          -17.333333333333332,
          -14.233333333333333,
          -11.133333333333333,
          -14.2,
          -17.3,
          -11.233333333333333,
          -11.533333333333333,
          -20.966666666666665,
          -11.333333333333334,
          -11,
          -14.233333333333333,
          -14.3,
          -14.5,
          -17.333333333333332,
          -11.2,
          -14,
          -11.233333333333333,
          -11,
          -11.066666666666666,
          -14.266666666666667,
          -14.5,
          -16.933333333333334,
          -14.266666666666667,
          -11.133333333333333,
          -14.233333333333333,
          -14.366666666666667,
          -14.433333333333334,
          -14.266666666666667,
          -14.433333333333334,
          -11.2,
          -11.2,
          -11.066666666666666,
          -14.366666666666667,
          -14.266666666666667,
          -14.166666666666666,
          -11.066666666666666,
          -17.633333333333333,
          -11.066666666666666,
          -14.8,
          -14.2,
          -17.533333333333335,
          -11.066666666666666,
          -11.066666666666666,
          -14.366666666666667,
          -11.066666666666666,
          -11.166666666666666,
          -11.133333333333333,
          -17.166666666666668,
          -11,
          -14.9,
          -11.066666666666666,
          -11.066666666666666,
          -11.033333333333333,
          -11.133333333333333,
          -14.266666666666667,
          -14.166666666666666,
          -14.266666666666667,
          -14.366666666666667,
          -11.1,
          -14.033333333333333,
          -11.266666666666667,
          -17.566666666666666,
          -17.4,
          -17.2,
          -11,
          -11.433333333333334,
          -14.2,
          -11.3,
          -14.233333333333333,
          -11.166666666666666,
          -17.566666666666666,
          -17.466666666666665,
          -11,
          -11.2,
          -11.133333333333333,
          -14.1,
          -20.133333333333333,
          -11.2,
          -14.233333333333333,
          -11.333333333333334,
          -17.433333333333334,
          -11.266666666666667,
          -14.133333333333333,
          -11.066666666666666,
          -11.133333333333333,
          -17.066666666666666,
          -14.533333333333333,
          -11.133333333333333,
          -14.033333333333333,
          -11.066666666666666,
          -11.1,
          -14.166666666666666,
          -14.733333333333333,
          -14.566666666666666,
          -11.666666666666666,
          -14.533333333333333,
          -17.933333333333334,
          -14.1,
          -17.633333333333333,
          -11.666666666666666,
          -14.266666666666667,
          -11.133333333333333,
          -17.133333333333333,
          -14.233333333333333,
          -14.033333333333333,
          -11.133333333333333,
          -11.066666666666666,
          -24.266666666666666,
          -14,
          -11.566666666666666,
          -14.5,
          -11.033333333333333,
          -14.366666666666667,
          -11.133333333333333,
          -14.433333333333334,
          -11.4,
          -14.266666666666667,
          -11.133333333333333,
          -17.666666666666668,
          -14.3,
          -11.033333333333333,
          -14.266666666666667,
          -11.133333333333333,
          -14.3,
          -11.2,
          -17.333333333333332,
          -17.333333333333332,
          -11.466666666666667,
          -11.266666666666667,
          -11.1,
          -11,
          -11,
          -11.166666666666666,
          -14.1,
          -14.3,
          -20.533333333333335,
          -20.433333333333334,
          -11.233333333333333,
          -14.366666666666667,
          -11.133333333333333,
          -14.333333333333334,
          -14.4,
          -14.266666666666667,
          -11.266666666666667,
          -14.4,
          -17.5,
          -11.133333333333333,
          -11.033333333333333,
          -11.066666666666666,
          -11.133333333333333,
          -11.433333333333334,
          -14.333333333333334,
          -11.033333333333333,
          -17.566666666666666,
          -11.333333333333334,
          -11.166666666666666,
          -11.466666666666667,
          -14.1,
          -11.033333333333333,
          -11,
          -14.466666666666667,
          -14.5,
          -14.133333333333333,
          -11.2,
          -11,
          -14.033333333333333,
          -17.666666666666668,
          -11,
          -11,
          -13.966666666666667,
          -17.566666666666666,
          -17.366666666666667,
          -14.4,
          -14.633333333333333,
          -14.133333333333333,
          -14.166666666666666,
          -11.066666666666666,
          -14.133333333333333,
          -14.333333333333334,
          -11.066666666666666,
          -14.4,
          -11.1,
          -11.066666666666666,
          -11.133333333333333,
          -14.166666666666666,
          -14.166666666666666,
          -11,
          -14.4,
          -12.066666666666666,
          -14.266666666666667,
          -14.266666666666667,
          -11,
          -11.066666666666666,
          -14.1,
          -11.066666666666666,
          -11.2,
          -14.6,
          -17.7,
          -14.133333333333333,
          -11.233333333333333,
          -11.366666666666667,
          -17.433333333333334,
          -11.2,
          -14.766666666666667,
          -14.3,
          -14.333333333333334,
          -11.133333333333333,
          -14.266666666666667,
          -14.333333333333334,
          -17.566666666666666,
          -14.3,
          -11.533333333333333,
          -11.166666666666666,
          -11.033333333333333,
          -14.333333333333334,
          -11.066666666666666,
          -11.266666666666667,
          -17.466666666666665,
          -11.133333333333333,
          -11.033333333333333,
          -11.433333333333334,
          -20.566666666666666,
          -11.566666666666666,
          -11,
          -14.4,
          -11.033333333333333,
          -20.2,
          -18.133333333333333,
          -11.166666666666666,
          -17.333333333333332,
          -11.4,
          -11.133333333333333,
          -20.5,
          -14.166666666666666,
          -11.433333333333334,
          -11.066666666666666,
          -11.2,
          -11.3,
          -11,
          -20.666666666666668,
          -11.033333333333333,
          -11.366666666666667,
          -11.066666666666666,
          -11.266666666666667,
          -11.266666666666667,
          -14.033333333333333,
          -11.066666666666666,
          -11,
          -17.5,
          -17.466666666666665,
          -11.366666666666667,
          -14.233333333333333,
          -17.7,
          -11.2,
          -11.066666666666666,
          -20.466666666666665,
          -17.6,
          -11.1,
          -11,
          -20.6,
          -11.333333333333334,
          -11,
          -11.666666666666666,
          -11.066666666666666,
          -14.066666666666666,
          -14.233333333333333,
          -11.133333333333333,
          -14.366666666666667,
          -11.4,
          -14.233333333333333,
          -17.3,
          -14.366666666666667,
          -20.933333333333334,
          -11.2,
          -14.633333333333333,
          -11.233333333333333,
          -14.133333333333333,
          -11,
          -11.166666666666666,
          -14.333333333333334,
          -11.266666666666667,
          -17.266666666666666,
          -20.566666666666666,
          -14.333333333333334,
          -17.5,
          -11.266666666666667,
          -11.066666666666666,
          -11.133333333333333,
          -14.133333333333333,
          -11.3,
          -11.2,
          -14.133333333333333,
          -11.2,
          -14.033333333333333,
          -20.866666666666667,
          -11.066666666666666,
          -11.1,
          -20.8,
          -17.3,
          -14.1,
          -11.2,
          -11.2,
          -14.666666666666666,
          -14.4,
          -17.166666666666668,
          -17.433333333333334,
          -11.633333333333333,
          -11.066666666666666,
          -11,
          -14.133333333333333,
          -11,
          -11.166666666666666,
          -14.733333333333333,
          -11,
          -14.333333333333334,
          -17.6,
          -11.366666666666667,
          -11,
          -11.133333333333333,
          -14.166666666666666,
          -14.1,
          -11.066666666666666,
          -11.233333333333333,
          -11.2,
          -11.133333333333333,
          -14.133333333333333,
          -14.666666666666666,
          -14.133333333333333,
          -14.3,
          -11,
          -14.266666666666667,
          -14.033333333333333,
          -11.2,
          -11,
          -17.2,
          -11.266666666666667,
          -11.233333333333333,
          -11.2,
          -11.3,
          -11.133333333333333,
          -14.033333333333333,
          -11,
          -11.266666666666667,
          -20.466666666666665,
          -11.333333333333334,
          -14.4,
          -11.133333333333333,
          -11.4,
          -11.266666666666667,
          -14.433333333333334,
          -20.433333333333334,
          -14.7,
          -11.033333333333333,
          -11.066666666666666,
          -17.4,
          -11.133333333333333,
          -14.333333333333334,
          -11.666666666666666,
          -11.333333333333334,
          -12.066666666666666,
          -11.1,
          -21,
          -17.533333333333335,
          -11.233333333333333,
          -17.633333333333333,
          -11.433333333333334,
          -17.9,
          -14.133333333333333,
          -11.233333333333333,
          -11.166666666666666,
          -11,
          -14.1,
          -14.2,
          -11.4,
          -11.133333333333333,
          -17.166666666666668,
          -20.566666666666666,
          -11,
          -11.1,
          -14.2,
          -11.066666666666666,
          -11.066666666666666,
          -11.733333333333333,
          -11.033333333333333,
          -11.133333333333333,
          -14.466666666666667,
          -11.066666666666666,
          -17.2,
          -11.466666666666667,
          -14.433333333333334,
          -14.2,
          -11.1,
          -11.066666666666666,
          -11.066666666666666,
          -14.3,
          -14.166666666666666,
          -14.2,
          -11.133333333333333,
          -14.466666666666667,
          -14.133333333333333,
          -11.066666666666666,
          -11.233333333333333,
          -11.1,
          -11.066666666666666,
          -14.233333333333333,
          -14.333333333333334,
          -11.133333333333333,
          -11.133333333333333,
          -14.433333333333334,
          -11.333333333333334,
          -11,
          -14.266666666666667,
          -11.066666666666666,
          -14.133333333333333,
          -14.266666666666667,
          -14.166666666666666,
          -14.633333333333333,
          -14.4,
          -14.166666666666666,
          -14.366666666666667,
          -11.4,
          -23.833333333333332,
          -17.6,
          -17.466666666666665,
          -14.4,
          -17.333333333333332,
          -11,
          -11.2,
          -17.333333333333332,
          -17.566666666666666,
          -11.433333333333334,
          -11.066666666666666,
          -11,
          -17.4,
          -11,
          -11.566666666666666,
          -14.633333333333333,
          -26.733333333333334,
          -11.166666666666666,
          -14.366666666666667,
          -14.2,
          -11.066666666666666,
          -11.333333333333334,
          -11.133333333333333,
          -11.366666666666667,
          -14.1,
          -11.066666666666666,
          -14.733333333333333,
          -11.3,
          -20.6,
          -14.1,
          -14.466666666666667,
          -11.133333333333333,
          -11.6,
          -14.266666666666667,
          -14.2,
          -11.066666666666666,
          -17.466666666666665,
          -14.4,
          -14.366666666666667,
          -14.1,
          -17.633333333333333,
          -17.833333333333332,
          -14.5,
          -11.066666666666666,
          -11.133333333333333,
          -11.266666666666667,
          -11.266666666666667,
          -20.3,
          -14.1,
          -14.4,
          -11,
          -11.033333333333333,
          -13.966666666666667,
          -14.533333333333333,
          -11.2,
          -11.133333333333333,
          -14.2,
          -14.4,
          -11.333333333333334,
          -14.233333333333333,
          -14.666666666666666,
          -14.233333333333333,
          -11.133333333333333,
          -11.366666666666667,
          -11,
          -11.733333333333333,
          -20.666666666666668,
          -11.033333333333333,
          -14.7,
          -11.166666666666666,
          -11,
          -17.433333333333334,
          -11,
          -14.433333333333334,
          -14.433333333333334,
          -14.433333333333334,
          -11.066666666666666,
          -17.5,
          -14.366666666666667,
          -14.5,
          -11.433333333333334,
          -14.333333333333334,
          -11.1,
          -14.333333333333334,
          -14.266666666666667,
          -11.233333333333333,
          -17.033333333333335,
          -11.2,
          -11.133333333333333,
          -11.333333333333334,
          -11.4,
          -17.333333333333332,
          -11.5,
          -14.6,
          -11,
          -11.233333333333333,
          -17.4,
          -11.233333333333333,
          -11.2,
          -14.266666666666667,
          -14.766666666666667,
          -20.5,
          -11.133333333333333,
          -14.133333333333333,
          -14.066666666666666,
          -11.066666666666666,
          -11.033333333333333,
          -14.666666666666666,
          -14.466666666666667,
          -17.133333333333333,
          -11.133333333333333,
          -14.2,
          -14.333333333333334,
          -11.133333333333333,
          -11.166666666666666,
          -20.566666666666666,
          -11.2,
          -14.333333333333334,
          -20.966666666666665,
          -14.633333333333333,
          -11.133333333333333,
          -14.166666666666666,
          -17.633333333333333,
          -11.033333333333333,
          -17.3,
          -11.333333333333334,
          -14.133333333333333,
          -14.233333333333333,
          -11.033333333333333,
          -14.233333333333333,
          -11.666666666666666,
          -17.1,
          -11.133333333333333,
          -11.233333333333333,
          -14.433333333333334,
          -11.133333333333333,
          -14.266666666666667,
          -14.533333333333333,
          -11.333333333333334,
          -11.166666666666666,
          -11.3,
          -11.133333333333333,
          -14.433333333333334,
          -11.6,
          -11,
          -14.3,
          -11.033333333333333,
          -14.466666666666667,
          -14.4,
          -17.633333333333333,
          -20.366666666666667,
          -11.333333333333334,
          -14.2,
          -14.233333333333333,
          -14.166666666666666,
          -11.266666666666667,
          -20.8,
          -17.466666666666665,
          -17.2,
          -17.166666666666668,
          -14.3,
          -11.2,
          -17.6,
          -11.066666666666666,
          -11.1,
          -14.266666666666667,
          -17.233333333333334,
          -11,
          -14.3,
          -14.333333333333334,
          -14.333333333333334,
          -11,
          -11.3,
          -14.1,
          -11.4,
          -11.566666666666666,
          -14.166666666666666,
          -14.133333333333333,
          -11.1,
          -11.3,
          -11,
          -11.066666666666666,
          -14.133333333333333,
          -11.066666666666666,
          -11.033333333333333,
          -11.533333333333333,
          -14.233333333333333,
          -14.633333333333333,
          -14.766666666666667,
          -14.4,
          -14.433333333333334,
          -14.233333333333333,
          -11.4,
          -14.4,
          -11.233333333333333,
          -11.066666666666666,
          -14.366666666666667,
          -14.366666666666667,
          -11,
          -11.066666666666666,
          -11.066666666666666,
          -11.333333333333334,
          -11.166666666666666,
          -11.466666666666667,
          -14.166666666666666,
          -17.633333333333333,
          -11.133333333333333,
          -11.066666666666666,
          -11.533333333333333,
          -17.4,
          -14.3,
          -17.366666666666667,
          -14.133333333333333,
          -11.2,
          -11.133333333333333,
          -14.266666666666667,
          -14.233333333333333,
          -11.133333333333333,
          -14.4,
          -14.6,
          -11.133333333333333,
          -11.3,
          -17.3,
          -17.566666666666666,
          -11.433333333333334,
          -11.533333333333333,
          -17.433333333333334,
          -14.8,
          -14.266666666666667,
          -14.333333333333334,
          -14.633333333333333,
          -11.066666666666666,
          -11.133333333333333,
          -11.333333333333334,
          -11.066666666666666,
          -17.066666666666666,
          -11.066666666666666,
          -14.166666666666666,
          -17.633333333333333,
          -11.1,
          -14.1,
          -14.3,
          -11.6,
          -11.2,
          -11,
          -17.633333333333333,
          -11.133333333333333,
          -11.133333333333333,
          -11.066666666666666,
          -14.466666666666667,
          -14.1,
          -11.2,
          -11.066666666666666,
          -17.166666666666668,
          -11,
          -11.066666666666666,
          -14.166666666666666,
          -11.4,
          -11.066666666666666,
          -11,
          -11.566666666666666,
          -11.2,
          -17.466666666666665,
          -14.133333333333333,
          -14.3,
          -11.066666666666666,
          -11,
          -14.433333333333334,
          -11.133333333333333,
          -11,
          -14.1,
          -17.3,
          -17.333333333333332,
          -14.366666666666667,
          -11.133333333333333,
          -11.333333333333334,
          -21.1,
          -14.233333333333333,
          -14.233333333333333,
          -14.633333333333333,
          -17.1,
          -11.133333333333333,
          -11.166666666666666,
          -11.133333333333333,
          -11.066666666666666,
          -11.066666666666666,
          -11,
          -14.133333333333333,
          -14.233333333333333,
          -14.166666666666666,
          -11.266666666666667,
          -17.766666666666666,
          -20.633333333333333,
          -11.166666666666666,
          -17.966666666666665,
          -11.1,
          -11.033333333333333,
          -14.5,
          -14.1,
          -11,
          -14.366666666666667,
          -11.133333333333333,
          -11.366666666666667,
          -17.833333333333332,
          -11,
          -11,
          -11.266666666666667,
          -17.4,
          -11.066666666666666,
          -11.233333333333333,
          -11.2,
          -11.1,
          -17.533333333333335,
          -14.366666666666667,
          -11,
          -14.333333333333334,
          -11.133333333333333,
          -17.033333333333335,
          -20.533333333333335,
          -14.333333333333334,
          -14.433333333333334,
          -14.366666666666667,
          -20.266666666666666,
          -14.1,
          -17.066666666666666,
          -11.2,
          -14.3,
          -11.133333333333333,
          -17.4,
          -20.466666666666665,
          -11.166666666666666,
          -14.1,
          -14.233333333333333,
          -11.2,
          -17.3,
          -23.566666666666666,
          -11.133333333333333,
          -11,
          -11.133333333333333,
          -14.233333333333333,
          -11,
          -17.466666666666665,
          -11.2,
          -14.1,
          -11.166666666666666,
          -11.066666666666666,
          -11.133333333333333,
          -14.633333333333333,
          -11.066666666666666,
          -17.233333333333334,
          -11.1,
          -14.433333333333334,
          -11,
          -14.466666666666667,
          -11.233333333333333,
          -14.066666666666666,
          -11.266666666666667,
          -11.266666666666667,
          -11.2,
          -11.066666666666666,
          -17.4,
          -11.233333333333333,
          -11.066666666666666,
          -11.2,
          -11,
          -11.066666666666666,
          -11.8,
          -11.2,
          -17.533333333333335,
          -11.066666666666666,
          -11.2,
          -11.066666666666666,
          -14.233333333333333,
          -14.233333333333333,
          -14.366666666666667,
          -11.3,
          -11.066666666666666,
          -11.133333333333333,
          -14.566666666666666,
          -11.333333333333334,
          -14.1,
          -14.366666666666667,
          -11.133333333333333,
          -14.1,
          -11.133333333333333,
          -11.166666666666666,
          -20.433333333333334,
          -14.266666666666667,
          -11.066666666666666,
          -14.333333333333334,
          -11.066666666666666,
          -11.2,
          -17.166666666666668,
          -11.133333333333333,
          -11.133333333333333,
          -11.066666666666666,
          -13.966666666666667,
          -14.533333333333333,
          -11.133333333333333,
          -11.033333333333333,
          -11.066666666666666,
          -11.066666666666666,
          -11.2,
          -14.333333333333334,
          -20.4,
          -11.066666666666666,
          -11.166666666666666,
          -11.066666666666666,
          -11.133333333333333,
          -14.233333333333333,
          -11.166666666666666,
          -11.066666666666666,
          -11.066666666666666,
          -14.066666666666666,
          -11.1,
          -11,
          -11.333333333333334,
          -14.366666666666667,
          -11.266666666666667,
          -14.2,
          -17.1,
          -14.133333333333333,
          -20.6,
          -11.133333333333333,
          -11.1,
          -14.166666666666666,
          -11.9,
          -14.5,
          -14.033333333333333,
          -14.433333333333334,
          -11.066666666666666,
          -11.266666666666667,
          -20.2,
          -14.333333333333334,
          -17.6,
          -14.333333333333334,
          -11.533333333333333,
          -11.166666666666666,
          -11.166666666666666,
          -11,
          -14.2,
          -17.2,
          -17.533333333333335,
          -11.166666666666666,
          -17.5,
          -14.266666666666667,
          -14.4,
          -14.2,
          -14.4,
          -14.433333333333334,
          -14.366666666666667,
          -20.5,
          -14.066666666666666,
          -20.433333333333334,
          -17.4,
          -14.233333333333333,
          -14.333333333333334,
          -11.233333333333333,
          -14.266666666666667,
          -14.166666666666666,
          -11.533333333333333,
          -11.333333333333334,
          -11.166666666666666,
          -14.233333333333333,
          -11.133333333333333,
          -11.133333333333333,
          -11.266666666666667,
          -17.4,
          -20.933333333333334,
          -11.366666666666667,
          -14.033333333333333,
          -14.8,
          -17.933333333333334,
          -11.533333333333333,
          -14.4,
          -17.366666666666667,
          -11.166666666666666,
          -14.166666666666666,
          -14.533333333333333,
          -14.166666666666666,
          -11.5,
          -14.3,
          -14.333333333333334,
          -14.1,
          -11,
          -11.4,
          -11.1,
          -14.2,
          -14.233333333333333,
          -11.1,
          -14.366666666666667,
          -17.3,
          -11.333333333333334,
          -17.733333333333334,
          -14.2,
          -14.8,
          -11.3,
          -14.266666666666667,
          -11.133333333333333,
          -11.066666666666666,
          -14.533333333333333,
          -14.166666666666666,
          -11.066666666666666,
          -11.133333333333333,
          -14.233333333333333,
          -11.5,
          -14.266666666666667,
          -14.5,
          -14.533333333333333,
          -14.5,
          -14.166666666666666,
          -11.333333333333334,
          -14.166666666666666,
          -11.066666666666666,
          -17.466666666666665,
          -11.033333333333333,
          -20.666666666666668,
          -14.466666666666667,
          -14.266666666666667,
          -11.133333333333333,
          -14.7,
          -17.6,
          -14.233333333333333,
          -11.533333333333333,
          -11.5,
          -14.066666666666666,
          -14.366666666666667,
          -14.5,
          -11,
          -14.2,
          -14.233333333333333,
          -11.133333333333333,
          -20.7,
          -11.033333333333333,
          -17.566666666666666,
          -20.166666666666668,
          -17.533333333333335,
          -11,
          -11.133333333333333,
          -11.2,
          -11,
          -23.666666666666668,
          -14.133333333333333,
          -14.066666666666666,
          -14.466666666666667,
          -11.066666666666666,
          -14.233333333333333,
          -11.2,
          -11.033333333333333,
          -11.533333333333333,
          -11,
          -14.166666666666666,
          -17.333333333333332,
          -14.033333333333333,
          -11.166666666666666,
          -11.066666666666666,
          -17.366666666666667,
          -14.266666666666667,
          -14.133333333333333,
          -14.1,
          -11,
          -14.433333333333334,
          -11.066666666666666,
          -14.3,
          -11.066666666666666,
          -17.5,
          -14.3,
          -11.066666666666666,
          -11.033333333333333,
          -14.2,
          -11.166666666666666,
          -14.333333333333334,
          -17.233333333333334,
          -11.1,
          -14.9,
          -11.2,
          -11,
          -11.133333333333333,
          -14.2,
          -14.133333333333333,
          -17.433333333333334,
          -14.333333333333334,
          -11.266666666666667,
          -17.3,
          -14.333333333333334,
          -11.5,
          -14.5,
          -17.566666666666666,
          -11.433333333333334,
          -14.333333333333334,
          -14.2,
          -14.366666666666667,
          -17.333333333333332,
          -11.8,
          -11,
          -11.433333333333334,
          -14.466666666666667,
          -14.2,
          -14.433333333333334,
          -14.3,
          -11.466666666666667,
          -11.233333333333333,
          -14.466666666666667,
          -14.233333333333333,
          -14.033333333333333,
          -14.2,
          -14.4,
          -11.3,
          -20.533333333333335,
          -11.033333333333333,
          -11.333333333333334,
          -11.2,
          -11.133333333333333,
          -14.266666666666667,
          -11.266666666666667,
          -11.166666666666666,
          -11.166666666666666,
          -14.1,
          -14.133333333333333,
          -14.033333333333333,
          -14.166666666666666,
          -11.366666666666667,
          -14.1,
          -14.666666666666666,
          -14.233333333333333,
          -11.266666666666667,
          -11,
          -11.066666666666666,
          -11.133333333333333,
          -14.3,
          -14.4,
          -11.366666666666667,
          -14.333333333333334,
          -11.233333333333333,
          -14.233333333333333,
          -14.266666666666667,
          -11.2,
          -11.066666666666666,
          -17.133333333333333,
          -17.566666666666666,
          -11,
          -11.2,
          -11.5,
          -11.066666666666666,
          -17.533333333333335,
          -11.4,
          -11.3,
          -14.2,
          -21.033333333333335,
          -11.133333333333333,
          -17.7,
          -11.2,
          -11.066666666666666,
          -11.066666666666666,
          -14.233333333333333,
          -14.333333333333334,
          -14.133333333333333,
          -14.3,
          -11.5,
          -14.2,
          -14.1,
          -14.3,
          -14.3,
          -11.133333333333333,
          -20.566666666666666,
          -11.233333333333333,
          -17.633333333333333,
          -11.066666666666666,
          -14.166666666666666,
          -14.1,
          -11.233333333333333,
          -17.766666666666666,
          -14.1,
          -11.066666666666666,
          -14.433333333333334,
          -14.2,
          -11.233333333333333,
          -17.466666666666665,
          -14.433333333333334,
          -11,
          -11.3,
          -11.033333333333333,
          -14.333333333333334,
          -17.433333333333334,
          -14.266666666666667,
          -11.133333333333333,
          -11.1,
          -11.066666666666666,
          -14.433333333333334,
          -14.333333333333334,
          -11.133333333333333,
          -14.1,
          -17.566666666666666,
          -11.066666666666666,
          -17.333333333333332,
          -11.2,
          -11.066666666666666,
          -11.266666666666667,
          -17.5,
          -17.533333333333335,
          -11.2,
          -14.466666666666667,
          -11.1,
          -11.066666666666666,
          -11.066666666666666,
          -14.166666666666666,
          -14.1,
          -11.533333333333333,
          -14.733333333333333,
          -17.3,
          -14.1,
          -11.066666666666666,
          -18.033333333333335,
          -11.066666666666666,
          -11.2,
          -14.233333333333333,
          -17.4,
          -11.066666666666666,
          -14.4,
          -17.4,
          -11.1,
          -11.233333333333333,
          -11.033333333333333,
          -11.566666666666666,
          -11.133333333333333,
          -14.233333333333333,
          -11.133333333333333,
          -14.2,
          -11.166666666666666,
          -11.2,
          -11.366666666666667,
          -14.4,
          -14.266666666666667,
          -11.133333333333333,
          -11.2,
          -11.1,
          -11,
          -11.033333333333333,
          -17.366666666666667,
          -14.3,
          -11.4,
          -11,
          -14.233333333333333,
          -17.566666666666666,
          -20.633333333333333,
          -17.4,
          -17.466666666666665,
          -11.766666666666667,
          -11.066666666666666,
          -14.2,
          -11.066666666666666,
          -14.366666666666667,
          -14.266666666666667,
          -11.2,
          -14.1,
          -11.3,
          -11.2,
          -11.233333333333333,
          -14.3,
          -17.7,
          -11.1,
          -17.333333333333332,
          -11,
          -17.466666666666665,
          -17.5,
          -14.166666666666666,
          -11.066666666666666,
          -14.066666666666666,
          -11.533333333333333,
          -17.2,
          -11.133333333333333,
          -11.066666666666666,
          -17.366666666666667,
          -11,
          -14.233333333333333,
          -14.566666666666666,
          -11.066666666666666,
          -17.533333333333335,
          -14.266666666666667,
          -11.166666666666666,
          -20.533333333333335,
          -14.366666666666667,
          -11.066666666666666,
          -11.1,
          -14.133333333333333,
          -11.233333333333333,
          -17.5,
          -14.1,
          -11.066666666666666,
          -11.366666666666667,
          -14.266666666666667,
          -11.033333333333333,
          -11.666666666666666,
          -14.166666666666666,
          -17.3,
          -14.4,
          -11,
          -14.333333333333334,
          -11.133333333333333,
          -14.266666666666667,
          -11.166666666666666,
          -11.633333333333333,
          -17.566666666666666,
          -11.066666666666666,
          -11.2,
          -11.133333333333333,
          -11.066666666666666,
          -17.366666666666667,
          -11,
          -14.166666666666666,
          -14.333333333333334,
          -14.6,
          -11.033333333333333,
          -11.066666666666666,
          -14.666666666666666,
          -14.133333333333333,
          -14.7,
          -11.266666666666667,
          -14.3,
          -11.133333333333333,
          -17.533333333333335,
          -11.3,
          -11.033333333333333,
          -14.666666666666666,
          -14.1,
          -14.266666666666667,
          -11.266666666666667,
          -11.333333333333334,
          -17.133333333333333,
          -11.066666666666666,
          -17.766666666666666,
          -11.066666666666666,
          -11,
          -11.2,
          -11.266666666666667,
          -11.066666666666666,
          -20.833333333333332,
          -17.633333333333333,
          -20.366666666666667,
          -11.133333333333333,
          -14.333333333333334,
          -17.5,
          -11.1,
          -14.366666666666667,
          -11.1,
          -11,
          -11.166666666666666,
          -11.133333333333333,
          -11.266666666666667,
          -20.333333333333332,
          -17.766666666666666,
          -20.466666666666665,
          -14.233333333333333,
          -14.266666666666667,
          -14.166666666666666,
          -11,
          -17.466666666666665,
          -14.366666666666667,
          -14.533333333333333,
          -11,
          -14.333333333333334,
          -11.733333333333333,
          -11.066666666666666,
          -14.233333333333333,
          -14.4,
          -17.266666666666666,
          -11.133333333333333,
          -11.033333333333333,
          -11.233333333333333,
          -11.133333333333333,
          -14.366666666666667,
          -11.333333333333334,
          -14.2,
          -20.6,
          -17.066666666666666,
          -14.2,
          -14.466666666666667,
          -17.3,
          -14.5,
          -14.333333333333334,
          -14.233333333333333,
          -11,
          -17.4,
          -11.133333333333333,
          -11.133333333333333,
          -17.5,
          -14.366666666666667,
          -11,
          -14.1,
          -14.366666666666667,
          -17.733333333333334,
          -17.4,
          -14.533333333333333,
          -11.2,
          -11.2,
          -11.1,
          -11,
          -11.2,
          -17.466666666666665,
          -11.2,
          -14.466666666666667,
          -17.1,
          -11.133333333333333,
          -17.633333333333333,
          -11.466666666666667,
          -11.066666666666666,
          -14.266666666666667,
          -11.066666666666666,
          -14.266666666666667,
          -11.066666666666666,
          -11.2,
          -11.5,
          -14.366666666666667,
          -11.233333333333333,
          -14.066666666666666,
          -11.4,
          -11.066666666666666,
          -11.2,
          -14.3,
          -14.4,
          -11,
          -11.2,
          -14.633333333333333,
          -14.433333333333334,
          -14.133333333333333,
          -13.966666666666667,
          -14.266666666666667,
          -14.166666666666666,
          -11.1,
          -11.066666666666666,
          -11.233333333333333,
          -20.233333333333334,
          -14.5,
          -11.133333333333333,
          -11.066666666666666,
          -14.366666666666667,
          -14.033333333333333,
          -14.266666666666667,
          -14.133333333333333,
          -14.433333333333334,
          -11,
          -14.1,
          -11.066666666666666,
          -14.333333333333334,
          -14.3,
          -14.266666666666667,
          -11.133333333333333,
          -11.066666666666666,
          -11.2,
          -14.233333333333333,
          -11,
          -11,
          -14.233333333333333,
          -11.1,
          -17.333333333333332,
          -14.233333333333333,
          -11.4,
          -11.2,
          -11.333333333333334,
          -11.266666666666667,
          -14.633333333333333,
          -14.033333333333333,
          -17.3,
          -11.3,
          -17.566666666666666,
          -11.2,
          -11.133333333333333,
          -11.033333333333333,
          -14.433333333333334,
          -11.133333333333333,
          -17.7,
          -14.333333333333334,
          -14.2,
          -11.066666666666666,
          -14.333333333333334,
          -17.9,
          -15.333333333333334,
          -11.2,
          -11.066666666666666,
          -14.366666666666667,
          -11.1,
          -11.033333333333333,
          -14.4,
          -14.033333333333333,
          -20.8,
          -11.066666666666666,
          -11.133333333333333,
          -11.633333333333333,
          -17.366666666666667,
          -11,
          -14.166666666666666,
          -11.3,
          -11.066666666666666,
          -14.1,
          -11.133333333333333,
          -14.333333333333334,
          -11.066666666666666,
          -11.266666666666667,
          -11.2,
          -14.5,
          -11.133333333333333,
          -14.9,
          -11.133333333333333,
          -11.066666666666666,
          -17.3,
          -11.4,
          -23.633333333333333,
          -11,
          -17.5,
          -11.1,
          -14.266666666666667,
          -11,
          -14.1,
          -11.4,
          -14.433333333333334,
          -17.4,
          -11.233333333333333,
          -14.266666666666667,
          -11.133333333333333,
          -14.7,
          -11.366666666666667,
          -14.333333333333334,
          -11.266666666666667,
          -11,
          -11.1,
          -11,
          -11.133333333333333,
          -11.266666666666667,
          -14.1,
          -17.2,
          -11.1,
          -14.1,
          -11.066666666666666,
          -14.566666666666666,
          -11,
          -14.233333333333333,
          -11,
          -14.366666666666667,
          -11.066666666666666,
          -20.566666666666666,
          -11.266666666666667,
          -14.333333333333334,
          -11.166666666666666,
          -14.033333333333333,
          -11.066666666666666,
          -14.133333333333333,
          -14.2,
          -11.1,
          -14.4,
          -11,
          -11.2,
          -11.2,
          -14.033333333333333,
          -17.433333333333334,
          -14.033333333333333,
          -11.2,
          -14.333333333333334,
          -11.066666666666666,
          -14.233333333333333,
          -17.3,
          -11.066666666666666,
          -14.4,
          -17.566666666666666,
          -17.5,
          -11.2,
          -11,
          -11.033333333333333,
          -14.433333333333334,
          -17.533333333333335,
          -14.8,
          -11.066666666666666,
          -11.066666666666666,
          -14.433333333333334,
          -14.233333333333333,
          -11.633333333333333,
          -20.566666666666666,
          -11.266666666666667,
          -11.033333333333333,
          -11,
          -11.066666666666666,
          -14.333333333333334,
          -11,
          -15.133333333333333,
          -14.433333333333334,
          -11.1,
          -11.266666666666667,
          -14.233333333333333,
          -11.066666666666666,
          -11.2,
          -14.466666666666667,
          -11.5,
          -14.2,
          -11.133333333333333,
          -11.2,
          -14.233333333333333,
          -14.233333333333333,
          -14.533333333333333,
          -20.733333333333334,
          -17.366666666666667,
          -11,
          -14.366666666666667,
          -14.3,
          -20.133333333333333,
          -14.166666666666666,
          -11.133333333333333,
          -14.4,
          -11.1,
          -14.333333333333334,
          -11.333333333333334,
          -17.6,
          -11.133333333333333,
          -14.366666666666667,
          -11.5,
          -14.466666666666667,
          -11.1,
          -11.866666666666667,
          -17.7,
          -11.133333333333333,
          -14.566666666666666,
          -14.333333333333334,
          -14.3,
          -11,
          -11.133333333333333,
          -14.266666666666667,
          -11.2,
          -14.166666666666666,
          -11.166666666666666,
          -11.333333333333334,
          -14.7,
          -14.033333333333333,
          -14.4,
          -11.1,
          -11.133333333333333,
          -20.5,
          -14.266666666666667,
          -14.1,
          -11.133333333333333,
          -14.4,
          -11.533333333333333,
          -11.066666666666666,
          -14.1,
          -17.233333333333334,
          -11,
          -11.133333333333333,
          -11.1,
          -11.366666666666667,
          -11,
          -14.433333333333334,
          -11.133333333333333,
          -14.166666666666666,
          -11.333333333333334,
          -11.2,
          -17.4,
          -14.4,
          -17.366666666666667,
          -11.433333333333334,
          -11.033333333333333,
          -11.333333333333334,
          -11.033333333333333,
          -11.3,
          -17.4,
          -23.733333333333334,
          -11.4,
          -11.266666666666667,
          -11.066666666666666,
          -11.133333333333333,
          -14.233333333333333,
          -14.266666666666667,
          -11,
          -14.166666666666666,
          -14.4,
          -11.066666666666666,
          -17.6,
          -11.2,
          -17.3,
          -11.2,
          -14.266666666666667,
          -11.033333333333333,
          -14.533333333333333,
          -14.266666666666667,
          -14.266666666666667,
          -11.333333333333334,
          -11.066666666666666,
          -11,
          -17.433333333333334,
          -11.2,
          -14.366666666666667,
          -11.066666666666666,
          -14.6,
          -14.266666666666667,
          -17.6,
          -14.133333333333333,
          -11,
          -14.233333333333333,
          -11.266666666666667,
          -17.466666666666665,
          -11.366666666666667,
          -14.333333333333334,
          -14.6,
          -11.2,
          -14.166666666666666,
          -14.2,
          -11.133333333333333,
          -11.066666666666666,
          -14.366666666666667,
          -11.133333333333333,
          -14.4,
          -14.266666666666667,
          -11.066666666666666,
          -11.1,
          -11.266666666666667,
          -14.3,
          -14.266666666666667,
          -14.4,
          -11.133333333333333,
          -14.366666666666667,
          -17.166666666666668,
          -11.133333333333333,
          -14.1,
          -14.666666666666666,
          -11.133333333333333,
          -14.266666666666667,
          -17.433333333333334,
          -17.5,
          -11.033333333333333,
          -11.266666666666667,
          -11,
          -11.133333333333333,
          -14.366666666666667,
          -17.633333333333333,
          -11.133333333333333,
          -11.266666666666667,
          -11,
          -14.2,
          -14.433333333333334,
          -11.066666666666666,
          -11.133333333333333,
          -11.1,
          -14.5,
          -11.2,
          -11.133333333333333,
          -14.233333333333333,
          -20.4,
          -11,
          -11.133333333333333,
          -11.133333333333333,
          -14.1,
          -11.133333333333333,
          -14.7,
          -11.066666666666666,
          -11.2,
          -14.4,
          -11.2,
          -14.3,
          -11,
          -11.133333333333333,
          -11.266666666666667,
          -11.066666666666666,
          -11.066666666666666,
          -14.1,
          -14.033333333333333,
          -17.5,
          -20.666666666666668,
          -11.2,
          -11.066666666666666,
          -14.333333333333334,
          -11.2,
          -11.333333333333334,
          -14.133333333333333,
          -14.1,
          -11.133333333333333,
          -11.266666666666667,
          -14.333333333333334,
          -14.533333333333333,
          -11.066666666666666,
          -14.3,
          -14.1,
          -14.5,
          -14.166666666666666,
          -20.433333333333334,
          -14.366666666666667,
          -11.233333333333333,
          -17.333333333333332,
          -11.2,
          -20.733333333333334,
          -14.033333333333333,
          -11.133333333333333,
          -20.5,
          -11.066666666666666,
          -11.266666666666667,
          -17.533333333333335,
          -14.3,
          -11.066666666666666,
          -11.733333333333333,
          -14.5,
          -15.166666666666666,
          -11.133333333333333,
          -11.133333333333333,
          -11.033333333333333,
          -11.366666666666667,
          -11.1,
          -11.066666666666666,
          -11.133333333333333,
          -11.166666666666666,
          -14.033333333333333,
          -11.133333333333333,
          -11.166666666666666,
          -14.433333333333334,
          -14.433333333333334,
          -11.133333333333333,
          -11.066666666666666,
          -17.4,
          -11.1,
          -11.266666666666667,
          -14.366666666666667,
          -11.133333333333333,
          -14.333333333333334,
          -14.366666666666667,
          -11,
          -11.3,
          -20.333333333333332,
          -17.2,
          -14.633333333333333,
          -11.2,
          -11.333333333333334,
          -14.433333333333334,
          -14.5,
          -11.333333333333334,
          -11,
          -11.1,
          -11.066666666666666,
          -14.366666666666667,
          -11,
          -11.066666666666666,
          -17.266666666666666,
          -17.633333333333333,
          -14.266666666666667,
          -11.433333333333334,
          -11.066666666666666,
          -14.166666666666666,
          -11.2,
          -17.066666666666666,
          -11.1,
          -14.166666666666666,
          -14.2,
          -14.433333333333334,
          -20.7,
          -14.1,
          -11.2,
          -17.3,
          -17.6,
          -11.133333333333333,
          -11.466666666666667,
          -11.266666666666667,
          -17.2,
          -14.066666666666666,
          -11.333333333333334,
          -17.833333333333332,
          -11.033333333333333,
          -11.066666666666666,
          -15.166666666666666,
          -11.033333333333333,
          -11.033333333333333,
          -11.133333333333333,
          -11.366666666666667,
          -17.433333333333334,
          -11.266666666666667,
          -17.366666666666667,
          -14.166666666666666,
          -11.133333333333333,
          -11.066666666666666,
          -11.066666666666666,
          -11.1,
          -11.366666666666667,
          -14.366666666666667,
          -15,
          -11.266666666666667,
          -11.133333333333333,
          -11.066666666666666,
          -17.666666666666668,
          -14.333333333333334,
          -11.066666666666666,
          -17.833333333333332,
          -17.733333333333334,
          -11,
          -17.266666666666666,
          -17.6,
          -14.1,
          -14.433333333333334,
          -11.133333333333333,
          -11.266666666666667,
          -14.2,
          -11.4,
          -11.5,
          -11,
          -14.233333333333333,
          -14.266666666666667,
          -11.1,
          -11.133333333333333,
          -11.066666666666666
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Episodes"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "range": [
          -200,
          0
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards_df = pd.DataFrame(all_rewards)\n",
    "done_df = pd.DataFrame(all_done.cumsum(axis=0)).shift().fillna(0)\n",
    "all_trajectories = {}\n",
    "\n",
    "for i in range(N_ENV):\n",
    "    all_trajectories[i] = pd.DataFrame(done_df[i])\n",
    "    all_trajectories[i].columns = [\"Episodes\"]\n",
    "    all_trajectories[i][\"rewards\"] = rewards_df[i]\n",
    "\n",
    "    all_trajectories[i] = all_trajectories[i].groupby(\"Episodes\").agg(\"sum\")\n",
    "    all_trajectories[i] = all_trajectories[i].head(5000)\n",
    "    all_trajectories[i] = all_trajectories[i].squeeze()\n",
    "\n",
    "    title = (f\"Average Reward per Episode, averaged over {N_ENV} runs\",)\n",
    "px.line(\n",
    "    pd.DataFrame(all_trajectories).mean(axis=1),\n",
    "    range_y=[-200, 0],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-rl-KPtyfD6I-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
