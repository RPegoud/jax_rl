{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import optax\n",
    "import haiku as hk\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from jax import random, vmap, lax, tree_map\n",
    "from chex import dataclass\n",
    "from jax_tqdm import loop_tqdm\n",
    "from typing import Tuple, List\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from jym import (\n",
    "    Breakout,\n",
    "    DQN,\n",
    "    UniformReplayBuffer,\n",
    "    minatar_rollout,\n",
    "    BaseReplayBuffer,\n",
    "    SumTree,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': (64,),\n",
       " 'done': (64,),\n",
       " 'next_state': (64, 10, 10, 4),\n",
       " 'priority': (64,),\n",
       " 'reward': (64,),\n",
       " 'state': (64, 10, 10, 4)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = 64\n",
    "BATCH_SIZE = 8\n",
    "STATE_SHAPE = (10, 10, 4)\n",
    "\n",
    "buffer_state = {\n",
    "    \"state\": jnp.empty((BUFFER_SIZE, *STATE_SHAPE), dtype=jnp.float32),\n",
    "    \"action\": jnp.empty((BUFFER_SIZE,), dtype=jnp.int32),\n",
    "    \"reward\": jnp.empty((BUFFER_SIZE,), dtype=jnp.int32),\n",
    "    \"next_state\": jnp.empty((BUFFER_SIZE, *STATE_SHAPE), dtype=jnp.float32),\n",
    "    \"done\": jnp.empty((BUFFER_SIZE,), dtype=jnp.bool_),\n",
    "    \"priority\": jnp.empty((BUFFER_SIZE), dtype=jnp.float32),\n",
    "}\n",
    "jax.tree_map(lambda x: x.shape, buffer_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Experience:\n",
    "    state: jnp.ndarray\n",
    "    action: int\n",
    "    reward: float\n",
    "    next_state: jnp.ndarray\n",
    "    done: bool\n",
    "    priority: float = jnp.float32(0.0)\n",
    "\n",
    "\n",
    "class PrioritizedExperienceReplay(BaseReplayBuffer):\n",
    "    \"\"\"\n",
    "    Prioritized Experience Replay Buffer\n",
    "\n",
    "    Source: https://arxiv.org/pdf/1511.05952.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, buffer_size: int, batch_size: int, alpha: float, beta: float\n",
    "    ) -> None:\n",
    "        super().__init__(buffer_size, batch_size)\n",
    "        self.sum_tree = SumTree(buffer_size)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def add(\n",
    "        self,\n",
    "        tree_state: jnp.ndarray,\n",
    "        buffer_state: dict,\n",
    "        experience: Experience,\n",
    "        idx: int,\n",
    "    ) -> Tuple[dict, jnp.ndarray]:\n",
    "        \"\"\"\n",
    "        Adds an experience to the replay buffer and\n",
    "        its priority to the sum tree.\n",
    "        \"\"\"\n",
    "        # assigns maximal priority to the new experience\n",
    "        priorities = tree_state[-self.buffer_size :]\n",
    "        max_priority = lax.select(\n",
    "            jnp.count_nonzero(priorities) > 0,\n",
    "            jnp.max(priorities),\n",
    "            1.0,\n",
    "        )\n",
    "        experience = experience.replace(priority=max_priority)\n",
    "\n",
    "        # add the experience to the sum tree and the replay buffer\n",
    "        idx = idx % self.buffer_size\n",
    "        tree_state = self.sum_tree.add(tree_state, max_priority, idx)\n",
    "\n",
    "        # set experience fields\n",
    "        for field in experience:\n",
    "            buffer_state[field] = buffer_state[field].at[idx].set(experience[field])\n",
    "\n",
    "        return buffer_state, tree_state\n",
    "\n",
    "    def sample(\n",
    "        self,\n",
    "        key: random.PRNGKey,\n",
    "        buffer_state: dict,\n",
    "        tree_state: jnp.ndarray,\n",
    "    ) -> dict[Experience]:\n",
    "        @partial(vmap, in_axes=(0, None))\n",
    "        def sample_batch(indexes, buffer) -> Tuple[Experience]:\n",
    "            return tree_map(lambda x: x[indexes], buffer)\n",
    "\n",
    "        # compute the sampling probability\n",
    "        priorities = tree_state[-self.buffer_size :]\n",
    "        total_priority = tree_state[0]\n",
    "\n",
    "        probs = priorities**self.alpha\n",
    "        P = probs / total_priority\n",
    "        # TODO: determine how probabilities interact with the sum tree\n",
    "        # and how to replace random.choice with tree sampling\n",
    "\n",
    "        values = random.uniform(\n",
    "            key,\n",
    "            shape=(self.batch_size,),\n",
    "            minval=0,\n",
    "            maxval=total_priority,\n",
    "        )\n",
    "        samples_idx = self.sum_tree.sample_batch(tree_state, values)\n",
    "\n",
    "        return (sample_batch(samples_idx, buffer_state),)\n",
    "\n",
    "    # def _compute_importance_sampling(self, prob:float):\n",
    "    # return jnp.power((self.buffer_size*prob), -self.beta) / jnp.max()\n",
    "\n",
    "    def _compute_td_error(\n",
    "        model: hk.Transformed,\n",
    "        online_net_params: dict,\n",
    "        target_net_params: dict,\n",
    "        discount: float,\n",
    "        experience: Experience,\n",
    "    ):\n",
    "        state, action, reward, next_state, done = experience\n",
    "        # TODO: check wheter 1-done belongs here\n",
    "        td_target = (\n",
    "            (1 - done)\n",
    "            * discount\n",
    "            * jnp.max(model.apply(target_net_params, None, next_state))\n",
    "        )\n",
    "        prediction = model.apply(online_net_params, None, state)[action]\n",
    "        return reward + td_target - prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryanp\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\jax-rl-KPtyfD6I-py3.10\\lib\\site-packages\\jax\\_src\\ops\\scatter.py:94: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ryanp\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\jax-rl-KPtyfD6I-py3.10\\lib\\site-packages\\jax\\_src\\ops\\scatter.py:94: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "key = random.PRNGKey(0)\n",
    "env = Breakout()\n",
    "state, obs, env_key = env.reset(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experience(\n",
    "    state=obs,\n",
    "    action=jnp.int32(\n",
    "        1,\n",
    "    ),\n",
    "    reward=jnp.float32(\n",
    "        1,\n",
    "    ),\n",
    "    next_state=obs,\n",
    "    done=jnp.bool_(False),\n",
    ")\n",
    "\n",
    "per = PrioritizedExperienceReplay(BUFFER_SIZE, BATCH_SIZE, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryanp\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\jax-rl-KPtyfD6I-py3.10\\lib\\site-packages\\jax\\_src\\ops\\scatter.py:94: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Array([1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " Array(1, dtype=int32, weak_type=True))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_state = jnp.zeros(2 * BUFFER_SIZE - 1)\n",
    "buffer_state, tree_state = per.add(tree_state, buffer_state, exp, 0)\n",
    "tree_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-rl-KPtyfD6I-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
