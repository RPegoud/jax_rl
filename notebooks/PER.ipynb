{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryanp\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\jax-rl-KPtyfD6I-py3.10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import optax\n",
    "import haiku as hk\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "from jax import random, vmap, lax, tree_map\n",
    "from chex import dataclass\n",
    "from jax_tqdm import loop_tqdm\n",
    "from typing import Tuple, List\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from jym import (\n",
    "    Breakout,\n",
    "    DQN,\n",
    "    UniformReplayBuffer,\n",
    "    minatar_rollout,\n",
    "    BaseReplayBuffer,\n",
    "    SumTree,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': (64,),\n",
       " 'done': (64,),\n",
       " 'next_state': (64, 10, 10, 4),\n",
       " 'priority': (64,),\n",
       " 'reward': (64,),\n",
       " 'state': (64, 10, 10, 4)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = 64\n",
    "BATCH_SIZE = 8\n",
    "STATE_SHAPE = (10, 10, 4)\n",
    "\n",
    "buffer_state = {\n",
    "    \"state\": jnp.empty((BUFFER_SIZE, *STATE_SHAPE), dtype=jnp.float32),\n",
    "    \"action\": jnp.empty((BUFFER_SIZE,), dtype=jnp.int32),\n",
    "    \"reward\": jnp.empty((BUFFER_SIZE,), dtype=jnp.int32),\n",
    "    \"next_state\": jnp.empty((BUFFER_SIZE, *STATE_SHAPE), dtype=jnp.float32),\n",
    "    \"done\": jnp.empty((BUFFER_SIZE,), dtype=jnp.bool_),\n",
    "    \"priority\": jnp.empty((BUFFER_SIZE), dtype=jnp.float32),\n",
    "}\n",
    "jax.tree_map(lambda x: x.shape, buffer_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Experience:\n",
    "    state: jnp.ndarray\n",
    "    action: int\n",
    "    reward: float\n",
    "    next_state: jnp.ndarray\n",
    "    done: bool\n",
    "    priority: float = jnp.float32(0.0)\n",
    "\n",
    "\n",
    "class PrioritizedExperienceReplay(BaseReplayBuffer):\n",
    "    \"\"\"\n",
    "    Prioritized Experience Replay Buffer\n",
    "\n",
    "    Source: https://arxiv.org/pdf/1511.05952.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, buffer_size: int, batch_size: int, alpha: float, beta: float\n",
    "    ) -> None:\n",
    "        super().__init__(buffer_size, batch_size)\n",
    "        self.sum_tree = SumTree(buffer_size, batch_size)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def add(\n",
    "        self,\n",
    "        tree_state: jnp.ndarray,\n",
    "        buffer_state: dict,\n",
    "        idx: int,\n",
    "        experience: Experience,\n",
    "    ) -> Tuple[dict, jnp.ndarray]:\n",
    "        \"\"\"\n",
    "        Adds an experience to the replay buffer and\n",
    "        its priority to the sum tree.\n",
    "        \"\"\"\n",
    "        # assigns maximal priority to the new experience\n",
    "        priorities = tree_state[-self.buffer_size :]\n",
    "        max_priority = lax.select(\n",
    "            jnp.count_nonzero(priorities) > 0,\n",
    "            jnp.max(priorities),\n",
    "            1.0,\n",
    "        )\n",
    "        experience = experience.replace(priority=max_priority)\n",
    "\n",
    "        # add the experience to the sum tree and the replay buffer\n",
    "        idx = idx % self.buffer_size\n",
    "        tree_state = self.sum_tree.add(tree_state, idx, max_priority)\n",
    "\n",
    "        # set experience fields\n",
    "        for field in experience:\n",
    "            buffer_state[field] = buffer_state[field].at[idx].set(experience[field])\n",
    "\n",
    "        return buffer_state, tree_state\n",
    "\n",
    "    def update(self, tree_state: jnp.ndarray, td_error: float, idx: int) -> jnp.ndarray:\n",
    "        \"\"\"\n",
    "        Updates the priority of an experience using alpha.\n",
    "\n",
    "        Returns:\n",
    "            jnp.ndarray: the updated tre_state\n",
    "        \"\"\"\n",
    "        priority = td_error**self.alpha\n",
    "        return self.sum_tree.update(tree_state, idx, priority)\n",
    "\n",
    "    def sample(\n",
    "        self,\n",
    "        key: random.PRNGKey,\n",
    "        buffer_state: dict,\n",
    "        tree_state: jnp.ndarray,\n",
    "    ) -> Tuple[dict[Experience], List[float]]:\n",
    "        \"\"\"\n",
    "        Samples from the sum tree using the cumulative probability\n",
    "        distribution.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[Experience]: a tuple of `capacity` experiences\n",
    "        \"\"\"\n",
    "\n",
    "        @partial(vmap, in_axes=(0, None))\n",
    "        def sample_experiences(indexes: List[int]) -> Tuple[Experience]:\n",
    "            return tree_map(lambda x: x[indexes], buffer_state)\n",
    "\n",
    "        # sample from the sum tree\n",
    "        total_priority = tree_state[0]\n",
    "        values = random.uniform(\n",
    "            key,\n",
    "            shape=(self.batch_size,),\n",
    "            minval=0,\n",
    "            maxval=total_priority,\n",
    "        )\n",
    "        _, samples_idx, leaf_values = self.sum_tree.sample_idx_batch(tree_state, values)\n",
    "\n",
    "        # compute importance weights\n",
    "        priorities = tree_state[-self.buffer_size :]\n",
    "        N = jnp.count_nonzero(priorities)\n",
    "        importance_weights = (1.0 / (N * leaf_values)) ** -self.beta\n",
    "        # normalize weights\n",
    "        importance_weights /= importance_weights.max()\n",
    "\n",
    "        return sample_experiences(samples_idx), importance_weights\n",
    "\n",
    "    def _compute_td_error(\n",
    "        model: hk.Transformed,\n",
    "        online_net_params: dict,\n",
    "        target_net_params: dict,\n",
    "        discount: float,\n",
    "        experience: Experience,\n",
    "    ) -> float:\n",
    "        state, action, reward, next_state, done = experience\n",
    "        td_target = (\n",
    "            (1 - done)\n",
    "            * discount\n",
    "            * jnp.max(model.apply(target_net_params, None, next_state))\n",
    "        )\n",
    "        prediction = model.apply(online_net_params, None, state)[action]\n",
    "        return reward + td_target - prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryanp\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\jax-rl-KPtyfD6I-py3.10\\lib\\site-packages\\jax\\_src\\ops\\scatter.py:94: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ryanp\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\jax-rl-KPtyfD6I-py3.10\\lib\\site-packages\\jax\\_src\\ops\\scatter.py:94: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=bool with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "key = random.PRNGKey(0)\n",
    "env = Breakout()\n",
    "state, obs, env_key = env.reset(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experience(\n",
    "    state=obs,\n",
    "    action=jnp.int32(1),\n",
    "    reward=jnp.float32(1),\n",
    "    next_state=obs,\n",
    "    done=jnp.bool_(False),\n",
    ")\n",
    "\n",
    "per = PrioritizedExperienceReplay(BUFFER_SIZE, BATCH_SIZE, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_state = jnp.zeros(2 * BUFFER_SIZE - 1)\n",
    "tree_state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-rl-KPtyfD6I-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
